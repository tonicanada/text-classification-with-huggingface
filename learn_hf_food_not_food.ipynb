{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89543d37-1e0d-4c60-b94c-9a3409670f78",
   "metadata": {},
   "source": [
    "# Tutorial proyecto de clasificación de texto mediante Hugging Face (2 clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7de98-8123-4149-8878-35ca5d202a36",
   "metadata": {},
   "source": [
    "## ¿Qué vamos a construir?\n",
    "\n",
    "Bienvenido al tutorial del proyecto de clasificación de texto mediante Hugging Face. Este notebook está diseñado para que pueda ser reutilizable para otros casos.\n",
    "En concreto, vamos a construir un modelo que, a partir de una frase en inglés, va a determinar si se trata de comida o no (`food` o `not_food`). Para hacerlo, vamos a partir de un modelo ya existente en Hugging Face Hub, y lo vamos a adaptar a nuestras necesidades. Estos son los pasos que vamos a seguir:\n",
    "1. Datos: Definición del problema y adaptación de los datos\n",
    "2. Modelo: Entrenamiento y evaluación de modelo adecuado para nuestro problema.\n",
    "3. Demo: Vamos a crear una web pública donde cualquier persona podrá usar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c1dec-4a7a-46e5-993b-599dcc9965bc",
   "metadata": {},
   "source": [
    "## ¿Qué ventajas tiene aplicar esta técnica?\n",
    "Utilizar un modelo previamente entrenado y adaptarlo a nuestras necesidades específicas puede ser una estrategia muy beneficiosa. Existen muchos modelos disponibles, por ejemplo, en Hugging Face Hub, y podemos ajustarlos con una pequeña cantidad de datos para que cumplan con nuestras necesidades concretas.\n",
    "\n",
    "Estos modelos suelen ser relativamente ligeros en términos de tamaño, pero mantienen un alto grado de precisión, lo que los hace muy útiles para una amplia variedad de aplicaciones. Al ajustar un modelo, podemos implementarlo de forma eficiente en nuestro equipo local o en un servidor, integrándolo como una parte fundamental de una aplicación más amplia. Esta flexibilidad permite optimizar recursos y reducir significativamente el tiempo de desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec05865-dcbd-4d0e-8252-735426b2fbef",
   "metadata": {},
   "source": [
    "## Obtención y tratamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c40eb-46e4-4931-8807-578e76fc1fc0",
   "metadata": {},
   "source": [
    "### Importación de las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc6e874-4a93-4a52-b745-88359bcc05bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee87b136-48d3-433c-a3f6-d42486753fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acm/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers version: 4.45.2\n",
      "Using torch version: 2.4.1+cu121\n",
      "Using datasets version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "try:\n",
    "    import datasets, evaluate, accelerate, transformers\n",
    "    import gradio as gr\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -U datasets evaluate accelerate gradio transformers\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(f\"Using transformers version: {transformers.__version__}\")\n",
    "print(f\"Using torch version: {torch.__version__}\")\n",
    "print(f\"Using datasets version: {datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd66b7-7617-4b8c-be67-f8861860ab96",
   "metadata": {},
   "source": [
    "### Obtención de un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69f3d2f-8c65-44a7-bc30-37cef956c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path='mrdbourke/learn_hf_food_not_food_image_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e35d78-24e6-4e9d-acc5-a7f5f8460b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92a9eae-0773-4e53-98fb-a264505ee561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cómo son los datos?\n",
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17532330-83d2-4fe0-8424-a33874d2bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accedemos al set de entrenamiento\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1672fd50-0a8b-4270-8033-581ca809becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       " 'label': 'food'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254752a-8a14-46c1-b676-1097f84546d3",
   "metadata": {},
   "source": [
    "### Inspeccionamos ejemplos random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a347671-c2ec-4322-967a-9da207cc34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random samples from dataset:\n",
      "\n",
      "Text: Jicama in a bowl, sprinkled with chili powder and served with a side of lime wedges for a refreshing snack. | Label: food\n",
      "Text: Set of tea towels folded in a kitchen | Label: not_food\n",
      "Text: Creamy spinach and potato curry, featuring fluffy potatoes and nutritious spinach in a rich sauce with cream and garam masala. | Label: food\n",
      "Text: Set of candles lit on a table | Label: not_food\n",
      "Text: Flat screen TV neatly mounted on a wall | Label: not_food\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_indexs = random.sample(range(len(dataset['train'])), 5)\n",
    "random_indexs\n",
    "\n",
    "random_samples = dataset['train'][random_indexs]\n",
    "print(f\"[INFO] Random samples from dataset:\\n\")\n",
    "for text, label in zip(random_samples['text'], random_samples['label']):\n",
    "    print(f\"Text: {text} | Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb874a1d-14cc-4c0a-ade5-ecead31a437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'not_food']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los valores únicos de las etiquetas\n",
    "dataset['train'].unique('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86818bac-a8c8-4663-bfc0-0d79e7f55234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'food': 125, 'not_food': 125})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos la cantidad de frases para cada etiqueta\n",
    "from collections import Counter\n",
    "\n",
    "Counter(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e96fd2-dd48-49a5-a1c0-9c34c7a4b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Uniquely shaped sushi roll, such as a heart or...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Crunchy sushi roll with a creamy filling, feat...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>A gourmet pizza with a pesto base, topped with...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Set of measuring cups nested in a drawer</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>A slice of pizza with a spicy buffalo chicken ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Pizza with a unique crust, such as cauliflower...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     label\n",
       "55   Uniquely shaped sushi roll, such as a heart or...      food\n",
       "120  A slice of pepperoni pizza with a layer of mel...      food\n",
       "199  Crunchy sushi roll with a creamy filling, feat...      food\n",
       "140  A gourmet pizza with a pesto base, topped with...      food\n",
       "161           Set of measuring cups nested in a drawer  not_food\n",
       "141  A slice of pizza with a spicy buffalo chicken ...      food\n",
       "216  Pizza with a unique crust, such as cauliflower...      food"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos el dataset en un pandas DataFrame y tomamos una muestra\n",
    "food_not_food_df = pd.DataFrame(dataset['train'])\n",
    "food_not_food_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674e9c79-d723-4f20-9de9-282b387c40c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "food        125\n",
       "not_food    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea44f1-0398-4d0d-ab67-4c80ddbe297d",
   "metadata": {},
   "source": [
    "### Preparación de los datos para la clasificación de texto\n",
    "\n",
    "Queremos:\n",
    "1. Tokenizar nuestro texto - convertir texto en números (esto aplica para las frases y las etiquetas)\n",
    "2. Crear un train/test split - queremos entrentar nuestro modelo en el training split y evaluarlo en el test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be796f72-0978-4e72-b958-ec290dae501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'not_food', 1: 'food'}\n",
      "{'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Crear un mapeo para labels hacia un número id\n",
    "id2label ={0: \"not_food\", 1: \"food\"}\n",
    "label2id = {\"not_food\": 0, \"food\":1}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc56334e-0062-48c9-847e-ae1b473fa83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'not_food', 1: 'food'}\n"
     ]
    }
   ],
   "source": [
    "# Creando mappings para labels hacia números id de forma automática (especialmente útil cuando se trata de más de 2 clases)\n",
    "id2label = {idx: label for idx, label in enumerate(dataset['train'].unique('label')[::-1])}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83607331-a29c-4080-b84c-7ed2b2356b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: idx for idx,label in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ea05ae-d0d1-43fc-b1ce-bfcb5007f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'This is a sentence about my favourite food: honey', 'label': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convierte labels en 0 y 1\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "example_sample = {'text': 'This is a sentence about my favourite food: honey', 'label': 'food'}\n",
    "map_labels_to_number(example_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "325eb88e-876c-4bbe-9ca0-1b8399adbeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       "  'Set of books stacked on a desk',\n",
       "  'Watching TV together, a family has their dog stretched out on the floor',\n",
       "  'Wooden dresser with a mirror reflecting the room',\n",
       "  'Lawn mower stored in a shed'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapea las labels del dataset entero a números  \n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba568fbb-f0af-4c7f-aabd-9295a9fb0510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Set of paintbrushes stored in a jar',\n",
       "  'A close-up of a girl feeding her rabbit in the garden',\n",
       "  'A boy giving his dog a bath in the backyard',\n",
       "  'Set of baking sheets stacked in a cabinet',\n",
       "  'Camping tent pitched in a backyard'],\n",
       " 'label': [0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mezclar datos y observar más muestras aleatorias\n",
    "dataset.shuffle()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06215883-e1ac-4cec-be62-0e330f9fe701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dividir el dataset en training y test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba02086b-8c6f-4d4e-be25-b8944d613414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'A pair of slices from a barbecue chicken pizza', 'label': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx_train = random.randint(0, len(dataset['train']))\n",
    "random_sample_train = dataset['train'][random_idx_train]\n",
    "random_sample_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6deb0988-8ef2-4684-9e34-fc475138516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Comforting lamb curry bowl, featuring tender lamb slow-cooked in a flavorful sauce with cumin and coriander, garnished with toasted cumin seeds.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx_test = random.randint(0, len(dataset['test']))\n",
    "random_sample_test = dataset['test'][random_idx_test]\n",
    "random_sample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c8f11-0354-45a2-9180-5a7dc19650f1",
   "metadata": {},
   "source": [
    "### Tokenizar el texto\n",
    "\n",
    "Consiste básicamente en transformar texto a números. Es importante tomar el mismo `tokenizer` con el que los datos fueron entrenados. En nuestro caso, vamos a usar el tokenizer del modelo `distilbert/distilbert-base-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988a315d-4269-4fa0-a19c-91a99a3a65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path='distilbert/distilbert-base-uncased',\n",
    "                                         use_fast=True) # Use the fast implementation (on by default)\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e82615b-8e17-4535-8e06-152fc20d10b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el tokenizer\n",
    "tokenizer(\"I love pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bd368-abda-4f78-b528-434f0070d499",
   "metadata": {},
   "source": [
    "* `input_ids` = texto convertido en números\n",
    "* `attention_mask` = indica si hay que prestarle atención al input o no (1=sí prestar atención, 0 = no, no prestar atención)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11962402-4e9b-4b27-90f0-4fe26f3029cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('I love pizza!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c2bf145-6de7-4c8b-87dc-92031942e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tamaño del vocabulario del tokenizer: 30522 tokens\n",
      "[INFO] Longitud máxima de entrada que puede procesar el tokenizer: 512 tokens\n"
     ]
    }
   ],
   "source": [
    "# Calculamos cuán largo es el vocabulario del tokenizer escogido\n",
    "length_of_tokenizer_vocab = len(tokenizer.vocab)\n",
    "print(f\"[INFO] Tamaño del vocabulario del tokenizer: {length_of_tokenizer_vocab} tokens\")\n",
    "\n",
    "# Obtenemos la longitud máxima de secuencia que el tokenizer puede manejar\n",
    "max_tokenizer_input_sequence_length = tokenizer.model_max_length\n",
    "print(f\"[INFO] Longitud máxima de entrada que puede procesar el tokenizer: {max_tokenizer_input_sequence_length} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f751013-ae3c-4948-b409-cfe16af68bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4980"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Está \"antonio\" en el vocabulario? Vemos que sí\n",
    "tokenizer.vocab['antonio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4832113a-02ca-4a69-b886-3826f0734740",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'akash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Está \"akash\" en el vocabularoi? Vemos que no, da error\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43makash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'akash'"
     ]
    }
   ],
   "source": [
    "# Está \"akash\" en el vocabularoi? Vemos que no, da error\n",
    "tokenizer.vocab['akash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "582a153b-e8d5-4103-837b-f90b675b38dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 9875, 4095, 102], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('akash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38037e5-687f-42d5-aa69-faf3b7835d45",
   "metadata": {},
   "source": [
    "Las palabras que no están en el vocabulario del tokenizer igual son procesadas por este. Tal como se puede ver con \"akash\", el tokenizer ha subdividido la palabra en 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7bfbbfc-e472-4a8e-8749-6248b52f2f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'aka', '##sh', '[SEP]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer('akash').input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cff7cc69-9d4c-4250-8b1b-3d596fe8cf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '[SEP]']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intentamos tokenizar un emoji\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(\"😆\").input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76f82d0c-9fa4-4e8b-8f45-49a45361c103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 999), ('\"', 1000), ('#', 1001), ('##!', 29612), ('##\"', 29613)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomamos los 5 primeros items del vocabulario\n",
    "sorted(tokenizer.vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a836c6c-26ef-4293-873d-d7d771036849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guarantees', 21586),\n",
       " ('drummond', 19266),\n",
       " ('##watch', 18866),\n",
       " ('regretted', 18991),\n",
       " ('what', 2054)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(sorted(tokenizer.vocab.items()), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20525fda-1e06-4b16-a13a-535e5f88f383",
   "metadata": {},
   "source": [
    "### Creamos una función para tokenizar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93f9aa50-d937-4459-8b82-6202a255c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(ejemplos):\n",
    "    \"\"\"\n",
    "    Tokeniza el texto del ejemplo dado y devuelve el texto tokenizado.\n",
    "    \"\"\"\n",
    "    return tokenizer(ejemplos['text'],\n",
    "                    padding=True,  # rellena las secuencias cortas al tamaño de la secuencia más larga en el lote\n",
    "                    truncation=True)  # trunca las secuencias largas a la longitud máxima que el modelo puede procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99a52a21-e855-4d56-8b3f-e74b12a70c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sample_2 = {\"text\": \"I love pizza\", \"label\": 1}\n",
    "\n",
    "# Probamos la función\n",
    "tokenize_text(example_sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c923abf6-9ab6-465e-b761-c5be3f072ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = \"I love pizza \" * 1000\n",
    "long_text\n",
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9086a263-c417-46eb-a8b2-09186bb1195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_long_text = tokenize_text({\"text\": long_text, \"label\": 1})\n",
    "len(tokenized_long_text['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44e9a26c-6280-4fd4-a14b-267f3b5831a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae742455-02ae-4df3-8995-7b5e2c81b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████| 200/200 [00:00<00:00, 21305.48 examples/s]\n",
      "Map: 100%|█████████████████████████████| 50/50 [00:00<00:00, 9143.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Mapeamos la función tokenizer a todo el dataset\n",
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True, # set batched=True to tokenize across batches of samples at a time\n",
    "                                batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d95f422-d632-4c7f-a89c-42f30c84a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Key: text\n",
      "Train sample: Set of headphones placed on a desk\n",
      "Test sample: A slice of pepperoni pizza with a layer of melted cheese\n",
      "\n",
      "[INFO] Key: label\n",
      "Train sample: 0\n",
      "Test sample: 1\n",
      "\n",
      "[INFO] Key: input_ids\n",
      "Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[INFO] Key: attention_mask\n",
      "Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tomamos 2 ejemplos\n",
    "train_tokenized_sample = tokenized_dataset['train'][0]\n",
    "test_tokenized_sample = tokenized_dataset['test'][0]\n",
    "\n",
    "for key in train_tokenized_sample.keys():\n",
    "    print(f\"[INFO] Key: {key}\")\n",
    "    print(f\"Train sample: {train_tokenized_sample[key]}\")\n",
    "    print(f\"Test sample: {test_tokenized_sample[key]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12b7a0-56f3-45a8-9fbc-4ce9ece1218a",
   "metadata": {},
   "source": [
    "### Puntos claves sobre la tokenización\n",
    "1. Tokenizers = Convertir datos en números\n",
    "2. Hay muchos modelos disponibles con diferentes tokenizers; las herramientas `Auto` de Hugging Face (por ejemplo, `AutoTokenizer`, `AutoProcessor`, `AutoModel`, etc.) ayudan a emparejar tokenizers con los modelos correctos.\n",
    "3. Tokenización se puede hacer en paralelo usando funciones como `map` y en lotes (`batched`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbb9b1-64be-408a-927d-c78b4368e099",
   "metadata": {},
   "source": [
    "## Preparación del modelo\n",
    "\n",
    "Antes de configurar el modelo, debemos definir también cómo se medirá cuán buenas han sido las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68743221-1b77-41ba-8b18-ede891e4be6f",
   "metadata": {},
   "source": [
    "### Seteando una métrica de evaluación\n",
    "\n",
    "Queremos escoger una métrica de evaluación que nos permita tener una idea númerica de cuán bien nuestro modelo está funcionando.\n",
    "\n",
    "Algunas métricas de evaluación comunes son:\n",
    "- \n",
    "\n",
    "Some common evaluation metrics for classification:\n",
    "- Exactitud (Accuracy) (Cuántos ejemplos de cada 100 se clasificaron bien?)\n",
    "- Precisión (Precision)\n",
    "- Sensibilidad o Exhaustividad (Recall)\n",
    "- F1 Score\n",
    "\n",
    "La métrica de evaluación es importante porque en algunos proyectos puede haber algún mínimo que cumplir\n",
    "\n",
    "Algun formas para encontrar métricas de evaluación:\n",
    "- Scikit evaluation\n",
    "- Hugging Face evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f42ff83-7953-440a-8800-cacc2ae76d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./env/lib/python3.11/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33849724-0719-48bf-a4f9-b97d703c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a model by comparing the predictions and labels.\n",
    "    \"\"\"\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape) >= 2:\n",
    "        # need to get the maximum value from the model output (the index) as this is the \"most likely\" label according to the model\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58d6f673-a54c-436e-a41a-d310b2596c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when all predictions are correct: {'accuracy': 1.0}\n",
      "Accuracy when all one prediction is correct: {'accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de predicciones y de la métrica de exactitud\n",
    "example_preds_all_correct = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "example_preds_one_incorrect = np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "example_labels = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "# Test the function\n",
    "print(f\"Accuracy when all predictions are correct: {compute_accuracy((example_preds_all_correct, example_labels))}\")\n",
    "print(f\"Accuracy when all one prediction is correct: {compute_accuracy((example_preds_one_incorrect, example_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029a7d-dff6-458d-9ab2-1cd8892f43f0",
   "metadata": {},
   "source": [
    "### Seteamos un modelo para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92665719-bbcb-4e24-80a8-2523ca933b81",
   "metadata": {},
   "source": [
    "Flujo de trabajo:\n",
    "1. Crear y preprocesar los datos (hecho)\n",
    "2. Definir el modelo que nos gustaría usar para nuestro problema (huggingface/models) o consultar las \"guías de tareas\" en la documentación de HF Transformers\n",
    "3. Definir los argumentos de entrenamiento para entrenar nuestro modelo `transformers.TrainingArguments`\n",
    "4. Pasar los `TrainingArguments` a una instancia de `transformer.Trainer`\n",
    "5. Entrenar el modelo llamando a `Trainer.train()`\n",
    "6. Guardar nuestro modelo (en nuestra máquina local o en el Hugging Face Hub)\n",
    "7. Evaluar el modelo entrenado realizando y examinando predicciones sobre los datos de prueba\n",
    "8. Convertir el modelo en una demostración compartible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23079802-848b-4baa-a88f-3df814401821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = 'distilbert/distilbert-base-uncased',\n",
    "    num_labels=2, # Classify into food, not food\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ea622f0-d46a-44b8-879f-e9ef8cc20252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f19a7-9457-40af-8fc5-e4b8a0c672c1",
   "metadata": {},
   "source": [
    "Nuestro modelo se compone de las siguientes partes:\n",
    "1. `embeddings` - los embeddings son una forma de representación aprendida de los tokens. Así que, si los tokens son un mapeo directo de token a número, los embeddings son una representación vectorial aprendida.\n",
    "2. `transformer` - la columna vertebral de nuestra arquitectura de modelo, que ha descubierto patrones/relaciones en los embeddings.\n",
    "3. `classifier` - necesitamos personalizar esta capa para adaptarla a nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45a95bc8-188d-47f8-97ae-0aa0ad9f79fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Set of headphones placed on a desk',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  2275,\n",
       "  1997,\n",
       "  2132,\n",
       "  19093,\n",
       "  2872,\n",
       "  2006,\n",
       "  1037,\n",
       "  4624,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652caae-7446-4d50-a50f-23345ea97158",
   "metadata": {},
   "source": [
    "Nota: Si obtienes errores de entrada al pasar una muestra a un modelo, asegúrate de que la muestra que le pasas al modelo esté en el mismo formato en el que fue entrenado. Por ejemplo, si tu modelo usó un tokenizer específico, asegúrate de tokenizar tu texto antes de pasarlo al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f6733fe-f846-441c-a578-87a2e9148ebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m     \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:883\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    881\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 883\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    893\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:684\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m--> 684\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokenized_dataset['train'][0]['input_ids'],\n",
    "     attention_mask=tokenized_dataset['train'][0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20541d5-fc5d-4b19-b462-0063e548f4b1",
   "metadata": {},
   "source": [
    "### Contando los parámetros en nuestro modelo\n",
    "\n",
    "Pesos/parámetros = pequeñas oportunidades numéricas para que un modelo aprenda patrones en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "116cb8ee-c50c-4323-9964-24ab4cdb44fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainable_parameters': 66955010, 'total_parameters': 66955010}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    \"\"\"\n",
    "    Count the parameters of a PyTorch model.\n",
    "    \"\"\"\n",
    "    trainable_parameters = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "    total_parameters = sum(param.numel() for param in model.parameters())\n",
    "\n",
    "    return {\"trainable_parameters\": trainable_parameters, \"total_parameters\": total_parameters}\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73e05e-bae2-43e1-892c-ac369edc9d12",
   "metadata": {},
   "source": [
    "Parece que nuestro modelo tiene alrededor de 67 millones de parámetros y todos son entrenables\n",
    "\n",
    "Nota:\n",
    "\n",
    "* En general, cuantos más parámetros tenga un modelo, mayor capacidad tendrá para aprender.\n",
    "* Para ponerlo en perspectiva, modelos como Llama3 8B tienen 8 mil millones de parámetros.\n",
    "* Si buscas el mejor rendimiento posible, generalmente más parámetros es mejor.\n",
    "* Sin embargo, con más parámetros se requiere más capacidad de cómputo y tiempo.\n",
    "* Te sorprenderá lo bien que puede funcionar un modelo más pequeño con datos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2c5da74-1c53-4cf0-abac-6928caac0d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.40298507462687"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8_000_000_000/67_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53e0b1-88f1-4cc9-a651-c3bfbfbd4dd4",
   "metadata": {},
   "source": [
    "### Creando un directorio para guardar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbb30ddd-d4d2-4303-91aa-285452a51a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un directorio para guardar los modelos\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models dir\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = \"learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# Create model save path\n",
    "model_save_dir = Path(models_dir, model_save_name)\n",
    "\n",
    "model_save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7416178-cdba-499f-9d7b-1a7e3aa72b5e",
   "metadata": {},
   "source": [
    "### Configuración de los argumentos de entrenamiento (hiperparámetros) con TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c2a8c8c-eb77-4c31-be1a-148b81e2a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Guardando checkpoints del modelo: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "print(f\"[INFO] Guardando checkpoints del modelo: {model_save_dir}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create training arguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    # push_to_hub=True\n",
    "    hub_private_repo=False #When uploading to Hugging Face, do you want your model to be private or public (default public)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad5b5d7b-2812-4203-aef3-317d94c83df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/runs/Nov13_22-55-21_acm-msi,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.EPOCH,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=10,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=32,\n",
       "per_device_train_batch_size=32,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=3,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e791a-5b89-43df-b531-f5714dbda625",
   "metadata": {},
   "source": [
    "### Seteando una instancia de Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5d0f9f6-c1b3-48a3-b613-3832042a6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x75207dbcf750>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Setup Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bcb75-a83f-4575-be76-941dc5f8cb17",
   "metadata": {},
   "source": [
    "### ¡Entrenamos el modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f8913e6-93c9-4273-bac7-2e5540b66201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.107463</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df7d395f-d197-4483-91ba-7f86eb699bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_runtime: 16.3294\n",
      "train_samples_per_second: 122.479\n",
      "train_steps_per_second: 4.287\n",
      "total_flos: 18110777160000.0\n",
      "train_loss: 0.04557784213019269\n",
      "epoch: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionamos las métricas del modelo\n",
    "for key, value in results.metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509820-84c7-4021-93fd-26ee5e65ea86",
   "metadata": {},
   "source": [
    "### Guardamos el modelo para poder usarlo posteriormente\n",
    "\n",
    "**Nota**: Si estás guardando el modelo en Google Colab, ten en cuenta que desaparecerá de tu instancia de Colab cuando se desconecte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a23c1e90-33af-4330-9ada-50d00315388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "print(f\"[INFO] Saving model to {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e5519-9eb7-4cb0-a076-c28a5956c0b3",
   "metadata": {},
   "source": [
    "## Inspeccionamos las métricas del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54bbcbbb-6da4-46d2-9f8a-324862a48e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3992,\n",
       "  'grad_norm': 1.7019474506378174,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.10746302455663681,\n",
       "  'eval_accuracy': 0.98,\n",
       "  'eval_runtime': 0.0429,\n",
       "  'eval_samples_per_second': 1164.657,\n",
       "  'eval_steps_per_second': 46.586,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.0441,\n",
       "  'grad_norm': 0.14603981375694275,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos la historia del entrenamiento\n",
    "trainer_history_all = trainer.state.log_history\n",
    "trainer_history_metrics = trainer_history_all[:-1]\n",
    "trainer_history_training_time = trainer_history_all[-1]\n",
    "\n",
    "# Vemos las primeras 3\n",
    "trainer_history_metrics[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d22f9a52-beda-4ff3-96c3-fdf551beac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 2 en training set:\n",
      "[{'epoch': 1.0,\n",
      "  'grad_norm': 1.7019474506378174,\n",
      "  'learning_rate': 9e-05,\n",
      "  'loss': 0.3992,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'grad_norm': 0.14603981375694275,\n",
      "  'learning_rate': 8e-05,\n",
      "  'loss': 0.0441,\n",
      "  'step': 14}]\n",
      "\n",
      "Primeros 2 en eval epochs:\n",
      "[{'epoch': 1.0,\n",
      "  'eval_accuracy': 0.98,\n",
      "  'eval_loss': 0.10746302455663681,\n",
      "  'eval_runtime': 0.0429,\n",
      "  'eval_samples_per_second': 1164.657,\n",
      "  'eval_steps_per_second': 46.586,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'eval_accuracy': 0.98,\n",
      "  'eval_loss': 0.059366654604673386,\n",
      "  'eval_runtime': 0.0421,\n",
      "  'eval_samples_per_second': 1186.4,\n",
      "  'eval_steps_per_second': 47.456,\n",
      "  'step': 14}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Extraemos las métricas eval y training\n",
    "trainer_history_training_set = []\n",
    "trainer_history_eval_set = []\n",
    "\n",
    "# Loop a través de las métricas\n",
    "for item in trainer_history_metrics:\n",
    "    item_keys = list(item.keys())\n",
    "    if any(\"eval\" in item for item in item_keys):\n",
    "        trainer_history_eval_set.append(item)\n",
    "    else:\n",
    "        trainer_history_training_set.append(item)\n",
    "\n",
    "# Mostramos los 2 primeros de cada uno\n",
    "print(f\"Primeros 2 en training set:\")\n",
    "pprint.pprint(trainer_history_training_set[:2])\n",
    "\n",
    "print(f\"\\nPrimeros 2 en eval epochs:\")\n",
    "pprint.pprint(trainer_history_eval_set[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff569d-8fc8-4563-bee5-f23c9ee6ac36",
   "metadata": {},
   "source": [
    "### Revisando las `loss curves`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a351d42f-d94f-43f2-b188-26f41fd67009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3992</td>\n",
       "      <td>1.701947</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.146040</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate  epoch  step\n",
       "0  0.3992   1.701947        0.00009    1.0     7\n",
       "1  0.0441   0.146040        0.00008    2.0    14\n",
       "2  0.0059   0.046152        0.00007    3.0    21\n",
       "3  0.0019   0.022477        0.00006    4.0    28\n",
       "4  0.0012   0.019875        0.00005    5.0    35"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un pandas DataFrame para training y evaluation metrics\n",
    "trainer_history_train_df = pd.DataFrame(trainer_history_training_set)\n",
    "trainer_history_eval_df = pd.DataFrame(trainer_history_eval_set)\n",
    "\n",
    "trainer_history_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0981e67e-1e4f-49c3-bc9a-5b0e526186c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./env/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.11/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./env/lib/python3.11/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./env/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "671fced0-e269-4ae9-be8f-5b46164979b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(trainer_history_train_df['epoch'], trainer_history_train_df['loss'], label=\"Training loss\")\n",
    "plt.plot(trainer_history_eval_df['epoch'], trainer_history_eval_df['eval_loss'], label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Text classificacion fine-tuning DistilBert training and evaluation over time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057b253-8215-4cbb-995d-683c8cac3fe1",
   "metadata": {},
   "source": [
    "### Subiendo nuestro modelo al Hugging Face Hub\n",
    "\n",
    "¿Por qué hacer esto?\n",
    "- Para poder compartir nuestro modelo.\n",
    "- Otras personas pueden probarlo.\n",
    "- Podemos mantener un historial de diferentes versiones del modelo.\n",
    "\n",
    "Para escribir en Hugging Face:\n",
    "- Si estás en Google Token: configura el \"token\" con acceso de \"lectura y escritura\".\n",
    "- Si estás en una máquina local: configura `huggingface-cli`.\n",
    "\n",
    "Para guardar en el Hugging Face Hub, podemos usar el método `Trainer.push_to_hub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b119752d-3f65-4e87-b874-3cbfd03c3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/acm/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0995627-9ce9-4e36-9b65-d5911fce018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model successfully uploaded to the Hugging Face Hub with URL: https://huggingface.co/tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/tree/main/\n"
     ]
    }
   ],
   "source": [
    "# Save our model to the Hugging Face Hub\n",
    "model_upload_url = trainer.push_to_hub(\n",
    "    commit_message=\"Subiendo el modelo de clasificador de texto de food/not_food\",\n",
    ")\n",
    "print(f\"[INFO] Model successfully uploaded to the Hugging Face Hub with URL: {model_upload_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938c863-cc7d-4995-81f2-85314725f356",
   "metadata": {},
   "source": [
    "## Haciendo y evaluando predicciones en los datos test\n",
    "\n",
    "**Nota**: Evaluar un modelo es tan importante como entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "635ba9ea-68a3-4128-9ac6-392e1b2baf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Métricas de predicción en la data test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0004733024397864938,\n",
       " 'test_accuracy': 1.0,\n",
       " 'test_runtime': 0.0736,\n",
       " 'test_samples_per_second': 679.015,\n",
       " 'test_steps_per_second': 27.161}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones en el set de test\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "prediction_values = predictions_all.predictions\n",
    "prediction_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] Métricas de predicción en la data test:\")\n",
    "prediction_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bf46b89-d858-4530-8ec2-a39d1ba3bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.5655854,  4.050842 ],\n",
       "       [ 4.108436 , -3.5667434],\n",
       "       [-3.5987396,  4.051071 ],\n",
       "       [ 4.189356 , -3.5941718],\n",
       "       [ 4.174309 , -3.5734787],\n",
       "       [-3.5950534,  4.062822 ],\n",
       "       [ 4.179851 , -3.5814786],\n",
       "       [ 4.1800413, -3.5784364],\n",
       "       [-3.5961647,  4.0515275],\n",
       "       [-3.5851297,  4.040712 ],\n",
       "       [-3.5919209,  4.052533 ],\n",
       "       [-3.5278883,  3.977925 ],\n",
       "       [ 4.1621585, -3.5740569],\n",
       "       [-3.5964828,  4.047571 ],\n",
       "       [-3.575441 ,  4.0346985],\n",
       "       [ 4.193889 , -3.570478 ],\n",
       "       [-3.5895047,  4.049947 ],\n",
       "       [ 4.134468 , -3.565461 ],\n",
       "       [-3.6007972,  4.027627 ],\n",
       "       [-3.6008315,  4.056313 ],\n",
       "       [-3.5901027,  4.021924 ],\n",
       "       [-3.5940216,  4.0449224],\n",
       "       [ 4.157044 , -3.5858703],\n",
       "       [ 4.184146 , -3.5836735],\n",
       "       [-3.6022315,  4.0555916],\n",
       "       [-3.601858 ,  4.031769 ],\n",
       "       [-3.5864644,  4.0300655],\n",
       "       [ 4.173559 , -3.5732865],\n",
       "       [-3.5922463,  4.056378 ],\n",
       "       [ 4.1712446, -3.5756712],\n",
       "       [-3.5953584,  4.052969 ],\n",
       "       [-3.5861163,  4.0251436],\n",
       "       [-3.6032705,  4.0547924],\n",
       "       [ 4.183695 , -3.5825574],\n",
       "       [-3.5894945,  4.040144 ],\n",
       "       [-3.5976434,  4.031395 ],\n",
       "       [-3.5990906,  4.05225  ],\n",
       "       [-3.5894632,  4.0229206],\n",
       "       [ 4.1897984, -3.5634496],\n",
       "       [ 4.141019 , -3.548046 ],\n",
       "       [-3.3491764,  3.7925444],\n",
       "       [-3.5960152,  4.0398884],\n",
       "       [-3.5888462,  4.0464234],\n",
       "       [ 4.1806254, -3.5830078],\n",
       "       [-3.604766 ,  4.0404053],\n",
       "       [-3.5897412,  4.058768 ],\n",
       "       [-3.5865188,  4.0312247],\n",
       "       [-3.5943575,  4.057223 ],\n",
       "       [ 4.186881 , -3.5790954],\n",
       "       [-3.5953913,  4.0139875]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.0004733024397864938, 'test_accuracy': 1.0, 'test_runtime': 0.0736, 'test_samples_per_second': 679.015, 'test_steps_per_second': 27.161})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35c0eb-ead3-4f70-9393-e783b928f478",
   "metadata": {},
   "source": [
    "### Obtengamos las probabilidades predichas y evaluemos manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1882b35c-3213-4ed9-8184-22e7aaa0c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5655854,  4.050842 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo devuelve logits sin procesar\n",
    "predictions_all.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d39360bb-3c2f-4c45-95bd-f8ed451a0492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9206e-04, 9.9951e-01])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax convierte todos los valores para que estén entre 0 y 1 y la suma total de los valores sea 1\n",
    "# Esto es lo que se conoce como \"probabilidad de predicción\"\n",
    "torch.softmax(torch.tensor(predictions_all.predictions[0]), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4ce60-7655-4f00-bc0e-04caa4c482f6",
   "metadata": {},
   "source": [
    "**Nota**: Si deseas un buen método de evaluación, haz predicciones sobre todo tu conjunto de datos de prueba, luego indexa las predicciones que son incorrectas pero tienen una alta probabilidad de predicción. Por ejemplo, obtén las 100-1000 principales y revisa todos los ejemplos donde la predicción del modelo tenía una alta probabilidad pero fue incorrecta -> esto a menudo conduce a excelentes percepciones sobre tus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cbfd1-3de5-4780-b1a7-670e079fd3aa",
   "metadata": {},
   "source": [
    "**Nota**: Estos valores no sugieren cuán \"correcto\" está el modelo, porque un modelo puede tener una alta probabilidad de predicción pero aún así estar equivocado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69d3c85f-142d-43c9-bbf9-c14fa9cfb0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Test accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Predicted logits (raw outputs of the model) -> prediction probabilities with torch.softmax -> predicted labels\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Obtener prediction probabilities con torch.softmax\n",
    "pred_probs = torch.softmax(torch.tensor(prediction_values), dim=1)\n",
    "pred_probs\n",
    "\n",
    "# 2. Obtener las predicted labels\n",
    "pred_labels = torch.argmax(pred_probs, dim=1)\n",
    "pred_labels\n",
    "\n",
    "# 3. Obtener las true labels\n",
    "true_labels = tokenized_dataset['test']['label']\n",
    "\n",
    "# 4. Calcular las etiquetas de predicción con las etiquetas reales y obtener la precisión en el test\n",
    "test_accuracy = accuracy_score(y_true = true_labels,\n",
    "                               y_pred = pred_labels)\n",
    "\n",
    "print(f\"[INFO] Test accuracy: {test_accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57aa62b-1bda-43f8-8850-aa5260c57e50",
   "metadata": {},
   "source": [
    "### Explorando las probabilidades de predicción de nuestro modelo\n",
    "\n",
    "Es una excelente manera de evaluar un modelo ordenando las predicciones y observando dónde se equivocó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b112fee6-6231-45c2-a3b1-a20fdf0bd35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red brick fireplace with a mantel serving as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set of mugs hanging on a hook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_label  pred_label  \\\n",
       "0  A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "1  Red brick fireplace with a mantel serving as a...           0           0   \n",
       "2  A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
       "3                      Set of mugs hanging on a hook           0           0   \n",
       "4  Standing floor lamp providing light next to an...           0           0   \n",
       "\n",
       "   pred_probs  \n",
       "0    0.999508  \n",
       "1    0.999536  \n",
       "2    0.999524  \n",
       "3    0.999584  \n",
       "4    0.999569  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataFrame of test predictions\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    \"text\": dataset['test']['text'],\n",
    "    \"true_label\": true_labels,\n",
    "    \"pred_label\": pred_labels,\n",
    "    \"pred_probs\": torch.max(pred_probs, dim=1).values\n",
    "})\n",
    "\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa057b23-b609-42ef-a519-3670acc9c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A bowl of cherries with a sprig of mint for ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A close-up shot of a cheesy pizza slice being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Plate of sushi served with pickled ginger and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Two handfuls of bananas in a fruit bowl with g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Crunchy sushi roll with tempura flakes or pank...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pizza with a seafood theme, featuring toppings...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Close-up of a sushi roll with avocado, cucumbe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A fruit platter with a variety of exotic fruit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A bowl of sliced kiwi with a sprinkle of sugar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_label  pred_label  \\\n",
       "40  A bowl of cherries with a sprig of mint for ga...           1           1   \n",
       "11  A close-up shot of a cheesy pizza slice being ...           1           1   \n",
       "49  Plate of sushi served with pickled ginger and ...           1           1   \n",
       "14  Two handfuls of bananas in a fruit bowl with g...           1           1   \n",
       "31  Crunchy sushi roll with tempura flakes or pank...           1           1   \n",
       "20  Pizza with a seafood theme, featuring toppings...           1           1   \n",
       "37  Close-up of a sushi roll with avocado, cucumbe...           1           1   \n",
       "0   A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "26  A fruit platter with a variety of exotic fruit...           1           1   \n",
       "46  A bowl of sliced kiwi with a sprinkle of sugar...           1           1   \n",
       "\n",
       "    pred_probs  \n",
       "40    0.999209  \n",
       "11    0.999450  \n",
       "49    0.999504  \n",
       "14    0.999505  \n",
       "31    0.999505  \n",
       "20    0.999506  \n",
       "37    0.999506  \n",
       "0     0.999508  \n",
       "26    0.999508  \n",
       "46    0.999509  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra 10 ejemplos con baja prediction probability\n",
    "test_predictions_df.sort_values(\"pred_probs\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600f1ab-d683-4a51-b2bc-a5ba6a8b4c26",
   "metadata": {},
   "source": [
    "## Haciendo y evaluando predicciones en datos personalizados\n",
    "\n",
    "Vamos a probar el modelo para que haga predicciones sobre frases que no están ni en el training set ni en el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1f1cb31-3405-4244-aab6-da560d82bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "hugging_face_model_path = \"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef9d41-7664-40a9-8b8c-99ac41e2d84e",
   "metadata": {},
   "source": [
    "### Discutiendo formas de hacer predicciones (inferencia)\n",
    "* Nota: Siempre que escuches la palabra \"inferencia\", significa usar un modelo para hacer predicciones sobre datos.\n",
    "\n",
    "Dos formas principales de realizar inferencia:\n",
    "1. **Modo Pipeline** - Usando `transformers.pipeline` para cargar nuestro modelo y realizar clasificación de texto.\n",
    "2. **Modo PyTorch** - Usando una combinación de `transformers.AutoTokenizer` y `transformers.AutoModelForSequenceClassification` y pasando el nombre de nuestro modelo objetivo.\n",
    "\n",
    "Cada modo soporta:\n",
    "1. Predicciones una a la vez (rápido, pero puede ser más lento con muchos, muchos ejemplos).\n",
    "    * Útil para, por ejemplo, un sistema de comentarios donde los comentarios ocurren de forma esporádica, para predecir si el comentario es \"spam\" o \"no spam\".\n",
    "2. Lotes de predicciones a la vez (más rápido, pero hasta cierto punto, por ejemplo, si predices 32 ejemplos a la vez, esto puede ser mucho más rápido que uno a la vez, pero si predices 128 a la vez, puede que no veas muchas más mejoras en la velocidad).\n",
    "    * Útil cuando tienes una base de datos estática grande o muchos ejemplos entrando al mismo tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3e9de0a-db18-4666-a432-4639469d5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Definiendo el device para hacer las predicciones\n",
    "# Note: Normalmente si el hardware es más rápido, más rápidas son las predicciones, \n",
    "# por ejemplo, si tienes una GPU, te conviene usarla en lugar de la CPU \n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "DEVICE = set_device()\n",
    "print(f\"[INFO] Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca05b7-c393-4667-8251-333f5e0c693c",
   "metadata": {},
   "source": [
    "### Haciendo prediciones con el pipeline mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "636afad1-19ba-4493-9747-a5b1fa138f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 13 23:24:19 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8               4W /  80W |   1598MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6469      G   /usr/bin/gnome-shell                          2MiB |\n",
      "|    0   N/A  N/A     15129      C   ...rses/ztm-huggingface/env/bin/python     1592MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66f91271-8c0e-403c-a014-3e3ad2e1b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x752199cc7d50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE = 32 # reminder: prediction speed often increases with higher batch size (e.g. 1->32 but can saturate at even point)\n",
    "\n",
    "# Create an instance of transformers.pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=local_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k=1,\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "food_not_food_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62e0f679-3535-4fe7-85dd-e04dccccb3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9984574317932129}]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_custom_sentence = \"A plate of pizza\" \n",
    "food_not_food_classifier(test_custom_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8aa59e5d-6074-45ad-9cec-d01cdfc3d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipeline\n",
    "del food_not_food_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f651567-2cdd-4258-9b3d-3c9b8dfb4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pipeline with a model from Hugging Face\n",
    "from transformers import pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=hugging_face_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k=1,\n",
    "                                    batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8ee8d4a-f0db-4dd7-87c2-05444f454d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9984574317932129}]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(test_custom_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da0e22-7eb6-4f58-acd1-afb0be4cca64",
   "metadata": {},
   "source": [
    "#### Hacer múltiples predicciones al mismo tiempo con predicción por lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8528f41-d37e-4138-95e5-372a6088cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.9983304142951965}],\n",
       " [{'label': 'not_food', 'score': 0.9984914064407349}],\n",
       " [{'label': 'not_food', 'score': 0.9984080195426941}],\n",
       " [{'label': 'not_food', 'score': 0.9960306286811829}],\n",
       " [{'label': 'not_food', 'score': 0.9941054582595825}],\n",
       " [{'label': 'not_food', 'score': 0.9981845021247864}],\n",
       " [{'label': 'not_food', 'score': 0.9975733160972595}],\n",
       " [{'label': 'food', 'score': 0.9968075752258301}],\n",
       " [{'label': 'not_food', 'score': 0.9991003274917603}],\n",
       " [{'label': 'not_food', 'score': 0.9979191422462463}]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una lista de oraciones para hacer predicciones\n",
    "sentences = [\n",
    "    \"I whipped up a fresh batch of code, but it seems to have a syntax error.\",\n",
    "    \"We need to marinate these ideas overnight before presenting them to the client.\",\n",
    "    \"The new software is definitely a spicy upgrade, taking some time to get used to.\",\n",
    "    \"Her social media post was the perfect recipe for a viral sensation.\",\n",
    "    \"He served up a rebuttal full of facts, leaving his opponent speechless.\",\n",
    "    \"The team needs to simmer down a bit before tackling the next challenge.\",\n",
    "    \"The presentation was a delicious blend of humor and information, keeping the audience engaged.\",\n",
    "    \"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant.\",\n",
    "    \"Daniel Bourke is really cool :D\",\n",
    "    \"My favoruite food is biltong!\"\n",
    "]\n",
    "\n",
    "food_not_food_classifier(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6c177-1ab7-46f2-b94a-3236f930200e",
   "metadata": {},
   "source": [
    "#### Medir el tiempo de nuestro modelo con tamaños de muestra más grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc1f4e72-a7db-4cef-a420-d92a4891f348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cantidad de frases: 1000\n",
      "[INFO] Tiempo total para realizar predicciones en 1000 frases (una por una): 3.910560131072998s\n",
      "[INFO] Tiempo promedio para realizar una predicción (método una a una): 0.003910560131072998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create 1000 sentences\n",
    "sentences_1000 = sentences * 100\n",
    "\n",
    "# Time how long it takes to make predictions on all sentences (one at a time)\n",
    "print(f\"[INFO] Cantidad de frases: {len(sentences_1000)}\")\n",
    "start_time_one_at_a_time = time.time()\n",
    "for sentence in sentences_1000:\n",
    "    # Realizar una predicción\n",
    "    food_not_food_classifier(sentence)\n",
    "end_time_one_at_a_time = time.time()\n",
    "\n",
    "total_time_one_at_a_time = end_time_one_at_a_time - start_time_one_at_a_time\n",
    "avg_time_per_pred = total_time_one_at_a_time/len(sentences_1000)\n",
    "print(f\"[INFO] Tiempo total para realizar predicciones en {len(sentences_1000)} frases (una por una): {total_time_one_at_a_time}s\")\n",
    "print(f\"[INFO] Tiempo promedio para realizar una predicción (método una a una): {avg_time_per_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b885bfec-cb10-4091-80b9-4032caba80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of sentences: 100\n",
      "[INFO] Tiempo total para realizar predicciones en 100 frases (batch mode): 0.104925\n",
      "[INFO] Tiempo promedio para realizar una predicción (batch mode): 0.00104925\n",
      "\n",
      "[INFO] Number of sentences: 1000\n",
      "[INFO] Tiempo total para realizar predicciones en 1000 frases (batch mode): 0.67505\n",
      "[INFO] Tiempo promedio para realizar una predicción (batch mode): 0.00067505\n",
      "\n",
      "[INFO] Number of sentences: 10000\n",
      "[INFO] Tiempo total para realizar predicciones en 10000 frases (batch mode): 6.44067\n",
      "[INFO] Tiempo promedio para realizar una predicción (batch mode): 0.00064407\n",
      "\n",
      "[INFO] Number of sentences: 100000\n",
      "[INFO] Tiempo total para realizar predicciones en 100000 frases (batch mode): 66.494505\n",
      "[INFO] Tiempo promedio para realizar una predicción (batch mode): 0.00066495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's now use pipeline in batches\n",
    "for i in [10, 100, 1000, 10_000]:\n",
    "    sentences_big = sentences*i\n",
    "    print(f\"[INFO] Number of sentences: {len(sentences_big)}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Predict on all sentences in batch ode\n",
    "    food_not_food_classifier(sentences_big)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time_per_all_sentences_batch_mode = end_time - start_time\n",
    "    avg_time_per_sentence_batch_mode = total_time_per_all_sentences_batch_mode/len(sentences_big)\n",
    "\n",
    "    print(f\"[INFO] Tiempo total para realizar predicciones en {len(sentences_big)} frases (batch mode): {round(total_time_per_all_sentences_batch_mode, 6)}\")\n",
    "    print(f\"[INFO] Tiempo promedio para realizar una predicción (batch mode): {round(avg_time_per_sentence_batch_mode, 8)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0238a0-8f8b-4a45-a909-9b5a3643bfe9",
   "metadata": {},
   "source": [
    "### Haciendo predicciones con PyTorch\n",
    "\n",
    "Pasos para hacer predicciones con PyTorch:\n",
    "1. Crear el tokenizer con `AutoTokenizer`\n",
    "2. Crear el modelo con `AutoModel` (`AutoModelForSequenceClassification`)\n",
    "3. Tokenizar el texto con el paso 1\n",
    "4. Hacer la predicción con el paso 2\n",
    "5. Formatear la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "165b457d-527b-4b8e-b2ae-8cb7617288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Setup the model path\n",
    "model_path = \"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# Create an example to predict on\n",
    "sample_food_text = \"A delicious photo of a plate of scrambled eggs, toast an bacon\"\n",
    "\n",
    "# Prepare the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "inputs = tokenizer(sample_food_text,\n",
    "                   return_tensors=\"pt\") # \"pt\" stands for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef4e353d-4b6e-4e9b-8f17-031dd22fbd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load our text classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1bf38126-3ec4-4cd5-8f4c-a249120ae62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.4358,  3.8867]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "# with torch.no_grad()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a4e54c7-87b5-4de2-8e38-d18fd3bf28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: A delicious photo of a plate of scrambled eggs, toast an bacon\n",
      "Etiqueta predecida: food\n",
      "Probabilidad de predicción: 0.9993398785591125\n"
     ]
    }
   ],
   "source": [
    "# Convierte logits en prediction probability + label\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "prediction_probability = torch.softmax(outputs.logits, dim=1).max().item()\n",
    "\n",
    "print(f\"Texto: {sample_food_text}\")\n",
    "print(f\"Etiqueta predecida: {model.config.id2label[predicted_class_id]}\")\n",
    "print(f\"Probabilidad de predicción: {prediction_probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e4330bb-e4d0-4f73-b2f1-7321f73e7ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9993398785591125}]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(sample_food_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7860b-2341-4102-a6b0-59157e6571e6",
   "metadata": {},
   "source": [
    "## Proceso completo\n",
    "\n",
    "Vamos a repasar el proceso principio a fin.\n",
    "\n",
    "Desde la importación de los datos, pasando por la construcción del modelo, la evaluación del modelo hasta el guardado del modelo para nuestro proyecto de clasificación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e489ffe-32f4-4bc2-a549-cf7bb85058ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62b310e2-c2ce-44bf-a7bc-643bee19c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creando carpeta para guardar los modelos: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n",
      "[INFO] Descargando dataset de Hugging Face Hub, nombre: mrdbourke/learn_hf_food_not_food_image_captions\n",
      "[INFO] Tokenizing text for model training with tokenizer: distilbert/distilbert-base-uncased\n",
      "[INFO] Cargando modelo: distilbert/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ¡Modelo cargado correctamente!!\n",
      "[INFO] Empezando entrenamiento de modelo...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Entrenamiento completado, guardando modelo en siguiente carpeta local: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n",
      "[INFO] Subiendo modelo a Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_args.bin: 100%|███████████████████| 5.30k/5.30k [00:00<00:00, 7.41kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Modelo subido con éxito, disponible en https://huggingface.co/tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/tree/main/\n",
      "[INFO] Realizando evaluación en test dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Métricas de predicción en test data:\n",
      "{'test_accuracy': 1.0,\n",
      " 'test_loss': 0.0005472198827192187,\n",
      " 'test_runtime': 0.0564,\n",
      " 'test_samples_per_second': 886.989,\n",
      " 'test_steps_per_second': 35.48}\n"
     ]
    }
   ],
   "source": [
    "# 1. Importamos las librerías necesarias\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 2. Configuramos variables para model training y saving pipeline\n",
    "DATASET_NAME = \"mrdbourke/learn_hf_food_not_food_image_captions\"\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "MODEL_SAVE_DIR_NAME = \"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# 3. Creamos directorio para salvar los modelos\n",
    "print(f\"[INFO] Creando carpeta para guardar los modelos: {MODEL_SAVE_DIR_NAME}\")\n",
    "model_save_dir = Path(MODEL_SAVE_DIR_NAME)\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4. Cargamos y preprocesamos el dataset desde Hugging Face Hub\n",
    "print(f\"[INFO] Descargando dataset de Hugging Face Hub, nombre: {DATASET_NAME}\")\n",
    "dataset = datasets.load_dataset(DATASET_NAME)\n",
    "\n",
    "id2label = {0: \"not_food\", 1: \"food\"}\n",
    "label2id  = {\"not_food\": 0, \"food\": 1}\n",
    "\n",
    "# Creando función para mapear id a etiquetas en el dataset \n",
    "def map_labels_to_number(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "# Mapear la función en todo el dataset\n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "\n",
    "# Dividimos el dataset en train/test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Importamos tokenizer y lo mapeamos en todo el dataset\n",
    "print(f\"[INFO] Tokenizing text for model training with tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                          use_fast=True)\n",
    "\n",
    "# Creamos función para tokenizar ejemplos\n",
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True,\n",
    "                     truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "                     \n",
    "# 6. Definimos una métrica de evaluación\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_accuracy(predictions_and_labels):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    # El modelo tendrá outputs logits de la siguiente forma ([[item_n, item_n], [item_m, item_m]]) \n",
    "    # dependiendo del número de clases que tenga el problema\n",
    "    # Queramos comparar etiquetas que están en la forma ([0,0,0,1])\n",
    "    if len(predictions.shape) >= 2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "# 7. Seteamos un modelo\n",
    "print(f\"[INFO] Cargando modelo: {MODEL_NAME}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "print(f\"[INFO] ¡Modelo cargado correctamente!!\")\n",
    "\n",
    "# Configurar TrainingArguments (estos son los hiperparámetros para nuestro modelo)\n",
    "# Hiperparámetros = configuraciones que podemos establecer como desarrolladores\n",
    "# Parámetros = configuraciones/pesos que nuestro modelo aprende por sí mismo\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    "    hub_private_repo=False #Note: this will make our model public by default\n",
    ")\n",
    "\n",
    "# Creamos instancia de Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "# 8. Entrenamos el modelo\n",
    "print(f\"[INFO] Empezando entrenamiento de modelo...\")\n",
    "results = trainer.train()\n",
    "\n",
    "# 9. Guardamos el modelo en un directorio local\n",
    "print(f\"[INFO] Entrenamiento completado, guardando modelo en siguiente carpeta local: {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)\n",
    "\n",
    "# 10. Subimos el modelo a Hugging Face Hub\n",
    "print(f\"[INFO] Subiendo modelo a Hugging Face Hub...\")\n",
    "model_upload_url = trainer.push_to_hub(\n",
    "    commit_message=\"Subiendo clasificador de texto (food, not food)\",\n",
    "    token=os.getenv(\"HF_TOKEN\")\n",
    ")\n",
    "print(f\"[INFO] Modelo subido con éxito, disponible en {model_upload_url}\")\n",
    "\n",
    "# 11. Evaluación delo modelo en lla test data\n",
    "print(f\"[INFO] Realizando evaluación en test dataset...\")\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] Métricas de predicción en test data:\")\n",
    "pprint.pprint(predictions_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bfa3041a-adaf-4564-a36d-22c16b14ef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.9995301961898804}]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Nos aseguramos que el modelo funciona con frases que no están ni en el training ni en el test set\n",
    "from transformers import pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=model_save_dir,\n",
    "                                    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "                                    top_k=1,\n",
    "                                    batch_size=32)\n",
    "\n",
    "food_not_food_classifier(\"Yo!!! We just trained a model not food text classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3695d6cf-d29f-479c-aea0-8352a06e681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9993554949760437}]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"A bowl of sliced bell peppers with a sprinkle of paprika and a side of hummus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0233fca7-d612-4ed5-a78c-8516988cbaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9972631931304932}]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"a pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc129874-eb4b-49ae-be69-05ff3c152b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9918377995491028}]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"My favoruite food is biltong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89ae18bb-576d-49be-a013-0ec590e9f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9989994168281555}]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"Eggs and bakon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d137b-289a-424f-8fcf-dfefb74563c7",
   "metadata": {},
   "source": [
    "## Convirtiendo nuestro modelo a una demo\n",
    "\n",
    "onvertir un modelo en una demostración te ayuda a compartirlo con otros para que puedan probarlo.\n",
    "\n",
    "Y potencialmente puede ofrecer algunas ideas sobre cómo mejorar tu modelo.\n",
    "\n",
    "Vamos a crear una demostración de un modelo de aprendizaje automático con Gradio.\n",
    "\n",
    "Gradio ayuda a crear el flujo de trabajo: entradas -> Modelo de Aprendizaje Automático -> salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3616f71-c1c9-4e81-8335-94aaae121da3",
   "metadata": {},
   "source": [
    "### Creamos una función para realizar inferencias\n",
    "\n",
    "1. Tomamos un input tipo string\n",
    "2. Configuramos un pipeline de clasificación de texto\n",
    "3. Tomamos el output del pipeline\n",
    "4. Devolvemos la salida del pipeline en el paso 3 como un diccionario formateado con el siguiente formato:\n",
    "   `{\"label_1\": probability_1, \"label_2\": probability_2,...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8eb5cd57-c96e-4e0e-88e0-800d023b2247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_food': 0.9996128678321838, 'food': 0.0003871637745760381}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# 1. Creamos una función para tomar el string input\n",
    "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
    "    # 2. Seteamos el food not food classifier\n",
    "    food_not_food_classifier_pipeline = pipeline(task=\"text-classification\",\n",
    "                                        model=\"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\",\n",
    "                                        batch_size=32,\n",
    "                                        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                        top_k=None) # top_k=None => return all possible labels\n",
    "\n",
    "    # 3. Tomamos el output del pipeline\n",
    "    outputs = food_not_food_classifier_pipeline(text)[0]\n",
    "\n",
    "    # 4. Formateamos el output para Gradio\n",
    "    output_dict = {}\n",
    "    for item in outputs:\n",
    "        output_dict[item['label']]=item['score']\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "food_not_food_classifier(text=\"We're building a local demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cecc3-ef07-4e65-98d2-eb397d7b5ed1",
   "metadata": {},
   "source": [
    "### Construyendo una pequeña demo Grado que corra en forma local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90e8a608-edf1-418d-b454-013c11f5237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import gradio\n",
    "import gradio as gr\n",
    "\n",
    "# 2. Create a gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=food_not_food_classifier,\n",
    "    inputs=\"text\",\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"Food not food classifier\",\n",
    "    description=\"A text classifier to determine if a sentence is about food or not\",\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error\"],\n",
    "              [\"A plate of pancakes and strawberry icing\"]])\n",
    "\n",
    "# 3. Launch the interface\n",
    "demo.launch()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d54fd-640d-4647-8a5f-b9bbc3ff2737",
   "metadata": {},
   "source": [
    "### Haciendo nuestra demo accesible públicamente\n",
    "\n",
    "Existen 2 formas principales de hacer nuestra demo accesible públicamente con Hugging Face Space:\n",
    "1. Manualmente - Podemos ir a hugginface.co/spaces -> \"Crear nuevo espacio\" -> agregar nuestros archivos y ¡publicar!\n",
    "2. Programáticamente - Podemos usar la API de Python de Hugging Face Hub y agregar nuestros archivos a un Space con código.\n",
    "\n",
    "Para crear un espacio programáticamente necesitaremos 3 archivos:\n",
    "1. `app.py` - Esta es la aplicación principal con la funcionalidad de nuestra demo.\n",
    "2. `requirements.txt` - Estas son las dependencias que nuestra aplicación necesitará.\n",
    "3. `README.md` - Esto explicará de qué trata nuestro proyecto/demo. También añadirá algunos metadatos en formato YAML.\n",
    "\n",
    "Para crear estos usaremos la siguiente estructura:\n",
    "\n",
    "```\n",
    "demos/\n",
    "└── food_not_food_text_classifier/\n",
    "    ├── app.py\n",
    "    ├── README.md\n",
    "    └── requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e6a8b-a12e-432f-8623-2a38bc174e39",
   "metadata": {},
   "source": [
    "#### Creando una carpeta para guardar la demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dc6395a-7c1b-4edd-80de-bb5ddd72e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Make directory for demos\n",
    "demos_dir = Path(\"./demos\")\n",
    "demos_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a folder for the food_not_food_text_classifier demo\n",
    "food_not_food_text_classifier_demo_dir = Path(demos_dir, \"food_not_food_text_classifier\")\n",
    "food_not_food_text_classifier_demo_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e33d26-be3e-462c-aa5b-293896a8b2cc",
   "metadata": {},
   "source": [
    "#### Creando un archivo app.py\n",
    "\n",
    "Nuestro `app.py` contendrá la lógica principal de nuestra aplicación para ejecutarse.\n",
    "\n",
    "Cuando subimos a Hugging Face Spaces, Spaces intentará ejecutar `app.py` automáticamente.\n",
    "\n",
    "En nuestro archivo `app.py` queremos:\n",
    "1. Importar los paquetes\n",
    "2. Definir nuestra función para usar nuestro modelo (esto funcionará con Gradio)\n",
    "3. Crear una demo con Gradio\n",
    "4. Ejecutar la demo con `demo.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "820e7559-fb55-444d-b255-944a301df27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/app.py\n",
    "# 1. Importamos las librerías necesarias\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "from typing import Dict\n",
    "from transformers import pipeline\n",
    "\n",
    "# 2. Deifnimos nuestra función para usar el modelo\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=\"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\",\n",
    "                                    top_k=1,\n",
    "                                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                    batch_size=32)\n",
    "\n",
    "def classify_text(text):\n",
    "    # Usa el clasificador\n",
    "    result = food_not_food_classifier(text)\n",
    "    # Ahora accedemos al primer diccionario en la primera lista\n",
    "    return result[0][0]['label'], result[0][0]['score']\n",
    "    \n",
    "\n",
    "# 3. Create a Gradio interface\n",
    "description = \"\"\"\n",
    "A text classifier to determine if a sentence is about food or not food. \n",
    "\n",
    "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [small dataset of food and not food text](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "See [source code](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb).\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn = classify_text,\n",
    "    inputs = \"text\",\n",
    "    outputs=[gr.Label(num_top_classes=2), gr.Textbox()],\n",
    "    title=\"🍗🚫🥑 Food or Not Food Text Classifier\",\n",
    "    description=description,\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error.\"],\n",
    "                       [\"A delicious photo of a plate of scrambled eggs, bacon and toast.\"]])\n",
    "\n",
    "\n",
    "# 4. Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f87f0-65ab-49b3-990f-e3e7a3c93be2",
   "metadata": {},
   "source": [
    "#### Creando a README file\n",
    "\n",
    "Este archivo está en formato Markdown.  \n",
    "Con un bloque YAML en la parte superior.  \n",
    "El bloque YAML en la parte superior se utiliza para los metadatos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a6e53391-e9ee-4df1-9529-f0c2951db306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/README.md\n",
    "---\n",
    "title: Food Not Food Text Classifier\n",
    "emoji: 🍗🚫🥑\n",
    "colorFrom: blue\n",
    "colorTo: yellow\n",
    "sdk: gradio\n",
    "app_file: app.py\n",
    "pinned: false\n",
    "license: apache-2.0\n",
    "---\n",
    "\n",
    "# 🍗🚫🥑 Food Not Food Text Classifier\n",
    "\n",
    "Small demo to showcase a text classifier to determine if a sentence is about food or not food.\n",
    "\n",
    "DistillBERT model fine-tuned on a small synthetic dataset of 250 generated [Food or Not Food image captions](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "[Source code notebook](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf1523-be75-48c9-ae87-48a12511d26c",
   "metadata": {},
   "source": [
    "#### Creando un requirements file\n",
    "\n",
    "Este archivo le indicará a nuestro Hugging Face Space qué versiones/paquetes utilizar.\n",
    "\n",
    "Si no creamos este archivo, podríamos obtener un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11327b72-bb2c-4429-b65a-b7535c925d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/requirements.txt\n",
    "gradio\n",
    "torch\n",
    "transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a4af7-8216-4880-94e7-73bce53c77cb",
   "metadata": {},
   "source": [
    "#### Subiendo nuestra demo a Hugging Face Spaces\n",
    "\n",
    "Para hacerlo, utilizaremos la API de Python de Hugging Face Hub.\n",
    "\n",
    "Para subir nuestra demo a HF Spaces, podemos hacer lo siguiente:\n",
    "1. Importar las funciones necesarias\n",
    "2. Definir lo que queremos subir + los nombres de los archivos\n",
    "3. Crear el repositorio\n",
    "4. Obtener el nombre de nuestro repositorio de nuestra carga\n",
    "5. Subir el contenido de nuestro `./demos/food_not_food_classifier/` a nuestro Hugging Face\n",
    "6. Esperar que todo funcione e inspeccionar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d8d943db-efe8-4905-9805-3c9ff3fffef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "880bcef3-114a-4c09-ab7f-06b71bd1529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creando repo en Hugging Face Hub con nombre: learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Nombre completo del repositorio en HF: tonicanada/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Subiendo ./demos/food_not_food_text_classifier/ al repo tonicanada/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Demo folder se ha subido con éxito, esta es la commit url: https://huggingface.co/spaces/tonicanada/learn_hf_food_not_food_text_classifier_demo/tree/main/.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import (\n",
    "    create_repo,\n",
    "    get_full_repo_name,\n",
    "    upload_file,\n",
    "    upload_folder\n",
    ")\n",
    "\n",
    "# Define los parámetros que nos gustaría usar para subir nuestro Space\n",
    "LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD = \"./demos/food_not_food_text_classifier/\"\n",
    "HF_TARGET_SPACE_NAME = \"learn_hf_food_not_food_text_classifier_demo\"\n",
    "HF_REPO_TYPE = \"space\"\n",
    "HF_SPACE_SDK = \"gradio\"\n",
    "\n",
    "# Crea a Space repo on Hugging Face Hub\n",
    "print(f\"[INFO] Creando repo en Hugging Face Hub con nombre: {HF_TARGET_SPACE_NAME}\")\n",
    "create_repo(\n",
    "    repo_id=HF_TARGET_SPACE_NAME,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    repo_type = HF_REPO_TYPE,\n",
    "    private=False,\n",
    "    space_sdk=HF_SPACE_SDK,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# Obtener el nombre completo del repo (e.g. {username}/{repo_name})\n",
    "hf_full_repo_name = get_full_repo_name(model_id=HF_TARGET_SPACE_NAME)\n",
    "print(f\"[INFO] Nombre completo del repositorio en HF: {hf_full_repo_name}\")\n",
    "\n",
    "# Subiendo el demo folder\n",
    "print(f\"[INFO] Subiendo {LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD} al repo {hf_full_repo_name}\")\n",
    "folder_upload_url = upload_folder(\n",
    "    repo_id=hf_full_repo_name,\n",
    "    folder_path=LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,\n",
    "    path_in_repo=\".\",\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    repo_type=HF_REPO_TYPE,\n",
    "    commit_message=\"Uploading our food not food classifier demo from a notebook!\"\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Demo folder se ha subido con éxito, esta es la commit url: {folder_upload_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf35b7-100b-43cf-9d51-2969e97b030a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
