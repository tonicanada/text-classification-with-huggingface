{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89543d37-1e0d-4c60-b94c-9a3409670f78",
   "metadata": {},
   "source": [
    "# Tutorial proyecto de clasificaci√≥n de texto mediante Hugging Face (2 clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7de98-8123-4149-8878-35ca5d202a36",
   "metadata": {},
   "source": [
    "## ¬øQu√© vamos a construir?\n",
    "\n",
    "Bienvenido al tutorial del proyecto de clasificaci√≥n de texto mediante Hugging Face. Este notebook est√° dise√±ado para que pueda ser reutilizable para otros casos.\n",
    "En concreto, vamos a construir un modelo que, a partir de una frase en ingl√©s, va a determinar si se trata de comida o no (`food` o `not_food`). Para hacerlo, vamos a partir de un modelo ya existente en Hugging Face Hub, y lo vamos a adaptar a nuestras necesidades. Estos son los pasos que vamos a seguir:\n",
    "1. Datos: Definici√≥n del problema y adaptaci√≥n de los datos\n",
    "2. Modelo: Entrenamiento y evaluaci√≥n de modelo adecuado para nuestro problema.\n",
    "3. Demo: Vamos a crear una web p√∫blica donde cualquier persona podr√° usar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c1dec-4a7a-46e5-993b-599dcc9965bc",
   "metadata": {},
   "source": [
    "## ¬øQu√© ventajas tiene aplicar esta t√©cnica?\n",
    "Utilizar un modelo previamente entrenado y adaptarlo a nuestras necesidades espec√≠ficas puede ser una estrategia muy beneficiosa. Existen muchos modelos disponibles, por ejemplo, en Hugging Face Hub, y podemos ajustarlos con una peque√±a cantidad de datos para que cumplan con nuestras necesidades concretas.\n",
    "\n",
    "Estos modelos suelen ser relativamente ligeros en t√©rminos de tama√±o, pero mantienen un alto grado de precisi√≥n, lo que los hace muy √∫tiles para una amplia variedad de aplicaciones. Al ajustar un modelo, podemos implementarlo de forma eficiente en nuestro equipo local o en un servidor, integr√°ndolo como una parte fundamental de una aplicaci√≥n m√°s amplia. Esta flexibilidad permite optimizar recursos y reducir significativamente el tiempo de desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec05865-dcbd-4d0e-8252-735426b2fbef",
   "metadata": {},
   "source": [
    "## Obtenci√≥n y tratamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c40eb-46e4-4931-8807-578e76fc1fc0",
   "metadata": {},
   "source": [
    "### Importaci√≥n de las librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc6e874-4a93-4a52-b745-88359bcc05bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee87b136-48d3-433c-a3f6-d42486753fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acm/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers version: 4.45.2\n",
      "Using torch version: 2.4.1+cu121\n",
      "Using datasets version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "try:\n",
    "    import datasets, evaluate, accelerate, transformers\n",
    "    import gradio as gr\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -U datasets evaluate accelerate gradio transformers\n",
    "    import datasets, evaluate, accelerate\n",
    "    import gradio as gr\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(f\"Using transformers version: {transformers.__version__}\")\n",
    "print(f\"Using torch version: {torch.__version__}\")\n",
    "print(f\"Using datasets version: {datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd66b7-7617-4b8c-be67-f8861860ab96",
   "metadata": {},
   "source": [
    "### Obtenci√≥n de un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69f3d2f-8c65-44a7-bc30-37cef956c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path='mrdbourke/learn_hf_food_not_food_image_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e35d78-24e6-4e9d-acc5-a7f5f8460b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92a9eae-0773-4e53-98fb-a264505ee561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C√≥mo son los datos?\n",
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17532330-83d2-4fe0-8424-a33874d2bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accedemos al set de entrenamiento\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1672fd50-0a8b-4270-8033-581ca809becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       " 'label': 'food'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254752a-8a14-46c1-b676-1097f84546d3",
   "metadata": {},
   "source": [
    "### Inspeccionamos ejemplos random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a347671-c2ec-4322-967a-9da207cc34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random samples from dataset:\n",
      "\n",
      "Text: Jicama in a bowl, sprinkled with chili powder and served with a side of lime wedges for a refreshing snack. | Label: food\n",
      "Text: Set of tea towels folded in a kitchen | Label: not_food\n",
      "Text: Creamy spinach and potato curry, featuring fluffy potatoes and nutritious spinach in a rich sauce with cream and garam masala. | Label: food\n",
      "Text: Set of candles lit on a table | Label: not_food\n",
      "Text: Flat screen TV neatly mounted on a wall | Label: not_food\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_indexs = random.sample(range(len(dataset['train'])), 5)\n",
    "random_indexs\n",
    "\n",
    "random_samples = dataset['train'][random_indexs]\n",
    "print(f\"[INFO] Random samples from dataset:\\n\")\n",
    "for text, label in zip(random_samples['text'], random_samples['label']):\n",
    "    print(f\"Text: {text} | Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb874a1d-14cc-4c0a-ade5-ecead31a437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food', 'not_food']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los valores √∫nicos de las etiquetas\n",
    "dataset['train'].unique('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86818bac-a8c8-4663-bfc0-0d79e7f55234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'food': 125, 'not_food': 125})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos la cantidad de frases para cada etiqueta\n",
    "from collections import Counter\n",
    "\n",
    "Counter(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e96fd2-dd48-49a5-a1c0-9c34c7a4b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Uniquely shaped sushi roll, such as a heart or...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Crunchy sushi roll with a creamy filling, feat...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>A gourmet pizza with a pesto base, topped with...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Set of measuring cups nested in a drawer</td>\n",
       "      <td>not_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>A slice of pizza with a spicy buffalo chicken ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Pizza with a unique crust, such as cauliflower...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     label\n",
       "55   Uniquely shaped sushi roll, such as a heart or...      food\n",
       "120  A slice of pepperoni pizza with a layer of mel...      food\n",
       "199  Crunchy sushi roll with a creamy filling, feat...      food\n",
       "140  A gourmet pizza with a pesto base, topped with...      food\n",
       "161           Set of measuring cups nested in a drawer  not_food\n",
       "141  A slice of pizza with a spicy buffalo chicken ...      food\n",
       "216  Pizza with a unique crust, such as cauliflower...      food"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos el dataset en un pandas DataFrame y tomamos una muestra\n",
    "food_not_food_df = pd.DataFrame(dataset['train'])\n",
    "food_not_food_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674e9c79-d723-4f20-9de9-282b387c40c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "food        125\n",
       "not_food    125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea44f1-0398-4d0d-ab67-4c80ddbe297d",
   "metadata": {},
   "source": [
    "### Preparaci√≥n de los datos para la clasificaci√≥n de texto\n",
    "\n",
    "Queremos:\n",
    "1. Tokenizar nuestro texto - convertir texto en n√∫meros (esto aplica para las frases y las etiquetas)\n",
    "2. Crear un train/test split - queremos entrentar nuestro modelo en el training split y evaluarlo en el test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be796f72-0978-4e72-b958-ec290dae501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'not_food', 1: 'food'}\n",
      "{'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "# Crear un mapeo para labels hacia un n√∫mero id\n",
    "id2label ={0: \"not_food\", 1: \"food\"}\n",
    "label2id = {\"not_food\": 0, \"food\":1}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc56334e-0062-48c9-847e-ae1b473fa83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'not_food', 1: 'food'}\n"
     ]
    }
   ],
   "source": [
    "# Creando mappings para labels hacia n√∫meros id de forma autom√°tica (especialmente √∫til cuando se trata de m√°s de 2 clases)\n",
    "id2label = {idx: label for idx, label in enumerate(dataset['train'].unique('label')[::-1])}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83607331-a29c-4080-b84c-7ed2b2356b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not_food': 0, 'food': 1}\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: idx for idx,label in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ea05ae-d0d1-43fc-b1ce-bfcb5007f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'This is a sentence about my favourite food: honey', 'label': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convierte labels en 0 y 1\n",
    "def map_labels_to_number(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "example_sample = {'text': 'This is a sentence about my favourite food: honey', 'label': 'food'}\n",
    "map_labels_to_number(example_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "325eb88e-876c-4bbe-9ca0-1b8399adbeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',\n",
       "  'Set of books stacked on a desk',\n",
       "  'Watching TV together, a family has their dog stretched out on the floor',\n",
       "  'Wooden dresser with a mirror reflecting the room',\n",
       "  'Lawn mower stored in a shed'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapea las labels del dataset entero a n√∫meros  \n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba568fbb-f0af-4c7f-aabd-9295a9fb0510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Set of paintbrushes stored in a jar',\n",
       "  'A close-up of a girl feeding her rabbit in the garden',\n",
       "  'A boy giving his dog a bath in the backyard',\n",
       "  'Set of baking sheets stacked in a cabinet',\n",
       "  'Camping tent pitched in a backyard'],\n",
       " 'label': [0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mezclar datos y observar m√°s muestras aleatorias\n",
    "dataset.shuffle()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06215883-e1ac-4cec-be62-0e330f9fe701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dividir el dataset en training y test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba02086b-8c6f-4d4e-be25-b8944d613414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'A pair of slices from a barbecue chicken pizza', 'label': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx_train = random.randint(0, len(dataset['train']))\n",
    "random_sample_train = dataset['train'][random_idx_train]\n",
    "random_sample_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6deb0988-8ef2-4684-9e34-fc475138516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Comforting lamb curry bowl, featuring tender lamb slow-cooked in a flavorful sauce with cumin and coriander, garnished with toasted cumin seeds.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx_test = random.randint(0, len(dataset['test']))\n",
    "random_sample_test = dataset['test'][random_idx_test]\n",
    "random_sample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c8f11-0354-45a2-9180-5a7dc19650f1",
   "metadata": {},
   "source": [
    "### Tokenizar el texto\n",
    "\n",
    "Consiste b√°sicamente en transformar texto a n√∫meros. Es importante tomar el mismo `tokenizer` con el que los datos fueron entrenados. En nuestro caso, vamos a usar el tokenizer del modelo `distilbert/distilbert-base-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988a315d-4269-4fa0-a19c-91a99a3a65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path='distilbert/distilbert-base-uncased',\n",
    "                                         use_fast=True) # Use the fast implementation (on by default)\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e82615b-8e17-4535-8e06-152fc20d10b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el tokenizer\n",
    "tokenizer(\"I love pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bd368-abda-4f78-b528-434f0070d499",
   "metadata": {},
   "source": [
    "* `input_ids` = texto convertido en n√∫meros\n",
    "* `attention_mask` = indica si hay que prestarle atenci√≥n al input o no (1=s√≠ prestar atenci√≥n, 0 = no, no prestar atenci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11962402-4e9b-4b27-90f0-4fe26f3029cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('I love pizza!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c2bf145-6de7-4c8b-87dc-92031942e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tama√±o del vocabulario del tokenizer: 30522 tokens\n",
      "[INFO] Longitud m√°xima de entrada que puede procesar el tokenizer: 512 tokens\n"
     ]
    }
   ],
   "source": [
    "# Calculamos cu√°n largo es el vocabulario del tokenizer escogido\n",
    "length_of_tokenizer_vocab = len(tokenizer.vocab)\n",
    "print(f\"[INFO] Tama√±o del vocabulario del tokenizer: {length_of_tokenizer_vocab} tokens\")\n",
    "\n",
    "# Obtenemos la longitud m√°xima de secuencia que el tokenizer puede manejar\n",
    "max_tokenizer_input_sequence_length = tokenizer.model_max_length\n",
    "print(f\"[INFO] Longitud m√°xima de entrada que puede procesar el tokenizer: {max_tokenizer_input_sequence_length} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f751013-ae3c-4948-b409-cfe16af68bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4980"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Est√° \"antonio\" en el vocabulario? Vemos que s√≠\n",
    "tokenizer.vocab['antonio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4832113a-02ca-4a69-b886-3826f0734740",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'akash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Est√° \"akash\" en el vocabularoi? Vemos que no, da error\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43makash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'akash'"
     ]
    }
   ],
   "source": [
    "# Est√° \"akash\" en el vocabularoi? Vemos que no, da error\n",
    "tokenizer.vocab['akash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "582a153b-e8d5-4103-837b-f90b675b38dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 9875, 4095, 102], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('akash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38037e5-687f-42d5-aa69-faf3b7835d45",
   "metadata": {},
   "source": [
    "Las palabras que no est√°n en el vocabulario del tokenizer igual son procesadas por este. Tal como se puede ver con \"akash\", el tokenizer ha subdividido la palabra en 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7bfbbfc-e472-4a8e-8749-6248b52f2f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'aka', '##sh', '[SEP]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer('akash').input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cff7cc69-9d4c-4250-8b1b-3d596fe8cf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[UNK]', '[SEP]']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intentamos tokenizar un emoji\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(\"üòÜ\").input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76f82d0c-9fa4-4e8b-8f45-49a45361c103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 999), ('\"', 1000), ('#', 1001), ('##!', 29612), ('##\"', 29613)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomamos los 5 primeros items del vocabulario\n",
    "sorted(tokenizer.vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a836c6c-26ef-4293-873d-d7d771036849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guarantees', 21586),\n",
       " ('drummond', 19266),\n",
       " ('##watch', 18866),\n",
       " ('regretted', 18991),\n",
       " ('what', 2054)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(sorted(tokenizer.vocab.items()), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20525fda-1e06-4b16-a13a-535e5f88f383",
   "metadata": {},
   "source": [
    "### Creamos una funci√≥n para tokenizar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93f9aa50-d937-4459-8b82-6202a255c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(ejemplos):\n",
    "    \"\"\"\n",
    "    Tokeniza el texto del ejemplo dado y devuelve el texto tokenizado.\n",
    "    \"\"\"\n",
    "    return tokenizer(ejemplos['text'],\n",
    "                    padding=True,  # rellena las secuencias cortas al tama√±o de la secuencia m√°s larga en el lote\n",
    "                    truncation=True)  # trunca las secuencias largas a la longitud m√°xima que el modelo puede procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99a52a21-e855-4d56-8b3f-e74b12a70c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sample_2 = {\"text\": \"I love pizza\", \"label\": 1}\n",
    "\n",
    "# Probamos la funci√≥n\n",
    "tokenize_text(example_sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c923abf6-9ab6-465e-b761-c5be3f072ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = \"I love pizza \" * 1000\n",
    "long_text\n",
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9086a263-c417-46eb-a8b2-09186bb1195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_long_text = tokenize_text({\"text\": long_text, \"label\": 1})\n",
    "len(tokenized_long_text['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44e9a26c-6280-4fd4-a14b-267f3b5831a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae742455-02ae-4df3-8995-7b5e2c81b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 21305.48 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 9143.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Mapeamos la funci√≥n tokenizer a todo el dataset\n",
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True, # set batched=True to tokenize across batches of samples at a time\n",
    "                                batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d95f422-d632-4c7f-a89c-42f30c84a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Key: text\n",
      "Train sample: Set of headphones placed on a desk\n",
      "Test sample: A slice of pepperoni pizza with a layer of melted cheese\n",
      "\n",
      "[INFO] Key: label\n",
      "Train sample: 0\n",
      "Test sample: 1\n",
      "\n",
      "[INFO] Key: input_ids\n",
      "Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[INFO] Key: attention_mask\n",
      "Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tomamos 2 ejemplos\n",
    "train_tokenized_sample = tokenized_dataset['train'][0]\n",
    "test_tokenized_sample = tokenized_dataset['test'][0]\n",
    "\n",
    "for key in train_tokenized_sample.keys():\n",
    "    print(f\"[INFO] Key: {key}\")\n",
    "    print(f\"Train sample: {train_tokenized_sample[key]}\")\n",
    "    print(f\"Test sample: {test_tokenized_sample[key]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12b7a0-56f3-45a8-9fbc-4ce9ece1218a",
   "metadata": {},
   "source": [
    "### Puntos claves sobre la tokenizaci√≥n\n",
    "1. Tokenizers = Convertir datos en n√∫meros\n",
    "2. Hay muchos modelos disponibles con diferentes tokenizers; las herramientas `Auto` de Hugging Face (por ejemplo, `AutoTokenizer`, `AutoProcessor`, `AutoModel`, etc.) ayudan a emparejar tokenizers con los modelos correctos.\n",
    "3. Tokenizaci√≥n se puede hacer en paralelo usando funciones como `map` y en lotes (`batched`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbb9b1-64be-408a-927d-c78b4368e099",
   "metadata": {},
   "source": [
    "## Preparaci√≥n del modelo\n",
    "\n",
    "Antes de configurar el modelo, debemos definir tambi√©n c√≥mo se medir√° cu√°n buenas han sido las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68743221-1b77-41ba-8b18-ede891e4be6f",
   "metadata": {},
   "source": [
    "### Seteando una m√©trica de evaluaci√≥n\n",
    "\n",
    "Queremos escoger una m√©trica de evaluaci√≥n que nos permita tener una idea n√∫merica de cu√°n bien nuestro modelo est√° funcionando.\n",
    "\n",
    "Algunas m√©tricas de evaluaci√≥n comunes son:\n",
    "- \n",
    "\n",
    "Some common evaluation metrics for classification:\n",
    "- Exactitud (Accuracy) (Cu√°ntos ejemplos de cada 100 se clasificaron bien?)\n",
    "- Precisi√≥n (Precision)\n",
    "- Sensibilidad o Exhaustividad (Recall)\n",
    "- F1 Score\n",
    "\n",
    "La m√©trica de evaluaci√≥n es importante porque en algunos proyectos puede haber alg√∫n m√≠nimo que cumplir\n",
    "\n",
    "Algun formas para encontrar m√©tricas de evaluaci√≥n:\n",
    "- Scikit evaluation\n",
    "- Hugging Face evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f42ff83-7953-440a-8800-cacc2ae76d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./env/lib/python3.11/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33849724-0719-48bf-a4f9-b97d703c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a model by comparing the predictions and labels.\n",
    "    \"\"\"\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    if len(predictions.shape) >= 2:\n",
    "        # need to get the maximum value from the model output (the index) as this is the \"most likely\" label according to the model\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58d6f673-a54c-436e-a41a-d310b2596c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when all predictions are correct: {'accuracy': 1.0}\n",
      "Accuracy when all one prediction is correct: {'accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de predicciones y de la m√©trica de exactitud\n",
    "example_preds_all_correct = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "example_preds_one_incorrect = np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "example_labels = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "# Test the function\n",
    "print(f\"Accuracy when all predictions are correct: {compute_accuracy((example_preds_all_correct, example_labels))}\")\n",
    "print(f\"Accuracy when all one prediction is correct: {compute_accuracy((example_preds_one_incorrect, example_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029a7d-dff6-458d-9ab2-1cd8892f43f0",
   "metadata": {},
   "source": [
    "### Seteamos un modelo para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92665719-bbcb-4e24-80a8-2523ca933b81",
   "metadata": {},
   "source": [
    "Flujo de trabajo:\n",
    "1. Crear y preprocesar los datos (hecho)\n",
    "2. Definir el modelo que nos gustar√≠a usar para nuestro problema (huggingface/models) o consultar las \"gu√≠as de tareas\" en la documentaci√≥n de HF Transformers\n",
    "3. Definir los argumentos de entrenamiento para entrenar nuestro modelo `transformers.TrainingArguments`\n",
    "4. Pasar los `TrainingArguments` a una instancia de `transformer.Trainer`\n",
    "5. Entrenar el modelo llamando a `Trainer.train()`\n",
    "6. Guardar nuestro modelo (en nuestra m√°quina local o en el Hugging Face Hub)\n",
    "7. Evaluar el modelo entrenado realizando y examinando predicciones sobre los datos de prueba\n",
    "8. Convertir el modelo en una demostraci√≥n compartible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23079802-848b-4baa-a88f-3df814401821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = 'distilbert/distilbert-base-uncased',\n",
    "    num_labels=2, # Classify into food, not food\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ea622f0-d46a-44b8-879f-e9ef8cc20252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f19a7-9457-40af-8fc5-e4b8a0c672c1",
   "metadata": {},
   "source": [
    "Nuestro modelo se compone de las siguientes partes:\n",
    "1. `embeddings` - los embeddings son una forma de representaci√≥n aprendida de los tokens. As√≠ que, si los tokens son un mapeo directo de token a n√∫mero, los embeddings son una representaci√≥n vectorial aprendida.\n",
    "2. `transformer` - la columna vertebral de nuestra arquitectura de modelo, que ha descubierto patrones/relaciones en los embeddings.\n",
    "3. `classifier` - necesitamos personalizar esta capa para adaptarla a nuestro problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45a95bc8-188d-47f8-97ae-0aa0ad9f79fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Set of headphones placed on a desk',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  2275,\n",
       "  1997,\n",
       "  2132,\n",
       "  19093,\n",
       "  2872,\n",
       "  2006,\n",
       "  1037,\n",
       "  4624,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652caae-7446-4d50-a50f-23345ea97158",
   "metadata": {},
   "source": [
    "Nota: Si obtienes errores de entrada al pasar una muestra a un modelo, aseg√∫rate de que la muestra que le pasas al modelo est√© en el mismo formato en el que fue entrenado. Por ejemplo, si tu modelo us√≥ un tokenizer espec√≠fico, aseg√∫rate de tokenizar tu texto antes de pasarlo al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f6733fe-f846-441c-a578-87a2e9148ebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m     \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:883\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    881\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 883\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    893\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/ztm_courses/ztm-huggingface/env/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:684\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m--> 684\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model(input_ids=tokenized_dataset['train'][0]['input_ids'],\n",
    "     attention_mask=tokenized_dataset['train'][0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20541d5-fc5d-4b19-b462-0063e548f4b1",
   "metadata": {},
   "source": [
    "### Contando los par√°metros en nuestro modelo\n",
    "\n",
    "Pesos/par√°metros = peque√±as oportunidades num√©ricas para que un modelo aprenda patrones en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "116cb8ee-c50c-4323-9964-24ab4cdb44fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainable_parameters': 66955010, 'total_parameters': 66955010}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    \"\"\"\n",
    "    Count the parameters of a PyTorch model.\n",
    "    \"\"\"\n",
    "    trainable_parameters = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "    total_parameters = sum(param.numel() for param in model.parameters())\n",
    "\n",
    "    return {\"trainable_parameters\": trainable_parameters, \"total_parameters\": total_parameters}\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73e05e-bae2-43e1-892c-ac369edc9d12",
   "metadata": {},
   "source": [
    "Parece que nuestro modelo tiene alrededor de 67 millones de par√°metros y todos son entrenables\n",
    "\n",
    "Nota:\n",
    "\n",
    "* En general, cuantos m√°s par√°metros tenga un modelo, mayor capacidad tendr√° para aprender.\n",
    "* Para ponerlo en perspectiva, modelos como Llama3 8B tienen 8 mil millones de par√°metros.\n",
    "* Si buscas el mejor rendimiento posible, generalmente m√°s par√°metros es mejor.\n",
    "* Sin embargo, con m√°s par√°metros se requiere m√°s capacidad de c√≥mputo y tiempo.\n",
    "* Te sorprender√° lo bien que puede funcionar un modelo m√°s peque√±o con datos espec√≠ficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2c5da74-1c53-4cf0-abac-6928caac0d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.40298507462687"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8_000_000_000/67_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53e0b1-88f1-4cc9-a651-c3bfbfbd4dd4",
   "metadata": {},
   "source": [
    "### Creando un directorio para guardar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbb30ddd-d4d2-4303-91aa-285452a51a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un directorio para guardar los modelos\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models dir\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create model save name\n",
    "model_save_name = \"learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# Create model save path\n",
    "model_save_dir = Path(models_dir, model_save_name)\n",
    "\n",
    "model_save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7416178-cdba-499f-9d7b-1a7e3aa72b5e",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de los argumentos de entrenamiento (hiperpar√°metros) con TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c2a8c8c-eb77-4c31-be1a-148b81e2a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Guardando checkpoints del modelo: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "print(f\"[INFO] Guardando checkpoints del modelo: {model_save_dir}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create training arguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    # push_to_hub=True\n",
    "    hub_private_repo=False #When uploading to Hugging Face, do you want your model to be private or public (default public)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad5b5d7b-2812-4203-aef3-317d94c83df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/runs/Nov13_22-55-21_acm-msi,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.EPOCH,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=10,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=32,\n",
       "per_device_train_batch_size=32,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=3,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e791a-5b89-43df-b531-f5714dbda625",
   "metadata": {},
   "source": [
    "### Seteando una instancia de Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5d0f9f6-c1b3-48a3-b613-3832042a6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x75207dbcf750>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Setup Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bcb75-a83f-4575-be76-941dc5f8cb17",
   "metadata": {},
   "source": [
    "### ¬°Entrenamos el modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f8913e6-93c9-4273-bac7-2e5540b66201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.107463</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df7d395f-d197-4483-91ba-7f86eb699bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_runtime: 16.3294\n",
      "train_samples_per_second: 122.479\n",
      "train_steps_per_second: 4.287\n",
      "total_flos: 18110777160000.0\n",
      "train_loss: 0.04557784213019269\n",
      "epoch: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionamos las m√©tricas del modelo\n",
    "for key, value in results.metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509820-84c7-4021-93fd-26ee5e65ea86",
   "metadata": {},
   "source": [
    "### Guardamos el modelo para poder usarlo posteriormente\n",
    "\n",
    "**Nota**: Si est√°s guardando el modelo en Google Colab, ten en cuenta que desaparecer√° de tu instancia de Colab cuando se desconecte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a23c1e90-33af-4330-9ada-50d00315388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "print(f\"[INFO] Saving model to {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e5519-9eb7-4cb0-a076-c28a5956c0b3",
   "metadata": {},
   "source": [
    "## Inspeccionamos las m√©tricas del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54bbcbbb-6da4-46d2-9f8a-324862a48e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3992,\n",
       "  'grad_norm': 1.7019474506378174,\n",
       "  'learning_rate': 9e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 0.10746302455663681,\n",
       "  'eval_accuracy': 0.98,\n",
       "  'eval_runtime': 0.0429,\n",
       "  'eval_samples_per_second': 1164.657,\n",
       "  'eval_steps_per_second': 46.586,\n",
       "  'epoch': 1.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.0441,\n",
       "  'grad_norm': 0.14603981375694275,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 14}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos la historia del entrenamiento\n",
    "trainer_history_all = trainer.state.log_history\n",
    "trainer_history_metrics = trainer_history_all[:-1]\n",
    "trainer_history_training_time = trainer_history_all[-1]\n",
    "\n",
    "# Vemos las primeras 3\n",
    "trainer_history_metrics[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d22f9a52-beda-4ff3-96c3-fdf551beac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 2 en training set:\n",
      "[{'epoch': 1.0,\n",
      "  'grad_norm': 1.7019474506378174,\n",
      "  'learning_rate': 9e-05,\n",
      "  'loss': 0.3992,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'grad_norm': 0.14603981375694275,\n",
      "  'learning_rate': 8e-05,\n",
      "  'loss': 0.0441,\n",
      "  'step': 14}]\n",
      "\n",
      "Primeros 2 en eval epochs:\n",
      "[{'epoch': 1.0,\n",
      "  'eval_accuracy': 0.98,\n",
      "  'eval_loss': 0.10746302455663681,\n",
      "  'eval_runtime': 0.0429,\n",
      "  'eval_samples_per_second': 1164.657,\n",
      "  'eval_steps_per_second': 46.586,\n",
      "  'step': 7},\n",
      " {'epoch': 2.0,\n",
      "  'eval_accuracy': 0.98,\n",
      "  'eval_loss': 0.059366654604673386,\n",
      "  'eval_runtime': 0.0421,\n",
      "  'eval_samples_per_second': 1186.4,\n",
      "  'eval_steps_per_second': 47.456,\n",
      "  'step': 14}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Extraemos las m√©tricas eval y training\n",
    "trainer_history_training_set = []\n",
    "trainer_history_eval_set = []\n",
    "\n",
    "# Loop a trav√©s de las m√©tricas\n",
    "for item in trainer_history_metrics:\n",
    "    item_keys = list(item.keys())\n",
    "    if any(\"eval\" in item for item in item_keys):\n",
    "        trainer_history_eval_set.append(item)\n",
    "    else:\n",
    "        trainer_history_training_set.append(item)\n",
    "\n",
    "# Mostramos los 2 primeros de cada uno\n",
    "print(f\"Primeros 2 en training set:\")\n",
    "pprint.pprint(trainer_history_training_set[:2])\n",
    "\n",
    "print(f\"\\nPrimeros 2 en eval epochs:\")\n",
    "pprint.pprint(trainer_history_eval_set[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff569d-8fc8-4563-bee5-f23c9ee6ac36",
   "metadata": {},
   "source": [
    "### Revisando las `loss curves`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a351d42f-d94f-43f2-b188-26f41fd67009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3992</td>\n",
       "      <td>1.701947</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.146040</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.046152</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate  epoch  step\n",
       "0  0.3992   1.701947        0.00009    1.0     7\n",
       "1  0.0441   0.146040        0.00008    2.0    14\n",
       "2  0.0059   0.046152        0.00007    3.0    21\n",
       "3  0.0019   0.022477        0.00006    4.0    28\n",
       "4  0.0012   0.019875        0.00005    5.0    35"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un pandas DataFrame para training y evaluation metrics\n",
    "trainer_history_train_df = pd.DataFrame(trainer_history_training_set)\n",
    "trainer_history_eval_df = pd.DataFrame(trainer_history_eval_set)\n",
    "\n",
    "trainer_history_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0981e67e-1e4f-49c3-bc9a-5b0e526186c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./env/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.11/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./env/lib/python3.11/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./env/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "671fced0-e269-4ae9-be8f-5b46164979b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHDklEQVR4nOzdd3hU1dbH8e/MpPfQUiBSAkhNojRBBZVIUAGxAV6Vcm0vYkHAglcpoiKKXFQQBAUR9QpYsF4Qo3hFERAMoCBFKQmQUJOQBNLmvH8kGRiSQPpJ+X2eZx6YM/vss860ZGXvvY7FMAwDERERERERKRer2QGIiIiIiIjUBkquREREREREKoCSKxERERERkQqg5EpERERERKQCKLkSERERERGpAEquREREREREKoCSKxERERERkQqg5EpERERERKQCKLkSERERERGpAEquRC5g9erVWCwWVq9ebVoMFouFSZMmOW3bsGEDPXr0wNvbG4vFQlxcHJMmTcJisZgTZD4zY0hLS+Oee+4hODgYi8XC6NGj2bt3LxaLhXfeeceUmKrSO++8g8ViYe/evWaHUiLDhw+nWbNmFdbfVVddxVVXXeW4X5de+5I69zkqjYp+vaqj6vB9fz5mv6dr2ndMdVPUz3KpfZRcSaWyWCwlulXUD7KDBw8yadIk4uLiKqS/6io7O5vbbruN48eP8+9//5vFixfTtGlTs8My3QsvvMA777zDyJEjWbx4MXfddZfZIfHCCy+wfPlys8OodAVJdcHNy8uLiy66iP79+7Nw4UIyMzMr5Djbtm1j0qRJZf7l7tw4rVYrISEh9OvXj19++aVCYjxbRkYGkyZNKvF3XHnPT6Qi1JXvrcrw9ddfK4Gq41zMDkBqt8WLFzvdf/fdd1m1alWh7W3btq2Q4x08eJDJkyfTrFkzoqKiKqTP6uDUqVO4uJz5uP7111/s27eP+fPnc8899zi2P/300zz55JNmhFgtYvjuu++47LLLmDhxomObYRicOnUKV1dXU2J64YUXuPXWWxk4cGClH+uuu+5iyJAhuLu7V/qxijNnzhx8fHzIzMzkwIEDrFy5kn/+85/MnDmTL7/8krCwMEfb+fPnY7fbS9X/tm3bmDx5MldddVWhUZRvvvmm1HHa7Xbi4+OZP38+PXv2ZP369RX63ZGRkcHkyZMBSjRidL7zqwileY7OVZbXS2qm4r63qsN3THX39ddfM3v27CITrHN/lkvtpFdYKtWdd97pdP+XX35h1apVhbbL+Xl4eDjdP3z4MAABAQFO211cXEz/4jYzhsOHD9OuXTunbRaLpdDzV1vZbDZsNpupMdx66600aNDAcX/ChAm8//77DB06lNtuu81pdKiiE143N7cyxzlw4EA6dOjAsmXLKiS5stvtZGVllbuf8zEMg9OnT+Pp6VnifUrzHJ3LrD9QSPVRHb5jqoOMjAy8vLxKvV9d+VlU12laoJjObrczc+ZM2rdvj4eHB0FBQdx///2cOHHC0WbixIlYrVZiY2Od9r3vvvtwc3Nj8+bNrF69mi5dugAwYsQIx7SfC81NP3DgAHfffTehoaG4u7vTvHlzRo4ced5fjH788Uduu+02LrroItzd3QkLC+PRRx/l1KlTTu0SExMZMWIETZo0wd3dnZCQEG688UanKT+//vorMTExNGjQAE9PT5o3b84///lPp37Onqc9fPhwevXqBcBtt92GxWJx/EW8uPVO7733Hl27dsXLy4vAwEB69uzp9Bfszz77jBtuuMHxHISHhzNlyhRyc3ML9bVu3Tquv/56AgMD8fb2JiIigldffdXxeFEx5OTkMGXKFMLDw3F3d6dZs2Y89dRThaaKNWvWjH79+rFmzRq6du2Kh4cHLVq04N133y3mlchTsE5iz549fPXVV47Xfu/evUWuURg+fDg+Pj4cOHCAgQMH4uPjQ8OGDRk3blyhcy7J+7M4FouF9PR0Fi1a5Ihp+PDhjhiKGpko6vmzWCw8+OCDLF++nA4dOuDu7k779u1ZsWKFU7ui1kOU5jndsmULvXr1wtPTkyZNmvDcc8+xcOHCcq+xuOOOO7jnnntYt24dq1atcmwv6jn48MMP6dSpE76+vvj5+dGxY0fH++udd97htttuA+Dqq68uNK24POuJgoODAQr9YSAzM5OJEyfSsmVLx2f98ccfL/TeLXiN3n//fdq3b4+7uztz586lYcOGAEyePNkRb3FThi50fgWv5cqVK+ncuTOenp68+eabACxcuJBrrrmGRo0a4e7uTrt27ZgzZ06hY5z7HBV8dpYuXcrzzz9PkyZN8PDwoHfv3uzevdtp33Nfr4LP1vTp05k3b57j892lSxc2bNhQ6NjLli2jXbt2eHh40KFDBz799NMSr+Mq6XfUVVddRYcOHdi2bRtXX301Xl5eNG7cmJdeeqlQnwkJCQwcOBBvb28aNWrEo48+WqrpqwcOHOCf//wnQUFBjs/kggULHI8nJSXh4uLiGLk8244dO7BYLMyaNQuA48ePM27cODp27IiPjw9+fn5cd911bN68+YJxFPe+L+q5nT59Oj169KB+/fp4enrSqVMnPvroI6c25/veKm7N1RtvvOF434eGhjJq1CiSk5MLxVnS16YoJfk50q9fP1q0aFHk/t27d6dz585O29577z06deqEp6cn9erVY8iQIcTHxxcZ98aNG+nZsydeXl489dRTRR5j+PDhzJ49G3BeFlHg3M9/wff9zp07ufPOO/H396dhw4Y888wzGIZBfHw8N954I35+fgQHB/PKK68UOmZJv6Ok6mjkSkx3//3388477zBixAgefvhh9uzZw6xZs/jtt9/46aefcHV15emnn+aLL77g7rvvZuvWrfj6+rJy5Urmz5/PlClTiIyMJCkpiWeffZYJEyZw3333ceWVVwLQo0ePYo998OBBunbtSnJyMvfddx9t2rThwIEDfPTRR2RkZBT7V95ly5aRkZHByJEjqV+/PuvXr+f1118nISGBZcuWOdrdcsst/PHHHzz00EM0a9aMw4cPs2rVKvbv3++436dPHxo2bMiTTz5JQEAAe/fu5ZNPPjnv89W4cWNeeOEFHn74Ybp06UJQUFCx7SdPnsykSZPo0aMHzz77LG5ubqxbt47vvvuOPn36AHk/MH18fBgzZgw+Pj589913TJgwgdTUVF5++WVHX6tWraJfv36EhITwyCOPEBwczPbt2/nyyy955JFHio3hnnvuYdGiRdx6662MHTuWdevWMXXqVLZv386nn37q1Hb37t3ceuut3H333QwbNowFCxYwfPhwOnXqRPv27Yvsv23btixevJhHH32UJk2aMHbsWAAaNmzIkSNHitwnNzeXmJgYunXrxvTp0/n222955ZVXCA8PZ+TIkU7P94Xen8VZvHgx99xzD127duW+++4DIDw8vNj257NmzRo++eQTHnjgAXx9fXnttde45ZZb2L9/P/Xr1z/vviV5Tg8cOOD4hX78+PF4e3vz1ltvVdj0n7vuuot58+bxzTffcO211xbZZtWqVdx+++307t2badOmAbB9+3Z++uknHnnkEXr27MnDDz/Ma6+9xlNPPeWYTlyWacXHjx8H8pLnAwcOMGXKFDw8PBg0aJCjjd1uZ8CAAaxZs4b77ruPtm3bsnXrVv7973+zc+fOQmtSvvvuO5YuXcqDDz5IgwYNiIyMZM6cOYwcOZKbbrqJm2++GYCIiIgiYyrJ+e3YsYPbb7+d+++/n3vvvZeLL74YyJvm2L59ewYMGICLiwtffPEFDzzwAHa7nVGjRl3w+XjxxRexWq2MGzeOlJQUXnrpJe644w7WrVt3wX0/+OADTp48yf3334/FYuGll17i5ptv5u+//3Z8Pr766isGDx5Mx44dmTp1KidOnODuu++mcePGF+wfSv4dBXDixAn69u3LzTffzKBBg/joo4944okn6NixI9dddx2QNz2rd+/e7N+/n4cffpjQ0FAWL17Md999V6J4kpKSuOyyyxxJdcOGDfnvf//L3XffTWpqKqNHjyYoKIhevXqxdOlSp6nKAEuWLMFmszmS6b///pvly5dz22230bx5c5KSknjzzTfp1asX27ZtIzQ0tERxXcirr77KgAEDuOOOO8jKyuLDDz/ktttu48svv+SGG24ASv+9NWnSJCZPnkx0dDQjR45kx44dzJkzhw0bNhT6jizJa1OckvwcGTx4MEOHDmXDhg2OP7YC7Nu3j19++cXpvfL888/zzDPPMGjQIO655x6OHDnC66+/Ts+ePfntt9+cZoYcO3aM6667jiFDhnDnnXcW+zP3/vvv5+DBg0UufzifwYMH07ZtW1588UW++uornnvuOerVq8ebb77JNddcw7Rp03j//fcZN24cXbp0oWfPnkDpv6OkihgiVWjUqFHG2W+7H3/80QCM999/36ndihUrCm3funWr4ebmZtxzzz3GiRMnjMaNGxudO3c2srOzHW02bNhgAMbChQtLFM/QoUMNq9VqbNiwodBjdrvdMAzD+P777w3A+P777x2PZWRkFGo/depUw2KxGPv27TMMwzBOnDhhAMbLL79c7PE//fRTAyjy+GcDjIkTJzruF8S0bNkyp3YTJ050en537dplWK1W46abbjJyc3OLPL/izuf+++83vLy8jNOnTxuGYRg5OTlG8+bNjaZNmxonTpwotq9zY4iLizMA45577nHaZ9y4cQZgfPfdd45tTZs2NQDjf//7n2Pb4cOHDXd3d2Ps2LGFYjxX06ZNjRtuuMFp2549ewq9J4YNG2YAxrPPPuvU9pJLLjE6derkuF+a92dxvL29jWHDhhXaPmzYMKNp06aFtp/7/BlG3uvv5uZm7N6927Ft8+bNBmC8/vrrjm0LFy40AGPPnj2ObSV9Th966CHDYrEYv/32m2PbsWPHjHr16hXqsygFcR85cqTIxws+DzfddFOxz8Ejjzxi+Pn5GTk5OcUeZ9myZYU+jwV69epl9OrVy3G/qNe+IM5zbwEBAcaKFSuc+lu8eLFhtVqNH3/80Wn73LlzDcD46aefHNsAw2q1Gn/88YdT2yNHjhT6/J7P+c6v4LU8N07DKPozHBMTY7Ro0cJp27nPUcF3Sdu2bY3MzEzH9ldffdUAjK1btzq2nft6FTy/9evXN44fP+7Y/tlnnxmA8cUXXzi2dezY0WjSpIlx8uRJx7bVq1cbQJGfg5Kc37nfUQXnBxjvvvuuY1tmZqYRHBxs3HLLLY5tM2fONABj6dKljm3p6elGy5Yti33+z3b33XcbISEhxtGjR522DxkyxPD393fE++abbxZ6Hg3DMNq1a2dcc801jvunT58u9B29Z88ew93d3el7qqj39LmvaYGivmPOfR6zsrKMDh06OMViGMV/b537HXP48GHDzc3N6NOnj1P8s2bNMgBjwYIFTnGW5LUpSkl/jqSkpBT58+Kll15y+vm8d+9ew2azGc8//7xTu61btxouLi5O2wvinjt37nljLHDu7zlnO/e7oOD76L777nNsy8nJMZo0aWJYLBbjxRdfdGw/ceKE4enp6fS6lOY7SqqOpgWKqZYtW4a/vz/XXnstR48eddw6deqEj48P33//vaNthw4dmDx5Mm+99RYxMTEcPXqURYsWlXl9j91uZ/ny5fTv37/QVAHgvOXEz17jkJ6eztGjR+nRoweGYfDbb7852ri5ubF69epip5AV/GXsyy+/JDs7u0zncT7Lly/HbrczYcIErFbnj/vZ53f2+Zw8eZKjR49y5ZVXkpGRwZ9//gnAb7/9xp49exg9enShtV7ne66+/vprAMaMGeO0vWB06auvvnLa3q5dO8eoI+SNPl188cX8/fffFzrdUvu///s/p/tXXnml03FK8/6sbNHR0U5/PY6IiMDPz69Ez0tJntMVK1bQvXt3p/VG9erV44477qiQ+H18fIC891dxAgICSE9Pd5o6WFk+/vhjVq1axTfffMPChQtp3bo1t9xyCz///LOjzbJly2jbti1t2rRxev2vueYagEKvf69evQqt+atozZs3JyYmptD2sz/DKSkpHD16lF69evH333+TkpJywX5HjBjhNFJf8H4pyftr8ODBBAYGFrvvwYMH2bp1K0OHDnW8DyDv+erYseMF+4eSfUcV8PHxcVrX6+bmRteuXZ3O5euvvyYkJIRbb73Vsc3Ly8sxUnM+hmHw8ccf079/fwzDcHpvxMTEkJKSwqZNmwC4+eabcXFxYcmSJY79f//9d7Zt28bgwYMd29zd3R3f0bm5uRw7dgwfHx8uvvhiR18V4ezn8cSJE6SkpHDllVeW+RjffvstWVlZjB492ulnzL333oufn1+h7/eSvDZFKenPkYLplEuXLsUwDEe7JUuWcNlll3HRRRcB8Mknn2C32xk0aJDT6xccHEyrVq0Kfbbd3d0ZMWJEiZ6Tsji7MJXNZqNz584YhsHdd9/t2B4QEFDoe7u031FSNTQtUEy1a9cuUlJSaNSoUZGPFxRuKPDYY4/x4Ycfsn79el544YVy/SJz5MgRUlNT6dChQ6n33b9/PxMmTODzzz8vlDgV/CLj7u7OtGnTGDt2LEFBQVx22WX069ePoUOHOtZ39OrVi1tuuYXJkyfz73//m6uuuoqBAwfyj3/8o0KmY/31119YrdYLPk9//PEHTz/9NN999x2pqalFns9ff/0FUOrna9++fVitVlq2bOm0PTg4mICAAPbt2+e0veCH39kCAwNLtMapNDw8PBzrYYo7TknfnykpKU7r7dzc3KhXr16Fxlue56Uk++7bt4/u3bsXanfu61ZWaWlpAPj6+hbb5oEHHmDp0qVcd911NG7cmD59+jBo0CD69u1bITGcrWfPnk4FLW699VZatWrFQw89xMaNG4G813/79u2F3icFzv1+at68eYXHea7ijvHTTz8xceJE1q5dS0ZGhtNjKSkp+Pv7n7ffc98jBclSWd5f5+5b8Bkv6r3UsmXLEv1iX5LvqAJNmjQp9AefwMBAtmzZ4ri/b98+WrZsWahdwTTL8zly5AjJycnMmzePefPmFdmm4L3RoEEDevfuzdKlS5kyZQqQ94u+i4uLY5oo5P2x79VXX+WNN95gz549TmvJLjTttzS+/PJLnnvuOeLi4pzW5JT12oQFr+25z5ubmxstWrQo9P1ektemuOOU9OfI4MGDWb58OWvXrqVHjx789ddfbNy4kZkzZzra7Nq1C8MwaNWqVZHHO3e6d+PGjctVDOZCzv0M+fv74+Hh4fQdVbD92LFjjvul/Y6SqqHkSkxlt9tp1KgR77//fpGPn/uF8ffff7Nr1y4Atm7dWunxFSU3N5drr72W48eP88QTT9CmTRu8vb05cOAAw4cPdypVPHr0aPr378/y5ctZuXIlzzzzDFOnTuW7777jkksuwWKx8NFHH/HLL7/wxRdfOMpWv/LKK/zyyy9Of+WtLMnJyfTq1Qs/Pz+effZZwsPD8fDwYNOmTTzxxBMVVnq5pD+8i6tEdfZfIStCSSpelfT9+cgjj7Bo0SLH9l69el3wukbFPR9FFRE5X7wleV6q6jk9n99//x04f7LWqFEj4uLiWLlyJf/973/573//y8KFCxk6dKjT81sZfHx86NatG5999hnp6el4e3tjt9vp2LEjM2bMKHKfs8vKA6Wq2ldWRR3jr7/+onfv3rRp04YZM2YQFhaGm5sbX3/9Nf/+979L9Bmuzu+v0n5HVXY8Bce78847GTZsWJFtzl5XN2TIEEaMGEFcXBxRUVEsXbqU3r17O/3i/MILL/DMM8/wz3/+kylTplCvXj2sViujR4++4OtnsViKPLdzv0t+/PFHBgwYQM+ePXnjjTcICQnB1dWVhQsX8sEHH5T4/MujvK9NSX6O9O/fHy8vL5YuXUqPHj1YunQpVqvVsb4N8l5Di8XCf//73yJjOvdnb2V/touKoSTPVWm/o6RqKLkSU4WHh/Ptt99y+eWXX/DLy263M3z4cPz8/Bg9erTjOhxn//WvNH99a9iwIX5+fo5f+kpq69at7Ny5k0WLFjF06FDH9uKmMoWHhzN27FjGjh3Lrl27iIqK4pVXXuG9995ztLnsssu47LLLeP755/nggw+44447+PDDD52mCpRFeHg4drudbdu2FVteevXq1Rw7doxPPvnEsUgWYM+ePYX6grxfkqOjo0scQ9OmTbHb7ezatctpYX5SUhLJycnV+uLHJX1/Pv74405TXc6eIlXcezIwMLBQNS2g0F96q0rTpk0LVYcDitxWFgWLu4ua0nY2Nzc3+vfvT//+/bHb7TzwwAO8+eabPPPMM0WONFSknJwcIG+Uzdvbm/DwcDZv3kzv3r3LfNzS7leW43zxxRdkZmby+eefO/0FvLpMCSr4jJf1/VXS76jSxvT7779jGIbTc75jx44L7tuwYUN8fX3Jzc0t0XfhwIEDuf/++x1TA3fu3Mn48eOd2nz00UdcffXVvP32207bk5OTC41enCswMLDIaXXnfpd8/PHHeHh4sHLlSqeZEQsXLiy0b0nfhwWv7Y4dO5yq9GVlZbFnz55S/ay40HFK+nPE29ubfv36sWzZMmbMmMGSJUu48sornYqChIeHYxgGzZs3p3Xr1hUSY4HK/I46V0V8R0nF05orMdWgQYPIzc11TJc4W05OjtMvnzNmzODnn39m3rx5TJkyhR49ejBy5EiOHj3qaOPt7Q1Q5C+t57JarQwcOJAvvviCX3/9tdDjxf0lreCvSWc/bhiGUzlyyLsOxunTp522hYeH4+vr65iOceLEiULHKUiCKqKM6sCBA7FarTz77LOF/vpZcNyizicrK4s33njDqf2ll15K8+bNmTlzZqHn93x/dbz++usBnKZkAI6/tBVUqKqOSvr+bNeuHdHR0Y5bp06dHO28vb2LfD+Gh4eTkpLiNB3m0KFDhaonVpWYmBjWrl1LXFycY9vx48eLHbUrjQ8++IC33nqL7t2707t372LbnT3dBfI+owUjAAWfh9J8xkvj+PHj/PzzzwQHBzumgQ4aNIgDBw4wf/78Qu1PnTpFenr6BfstuBZOSeMty/kV9RlOSUkp8pdmM4SGhtKhQwfeffddx/RQgB9++KFEMxBK+h1VGtdffz0HDx50KkOekZFR7DS/c+O55ZZb+Pjjj4v849y5FUoDAgKIiYlh6dKlfPjhh7i5uRW6OK/NZiv0Pbps2TIOHDhwwXjCw8P5888/nY67efNmfvrpp0LHsFgsTiNae/fuLbKiXHHfW+eKjo7Gzc2N1157zSn+t99+m5SUlAr7fi/tz5HBgwdz8OBB3nrrLTZv3uy0vg3y1sLZbDYmT55c6Hk3DKPQd1FpVNZ3VFEq4jtKKp5GrsRUvXr14v7772fq1KnExcXRp08fXF1d2bVrF8uWLePVV1/l1ltvZfv27TzzzDMMHz6c/v37A3mleaOiohzrNCDvh0xAQABz587F19cXb29vunXrVuw6hRdeeIFvvvmGXr16OcqYHjp0iGXLlrFmzZpChRsA2rRpQ3h4OOPGjePAgQP4+fnx8ccfF1qbsHPnTnr37s2gQYNo164dLi4ufPrppyQlJTFkyBAAFi1axBtvvMFNN91EeHg4J0+eZP78+fj5+Tl+mJRHy5Yt+de//sWUKVO48sorufnmm3F3d2fDhg2EhoYydepUevToQWBgIMOGDePhhx/GYrGwePHiQj9wrFYrc+bMoX///kRFRTFixAhCQkL4888/+eOPP1i5cmWRMURGRjJs2DDmzZvnmN6zfv16Fi1axMCBA7n66qvLfZ6VpaTvz/Pp1KkT3377LTNmzCA0NJTmzZvTrVs3hgwZwhNPPMFNN93Eww8/TEZGBnPmzKF169YVuoC9pB5//HHee+89rr32Wh566CFHKfaLLrqI48ePl/ivoh999BE+Pj5kZWVx4MABVq5cyU8//URkZKTTZQqKcs8993D8+HGuueYamjRpwr59+3j99deJiopy/LU6KioKm83GtGnTSElJwd3d3XF9p9IoiNMwDA4ePMjbb7/NiRMnmDt3ruNc77rrLpYuXcr//d//8f3333P55ZeTm5vLn3/+ydKlSx3XmzofT09P2rVrx5IlS2jdujX16tWjQ4cOxa5dLMv59enTxzHid//995OWlsb8+fNp1KgRhw4dKtXzUlleeOEFbrzxRi6//HJGjBjBiRMnmDVrFh06dHBKuIpS0u+o0rj33nuZNWsWQ4cOZePGjYSEhLB48eISXxj2xRdf5Pvvv6dbt27ce++9tGvXjuPHj7Np0ya+/fZbR6n/AoMHD+bOO+/kjTfeICYmptDPln79+vHss88yYsQIevTowdatW3n//feLvWbT2f75z38yY8YMYmJiuPvuuzl8+DBz586lffv2TuvTbrjhBmbMmEHfvn35xz/+weHDh5k9ezYtW7YstOapuO+tczVs2JDx48czefJk+vbty4ABA9ixYwdvvPEGXbp0cRrRL4/S/hy5/vrr8fX1Zdy4cY5k+Gzh4eE899xzjB8/nr179zJw4EB8fX3Zs2cPn376Kffddx/jxo0rU6wFf1x7+OGHiYmJwWazOX7mV7SK+I6SSlDp9QhFzlJcidJ58+YZnTp1Mjw9PQ1fX1+jY8eOxuOPP24cPHjQyMnJMbp06WI0adLESE5OdtqvoFzwkiVLHNs+++wzo127doaLi0uJyrLv27fPGDp0qNGwYUPD3d3daNGihTFq1ChHWeKiSrFv27bNiI6ONnx8fIwGDRoY9957r6M0dsHxjh49aowaNcpo06aN4e3tbfj7+xvdunVzKv27adMm4/bbbzcuuugiw93d3WjUqJHRr18/49dff3WKkTKWYi+wYMEC45JLLjHc3d2NwMBAo1evXsaqVascj//000/GZZddZnh6ehqhoaHG448/bqxcubLIksRr1qwxrr32WsPX19fw9vY2IiIinMqBFxVDdna2MXnyZKN58+aGq6urERYWZowfP96phLJhFF1K3TCKLzV8rtKUYvf29i60f3HP3/nenxfy559/Gj179jQ8PT0NwKmM7jfffGN06NDBcHNzMy6++GLjvffeK7YU+6hRo4o837P7K64Ue0mf099++8248sorDXd3d6NJkybG1KlTjddee80AjMTExPOe57klzj08PIwmTZoY/fr1MxYsWFDotTaMwqWiP/roI6NPnz5Go0aNDDc3N+Oiiy4y7r//fuPQoUNO+82fP99o0aKFYbPZnN6jZS3F7u3tbXTv3t3ps1kgKyvLmDZtmtG+fXvH56dTp07G5MmTjZSUFEe74l4jwzCMn3/+2ejUqZPh5uZWorLsxZ1fca+lYRjG559/bkRERBgeHh5Gs2bNjGnTphkLFiwo9H4orhT7ud8lxX1uiirFXtTlJoo6zw8//NBo06aN4e7ubnTo0MH4/PPPjVtuucVo06bNeZ8Pwyj5d1SvXr2M9u3bF9q/qLLk+/btMwYMGGB4eXkZDRo0MB555BHHZRYuVIrdMAwjKSnJGDVqlBEWFma4uroawcHBRu/evY158+YVapuamur4DnjvvfcKPX769Glj7NixRkhIiOHp6Wlcfvnlxtq1a0v0njYMw3jvvfeMFi1aGG5ubkZUVJSxcuXKIs/57bffNlq1amW4u7sbbdq0MRYuXFjkd05x31tFfccYRl7p9TZt2hiurq5GUFCQMXLkyEKX7CjNa1OUkv4cKXDHHXcYgBEdHV1snx9//LFxxRVXGN7e3oa3t7fRpk0bY9SoUcaOHTsuGHdxcnJyjIceesho2LChYbFYnJ7bcz8XxV3CorifUUXFUtLvKKk6FsOowhXNIiJSo4wePZo333yTtLS0EhUBESmNqKgoGjZsWCXl90VEqoLWXImICIBTOXnIWwO1ePFirrjiCiVWUi7Z2dmOgiEFVq9ezebNm7nqqqvMCUpEpBJo5EpERIC8UYSrrrqKtm3bkpSUxNtvv83BgweJjY11qtImUlp79+4lOjqaO++8k9DQUP7880/mzp2Lv78/v//+e4Vey0lExEwqaCEiIkDeIvCPPvqIefPmYbFYuPTSS3n77beVWEm5BQYG0qlTJ9566y2OHDmCt7c3N9xwAy+++KISKxGpVTRyJSIiIiIiUgG05kpERERERKQCKLkSERERERGpAFpzVQS73c7Bgwfx9fUt8YUzRURERESk9jEMg5MnTxIaGorVev6xKSVXRTh48CBhYWFmhyEiIiIiItVEfHw8TZo0OW8bJVdF8PX1BfKeQD8/P5OjERERERERs6SmphIWFubIEc5HyVURCqYC+vn5KbkSEREREZESLRdSQQsREREREZEKoORKRERERESkAii5EhERERERqQBacyUiIiIidYZhGOTk5JCbm2t2KFJN2Gw2XFxcKuQSTEquRERERKROyMrK4tChQ2RkZJgdilQzXl5ehISE4ObmVq5+lFyJiIiISK1nt9vZs2cPNpuN0NBQ3NzcKmSkQmo2wzDIysriyJEj7Nmzh1atWl3wQsHno+RKRERERGq9rKws7HY7YWFheHl5mR2OVCOenp64urqyb98+srKy8PDwKHNfKmghIiIiInVGeUYlpPaqqPeF3l0iIiIiIiIVQMmViIiIiIhIBVByJSIiIiJSxzRr1oyZM2eWuP3q1auxWCwkJydXWkwA77zzDgEBAZV6jMqk5EpEREREpJqyWCznvU2aNKlM/W7YsIH77ruvxO179OjBoUOH8Pf3L9Px6gpVCxQRERERqaYOHTrk+P+SJUuYMGECO3bscGzz8fFx/N8wDHJzc3FxufCv+A0bNixVHG5ubgQHB5dqn7qoWoxczZ49m2bNmuHh4UG3bt1Yv359ifb78MMPsVgsDBw40Gm7YRhMmDCBkJAQPD09iY6OZteuXZUQuYiIiIjUVIZhkJGVU+U3wzBKHGNwcLDj5u/vj8Vicdz/888/8fX15b///S+dOnXC3d2dNWvW8Ndff3HjjTcSFBSEj48PXbp04dtvv3Xq99xpgRaLhbfeeoubbroJLy8vWrVqxeeff+54/NxpgQXT91auXEnbtm3x8fGhb9++TslgTk4ODz/8MAEBAdSvX58nnniCYcOGFfrd/ULmzJlDeHg4bm5uXHzxxSxevNjpNZw0aRIXXXQR7u7uhIaG8vDDDzsef+ONN2jVqhUeHh4EBQVx6623lurYpWX6yNWSJUsYM2YMc+fOpVu3bsycOZOYmBh27NhBo0aNit1v7969jBs3jiuvvLLQYy+99BKvvfYaixYtonnz5jzzzDPExMSwbdu2ctWtFxEREZHa41R2Lu0mrKzy4257NgYvt4r7NfzJJ59k+vTptGjRgsDAQOLj47n++ut5/vnncXd3591336V///7s2LGDiy66qNh+Jk+ezEsvvcTLL7/M66+/zh133MG+ffuoV69eke0zMjKYPn06ixcvxmq1cueddzJu3Djef/99AKZNm8b777/PwoULadu2La+++irLly/n6quvLvG5ffrppzzyyCPMnDmT6OhovvzyS0aMGEGTJk24+uqr+fjjj/n3v//Nhx9+SPv27UlMTGTz5s0A/Prrrzz88MMsXryYHj16cPz4cX788cdSPLOlZ/rI1YwZM7j33nsZMWIE7dq1Y+7cuXh5ebFgwYJi98nNzeWOO+5g8uTJtGjRwukxwzCYOXMmTz/9NDfeeCMRERG8++67HDx4kOXLl1fy2YiIiIiIVK1nn32Wa6+9lvDwcOrVq0dkZCT3338/HTp0oFWrVkyZMoXw8HCnkaiiDB8+nNtvv52WLVvywgsvkJaWdt4ZZdnZ2cydO5fOnTtz6aWX8uCDDxIbG+t4/PXXX2f8+PHcdNNNtGnThlmzZpW6WMX06dMZPnw4DzzwAK1bt2bMmDHcfPPNTJ8+HYD9+/cTHBxMdHQ0F110EV27duXee+91PObt7U2/fv1o2rQpl1xyidOoVmUwdeQqKyuLjRs3Mn78eMc2q9VKdHQ0a9euLXa/Z599lkaNGnH33XcXyj737NlDYmIi0dHRjm3+/v5069aNtWvXMmTIkEL9ZWZmkpmZ6bifmppantOqUNsOprI5IZnrO4bg7+lqdjgiIiIitYanq41tz8aYctyK1LlzZ6f7aWlpTJo0ia+++opDhw6Rk5PDqVOn2L9//3n7iYiIcPzf29sbPz8/Dh8+XGx7Ly8vwsPDHfdDQkIc7VNSUkhKSqJr166Ox202G506dcJut5f43LZv316o8Mbll1/Oq6++CsBtt93GzJkzadGiBX379uX666+nf//+uLi4cO2119K0aVPHY3379nVMe6wspo5cHT16lNzcXIKCgpy2BwUFkZiYWOQ+a9as4e2332b+/PlFPl6wX2n6nDp1Kv7+/o5bWFhYaU+l0ox8fyPjP9nK5vhks0MRERERqVUsFgtebi5VfrNYLBV6Ht7e3k73x40bx6effsoLL7zAjz/+SFxcHB07diQrK+u8/bi6Ov8h32KxnDcRKqp9adaTVYSwsDB27NjBG2+8gaenJw888AA9e/YkOzsbX19fNm3axH/+8x9CQkKYMGECkZGRlVpO3vRpgaVx8uRJ7rrrLubPn0+DBg0qrN/x48eTkpLiuMXHx1dY3+UV2SQAgC0JyabGISIiIiI1w08//cTw4cO56aab6NixI8HBwezdu7dKY/D39ycoKIgNGzY4tuXm5rJp06ZS9dO2bVt++uknp20//fQT7dq1c9z39PSkf//+vPbaa6xevZq1a9eydetWAFxcXIiOjuall15iy5Yt7N27l++++64cZ3Z+pk4LbNCgATabjaSkJKftSUlJRZZ6/Ouvv9i7dy/9+/d3bCvIpl1cXNixY4djv6SkJEJCQpz6jIqKKjIOd3d33N3dy3s6lSIyLIDPNx8kLj7F7FBEREREpAZo1aoVn3zyCf3798disfDMM8+UaipeRXnooYeYOnUqLVu2pE2bNrz++uucOHGiVCN3jz32GIMGDeKSSy4hOjqaL774gk8++cRR/fCdd94hNzeXbt264eXlxXvvvYenpydNmzblyy+/5O+//6Znz54EBgby9ddfY7fbufjiiyvrlM0duXJzc6NTp05OC9/sdjuxsbF07969UPs2bdqwdetW4uLiHLcBAwZw9dVXExcXR1hYGM2bNyc4ONipz9TUVNatW1dkn9VdZJO8C7VtTkiu8mFWEREREal5ZsyYQWBgID169KB///7ExMRw6aWXVnkcTzzxBLfffjtDhw6le/fu+Pj4EBMTU6rq3QMHDuTVV19l+vTptG/fnjfffJOFCxdy1VVXARAQEMD8+fO5/PLLiYiI4Ntvv+WLL76gfv36BAQE8Mknn3DNNdfQtm1b5s6dy3/+8x/at29fSWcMFsPk39iXLFnCsGHDePPNN+natSszZ85k6dKl/PnnnwQFBTF06FAaN27M1KlTi9x/+PDhJCcnO1UCnDZtGi+++KJTKfYtW7aUuBR7amoq/v7+pKSk4OfnV1GnWiansnLpMGkluXaDteOvIcTf09R4RERERGqi06dPs2fPHpo3b65L85jEbrfTtm1bBg0axJQpU8wOx8n53h+lyQ1Mv87V4MGDOXLkCBMmTCAxMZGoqChWrFjhKEixf/9+rNbSDbA9/vjjpKenc99995GcnMwVV1zBihUrauQHydPNRusgX7YfSmVzfLKSKxERERGpEfbt28c333xDr169yMzMZNasWezZs4d//OMfZodWaUwfuaqOqtPIFcD4T7bwn/XxjLwqnCf6tjE7HBEREZEaRyNXVS8+Pp4hQ4bw+++/YxgGHTp04MUXX6Rnz55mh1ZIrRm5kguLbBLAf9bHqxy7iIiIiNQYYWFhhSr91XY1qhR7XRWRX459a0IKdrsGGkVEREREqiMlVzVA6yAfPFytnMzM4e+j6WaHIyIiIiIiRVByVQO42Kx0CM0vya6pgSIiIiIi1ZKSqxoiMiwAgC0JyabGISIiIiIiRVNyVUNE5F9MOC4hxeRIRERERESkKEquaoio/JGr7QdTycqxmxuMiIiIiIgUouSqhrionhcBXq5k5dr5MzHV7HBEREREpBbZu3cvFouFuLi4Yts0a9aMmTNnVllMNZGSqxrCYrE4SrKrqIWIiIhI3TF8+HAsFkuhW9++fc0OTc6hiwjXIFFN/PnfziNsTkjhLrODEREREZEq07dvXxYuXOi0zd3d3aRopDgauapBNHIlIiIiUoEMA7LSq/5mGKUO1d3dneDgYKdbYGAgAP/4xz8YPHiwU/vs7GwaNGjAu+++C8CKFSu44oorCAgIoH79+vTr14+//vqrXE/f/v37ufHGG/Hx8cHPz49BgwaRlJTkeHzz5s1cffXV+Pr64ufnR6dOnfj1118B2LdvH/379ycwMBBvb2/at2/P119/Xa54qgONXNUgEWF5FQN3H0kjLTMHH3e9fCIiIiJllp0BL4RW/XGfOghu3hXW3R133MFtt91GWloaPj4+AKxcuZKMjAxuuukmANLT0xkzZgwRERGkpaUxYcIEbrrpJuLi4rBaSz/eYrfbHYnVDz/8QE5ODqNGjWLw4MGsXr3aEdcll1zCnDlzsNlsxMXF4erqCsCoUaPIysrif//7H97e3mzbts0Re02m385rkEa+HoT6e3Aw5TRbE1LoHl7f7JBEREREpAp8+eWXhZKPp556iqeeeoqYmBi8vb359NNPueuuvMUjH3zwAQMGDMDX1xeAW265xWnfBQsW0LBhQ7Zt20aHDh1KHU9sbCxbt25lz549hIWFAfDuu+/Svn17NmzYQJcuXdi/fz+PPfYYbdq0AaBVq1aO/ffv388tt9xCx44dAWjRokWpY6iOlFzVMJFhARxMSWRLQrKSKxEREZHycPXKG0Uy47ildPXVVzNnzhynbfXq1QPAxcWFQYMG8f7773PXXXeRnp7OZ599xocffuhou2vXLiZMmMC6des4evQodnvepX32799fpuRq+/bthIWFORIrgHbt2hEQEMD27dvp0qULY8aM4Z577mHx4sVER0dz2223ER4eDsDDDz/MyJEj+eabb4iOjuaWW24hIiKi1HFUN1pzVcNE5l/vanNCsqlxiIiIiNR4Fkve9LyqvlkspQ7V29ubli1bOt0KkivIm4IXGxvL4cOHWb58OZ6enk7VBPv378/x48eZP38+69atY926dQBkZWWV/3ksxqRJk/jjjz+44YYb+O6772jXrh2ffvopAPfccw9///03d911F1u3bqVz5868/vrrlRZLVVFyVcNENMlbd7U5PsXkSERERESkuujRowdhYWEsWbKE999/n9tuu82xvunYsWPs2LGDp59+mt69e9O2bVtOnDhRruO1bduW+Ph44uPjHdu2bdtGcnIy7dq1c2xr3bo1jz76KN988w0333yzU8XDsLAw/u///o9PPvmEsWPHMn/+/HLFVB1oWmAN07GxPxYLHEg+xZGTmTT0VQlOERERkdouMzOTxMREp20uLi40aNDAcf8f//gHc+fOZefOnXz//feO7YGBgdSvX5958+YREhLC/v37efLJJ8sVT3R0NB07duSOO+5g5syZ5OTk8MADD9CrVy86d+7MqVOneOyxx7j11ltp3rw5CQkJbNiwwbH2a/To0Vx33XW0bt2aEydO8P3339O2bdtyxVQdaOSqhvH1cCW8Yd5ixi2aGigiIiJSJ6xYsYKQkBCn2xVXXOHU5o477mDbtm00btyYyy+/3LHdarXy4YcfsnHjRjp06MCjjz7Kyy+/XK54LBYLn332GYGBgfTs2ZPo6GhatGjBkiVLALDZbBw7doyhQ4fSunVrBg0axHXXXcfkyZMByM3NZdSoUbRt25a+ffvSunVr3njjjXLFVB1YDKMMhfZrudTUVPz9/UlJScHPz8/scAoZu3QzH29K4OHerRhzbWuzwxERERGp9k6fPs2ePXto3rw5Hh4eZocj1cz53h+lyQ00clUDRYYVrLtKNjcQERERERFxUHJVA0U2CQDypgVq4FFEREREpHpQclUDtQnxxc1m5URGNvHHT5kdjoiIiIiIoOSqRnJ3sdE2JO9q23EqaiEiIiIiUi0ouaqhCi4mvEXrrkRERERKTEsqpCgV9b5QclVDReSvu9qskSsRERGRCyq4oG5GRobJkUh1VPC+KHiflJUuIlxDReVXDPz9QCo5uXZcbMqTRURERIpjs9kICAjg8OHDAHh5eWGxWEyOSsxmGAYZGRkcPnyYgIAAbDZbufpTclVDtWjgg4+7C2mZOew6nEbbkOp3PS4RERGR6iQ4OBjAkWCJFAgICHC8P8pDyVUNZbVa6NjYn7V/H2NzfLKSKxEREZELsFgshISE0KhRI7Kzs80OR6oJV1fXco9YFVByVYNFhgXkJVcJKQzpanY0IiIiIjWDzWarsF+mRc6mhTo1WGSTvHVXm1UxUERERETEdEquarCCcuw7kk5yOjvX3GBEREREROo4JVc1WIi/Bw183Mm1G/xxMMXscERERERE6jQlVzWYxWJxlGTfHK/kSkRERETETEquarhIXUxYRERERKRaUHJVw0Xkr7tSUQsREREREXMpuarhCioG7j2WQXJGlsnRiIiIiIjUXUquargALzea1vcCYEuC1l2JiIiIiJhFyVUtULDuaovWXYmIiIiImEbJVS0QkT81ME4VA0VERERETKPkqhaIKihqkZCMYRjmBiMiIiIiUkcpuaoF2of6Y7NaOHIyk8TU02aHIyIiIiJSJym5qgU83Wy0DvIFVJJdRERERMQs1SK5mj17Ns2aNcPDw4Nu3bqxfv36Ytt+8skndO7cmYCAALy9vYmKimLx4sVObYYPH47FYnG69e3bt7JPw1RRYXnrrjarYqCIiIiIiClMT66WLFnCmDFjmDhxIps2bSIyMpKYmBgOHz5cZPt69erxr3/9i7Vr17JlyxZGjBjBiBEjWLlypVO7vn37cujQIcftP//5T1Wcjmki8isGauRKRERERMQcpidXM2bM4N5772XEiBG0a9eOuXPn4uXlxYIFC4psf9VVV3HTTTfRtm1bwsPDeeSRR4iIiGDNmjVO7dzd3QkODnbcAgMDq+J0TFNQjn1rQgp2u4paiIiIiIhUNVOTq6ysLDZu3Eh0dLRjm9VqJTo6mrVr115wf8MwiI2NZceOHfTs2dPpsdWrV9OoUSMuvvhiRo4cybFjx4rtJzMzk9TUVKdbTdM6yAcPVysnM3P4+2i62eGIiIiIiNQ5piZXR48eJTc3l6CgIKftQUFBJCYmFrtfSkoKPj4+uLm5ccMNN/D6669z7bXXOh7v27cv7777LrGxsUybNo0ffviB6667jtzc3CL7mzp1Kv7+/o5bWFhYxZxgFXKxWekQmr/uSlMDRURERESqnIvZAZSFr68vcXFxpKWlERsby5gxY2jRogVXXXUVAEOGDHG07dixIxEREYSHh7N69Wp69+5dqL/x48czZswYx/3U1NQamWBFhgXw674TbElI5pZOTcwOR0RERESkTjE1uWrQoAE2m42kpCSn7UlJSQQHBxe7n9VqpWXLlgBERUWxfft2pk6d6kiuztWiRQsaNGjA7t27i0yu3N3dcXd3L/uJVBMRTfJGruJUMVBEREREpMqZOi3Qzc2NTp06ERsb69hmt9uJjY2le/fuJe7HbreTmZlZ7OMJCQkcO3aMkJCQcsVb3UWFBQCw/WAqWTl2c4MREREREaljTJ8WOGbMGIYNG0bnzp3p2rUrM2fOJD09nREjRgAwdOhQGjduzNSpU4G89VGdO3cmPDyczMxMvv76axYvXsycOXMASEtLY/Lkydxyyy0EBwfz119/8fjjj9OyZUtiYmJMO8+qcFE9LwK8XEnOyObPxFRHeXYREREREal8pidXgwcP5siRI0yYMIHExESioqJYsWKFo8jF/v37sVrPDLClp6fzwAMPkJCQgKenJ23atOG9995j8ODBANhsNrZs2cKiRYtITk4mNDSUPn36MGXKlFox9e98LBYLEU0C+N/OI2xOSFFyJSIiIiJShSyGYeiiSOdITU3F39+flJQU/Pz8zA6nVGZ8s4PXvtvNrZ2aMP22SLPDERERERGp0UqTG5h+EWGpWAWjVSrHLiIiIiJStZRc1TIRYXkVA3cfSSMtM8fkaERERERE6g4lV7VMI18PQv09MAzYqpLsIiIiIiJVRslVLRSZX5J9S0KyqXGIiIiIiNQlSq5qIce6KyVXIiIiIiJVRslVLRSZv+5qc7ymBYqIiIiIVBUlV7VQx8b+WCxwIPkUR05mmh2OiIiIiEidoOSqFvL1cCW8oQ+gdVciIiIiIlVFyVUtFelYd6WpgSIiIiIiVUHJVS11Zt1VsrmBiIiIiIjUEUquaqmCkastCckYhmFuMCIiIiIidYCSq1qqTYgvrjYLJzKyiT9+yuxwRERERERqPSVXtZS7i412IX6ArnclIiIiIlIVlFzVYpFhAYDWXYmIiIiIVAUlV7VYhKNiYLKpcYiIiIiI1AVKrmqxqPyKgb8fSCUn125yNCIiIiIitZuSq1qsRQMffNxdOJWdy67DaWaHIyIiIiJSqym5qsWsVgsdG+eNXm3R1EARERERkUql5KqWKyhqERefYm4gIiIiIiK1nJKrWi6ySd7IlSoGioiIiIhULiVXtVzByNWOpJOczs41NxgRERERkVpMyVUtF+LvQQMfd3LtBn8c1NRAEREREZHKouSqlrNYLI6S7Ju17kpEREREpNIouaoDdDFhEREREZHKp+SqDihYd7UlQSNXIiIiIiKVRclVHVBQMXDP0XSSM7JMjkZEREREpHZSclUHBHi50bS+F6DRKxERERGRyqLkqo6IzF93tUXrrkREREREKoWSqzoiIn9qYJwqBoqIiIiIVAolV3VEVH5Ri80JyRiGYW4wIiIiIiK1kJKrOqJ9qD82q4UjJzNJTD1tdjgiIiIiIrWOkqs6wtPNRusgX0AXExYRERERqQxKruqQqLC8dVe6mLCIiIiISMVTclWHRORXDNwcn2xqHCIiIiIitZGSqzqkoBz71oQU7HYVtRARERERqUhKruqQ1kE+eLhaOZmZw99H080OR0RERESkVlFyVYe42Kx0CM1bd6WLCYuIiIiIVCwlV3VMZMH1rrTuSkRERESkQim5qmMimhRUDFQ5dhERERGRiqTkqo6Jyh+52nYwlawcu7nBiIiIiIjUIkqu6piL6nkR4OVKVq6dPxNTzQ5HRERERKTWqBbJ1ezZs2nWrBkeHh5069aN9evXF9v2k08+oXPnzgQEBODt7U1UVBSLFy92amMYBhMmTCAkJARPT0+io6PZtWtXZZ9GjWCxWM5c70pTA0VEREREKozpydWSJUsYM2YMEydOZNOmTURGRhITE8Phw4eLbF+vXj3+9a9/sXbtWrZs2cKIESMYMWIEK1eudLR56aWXeO2115g7dy7r1q3D29ubmJgYTp8+XVWnVa1FFqy7UlELEREREZEKYzEMw9SryXbr1o0uXbowa9YsAOx2O2FhYTz00EM8+eSTJerj0ksv5YYbbmDKlCkYhkFoaChjx45l3LhxAKSkpBAUFMQ777zDkCFDLthfamoq/v7+pKSk4OfnV/aTq6a+3ZbEPe/+SusgH755tJfZ4YiIiIiIVFulyQ1MHbnKyspi48aNREdHO7ZZrVaio6NZu3btBfc3DIPY2Fh27NhBz549AdizZw+JiYlOffr7+9OtW7di+8zMzCQ1NdXpVptFhOWNXO06nEZaZo7J0YiIiIiI1A6mJldHjx4lNzeXoKAgp+1BQUEkJiYWu19KSgo+Pj64ublxww038Prrr3PttdcCOPYrTZ9Tp07F39/fcQsLCyvPaVV7jXw9CPX3wDBgq9ZdiYiIiIhUCNPXXJWFr68vcXFxbNiwgeeff54xY8awevXqMvc3fvx4UlJSHLf4+PiKC7aaKriY8JaEZFPjEBERERGpLVzMPHiDBg2w2WwkJSU5bU9KSiI4OLjY/axWKy1btgQgKiqK7du3M3XqVK666irHfklJSYSEhDj1GRUVVWR/7u7uuLu7l/NsapaIJgH89/dENiu5EhERERGpEKaOXLm5udGpUydiY2Md2+x2O7GxsXTv3r3E/djtdjIzMwFo3rw5wcHBTn2mpqaybt26UvVZ20WGFVQM1LRAEREREZGKYOrIFcCYMWMYNmwYnTt3pmvXrsycOZP09HRGjBgBwNChQ2ncuDFTp04F8tZHde7cmfDwcDIzM/n6669ZvHgxc+bMAfKu4zR69Giee+45WrVqRfPmzXnmmWcIDQ1l4MCBZp1mtdOxsT8WCxxIPsXRtEwa+NStkTsRERERkYpmenI1ePBgjhw5woQJE0hMTCQqKooVK1Y4ClLs378fq/XMAFt6ejoPPPAACQkJeHp60qZNG9577z0GDx7saPP444+Tnp7OfffdR3JyMldccQUrVqzAw8Ojys+vuvL1cCW8oQ+7D6exJSGZa9oEXXgnEREREREplunXuaqOavt1rgqMXbqZjzcl8HDvVoy5trXZ4YiIiIiIVDs15jpXYq4z666SzQ1ERERERKQWUHJVh0U2CQDyyrFrAFNEREREpHyUXNVhbUJ8cbVZOJGRTfzxU2aHIyIiIiJSoym5qsPcXWy0C8mbN6rrXYmIiIiIlI+SqzouIn9qoNZdiYiIiIiUj5KrOi4yLACALQm6mLCIiIiISHkouarjovIrBm49kEJOrt3kaEREREREai4lV3VciwY++Li7cCo7l12H08wOR0RERESkxlJyVcdZrRY6Ns4bvdqiohYiIiIiImWm5EqIyJ8aGBevdVciIiIiImWl5EqIOutiwiIiIiIiUjZKrsRRMfDPxJOczs41NxgRERERkRpKyZUQ4u9BAx93cu0GfxxMNTscEREREZEaScmVYLFYHCXZdTFhEREREZGyUXIlAETkr7varHVXIiIiIiJlouRKgDPrrrYkqGKgiIiIiEhZKLkSACLyr3W152g6KRnZJkcjIiIiIlLzKLkSAAK93Wha3wuALQeSzQ1GRERERKQGUnIlDpEF665U1EJEREREpNSUXIlDRJO8qYFx8Vp3JSIiIiJSWkquxCEqv6jF5oRkDMMwNxgRERERkRpGyZU4tA/1x2a1cORkJompp80OR0RERESkRlFyJQ6ebjZaB/kCsFlTA0VERERESkXJlTiJzF93pYsJi4iIiIiUjpIrcXLmYsLJpsYhIiIiIlLTKLkSJwXl2LfEp2C3q6iFiIiIiEhJKbkSJ62DfPBwtXIyM4e/j6abHY6IiIiISI2h5EqcuNisdAjNW3elqYEiIiIiIiWn5EoKicifGrg5PtnUOEREREREahIlV1JIZFhBxUCVYxcRERERKSklV1JIVH7FwG0HU8nKsZsbjIiIiIhIDaHkSgq5qJ4XAV6uZOXa2ZF40uxwRERERERqBCVXUojFYnGsu4pTUQsRERERkRJRciVFimySv+5KRS1EREREREpEyZUUyXExYY1ciYiIiIiUiJIrKVJEfsXAXYfTSMvMMTkaEREREZHqT8mVFKmRrweh/h4YBvx+QCXZRUREREQuRMmVFCsyvyS71l2JiIiIiFyYkispVoRj3ZVGrkRERERELkTJlRQrMn/dVZxGrkRERERELkjJlRSrY2N/LBY4kHyKo2mZZocjIiIiIlKtKbmSYvl6uBLe0AdQSXYRERERkQupFsnV7NmzadasGR4eHnTr1o3169cX23b+/PlceeWVBAYGEhgYSHR0dKH2w4cPx2KxON369u1b2adRK0U0KZgaqHVXIiIiIiLnY3pytWTJEsaMGcPEiRPZtGkTkZGRxMTEcPjw4SLbr169mttvv53vv/+etWvXEhYWRp8+fThw4IBTu759+3Lo0CHH7T//+U9VnE6tE5VfMVAjVyIiIiIi52d6cjVjxgzuvfdeRowYQbt27Zg7dy5eXl4sWLCgyPbvv/8+DzzwAFFRUbRp04a33noLu91ObGysUzt3d3eCg4Mdt8DAwKo4nVonMr9i4Ob4ZAzDMDcYEREREZFqzNTkKisri40bNxIdHe3YZrVaiY6OZu3atSXqIyMjg+zsbOrVq+e0ffXq1TRq1IiLL76YkSNHcuzYsWL7yMzMJDU11ekmedqE+OJqs3AiI5v446fMDkdEREREpNoyNbk6evQoubm5BAUFOW0PCgoiMTGxRH088cQThIaGOiVoffv25d133yU2NpZp06bxww8/cN1115Gbm1tkH1OnTsXf399xCwsLK/tJ1TLuLjbahfgBsFlTA0VEREREimX6tMDyePHFF/nwww/59NNP8fDwcGwfMmQIAwYMoGPHjgwcOJAvv/ySDRs2sHr16iL7GT9+PCkpKY5bfHx8FZ1BzRBx1tRAEREREREpmqnJVYMGDbDZbCQlJTltT0pKIjg4+Lz7Tp8+nRdffJFvvvmGiIiI87Zt0aIFDRo0YPfu3UU+7u7ujp+fn9NNzoh0FLVQxUARERERkeKYmly5ubnRqVMnp2IUBcUpunfvXux+L730ElOmTGHFihV07tz5gsdJSEjg2LFjhISEVEjcdU1kfjn2rQdSyMm1mxyNiIiIiEj1ZPq0wDFjxjB//nwWLVrE9u3bGTlyJOnp6YwYMQKAoUOHMn78eEf7adOm8cwzz7BgwQKaNWtGYmIiiYmJpKWlAZCWlsZjjz3GL7/8wt69e4mNjeXGG2+kZcuWxMTEmHKONV2Lhj74uLtwKjuX3UfSzA5HRERERKRacjE7gMGDB3PkyBEmTJhAYmIiUVFRrFixwlHkYv/+/VitZ3LAOXPmkJWVxa233urUz8SJE5k0aRI2m40tW7awaNEikpOTCQ0NpU+fPkyZMgV3d/cqPbfawma10LGxP2v/Psbm+GTaBGvapIiIiIjIuSyGLl5USGpqKv7+/qSkpGj9Vb6p/93Omz/8ze1dL2LqzR3NDkdEREREpEqUJjcwfVqg1AxR+RUDt6gcu4iIiIhIkZRcSYlE5FcM/DPxJKezi75emIiIiIhIXabkSkok1N+DBj7u5NoN/jiYanY4IiIiIiLVjpIrKRGLxUJUWF5Jdl1MWERERESkMCVXUmIRWnclIiIiIlIsJVdSYpH56642J6SYG4iIiIiISDWk5EpKLKJx3rTAPUfTScnINjkaEREREZHqRcmVlFigtxtN63sBsOVAsrnBiIiIiIhUM0qupFQK1l2pqIWIiIiIiDMlV1IqkU3yKwZq3ZWIiIiIiBMlV1IqUQVFLTRyJSIiIiLiRMmVlEr7UH9sVguHT2aSmHLa7HBERERERKoNJVdSKp5uNloH+QIQp9ErEREREREHJVdSamfWXSWbG4iIiIiISDWi5EpKreBiwluUXImIiIiIOCi5klKLyB+52hKfgt1umByNiIiIiEj1oORKSq11kC8erlZOZuaw51i62eGIiIiIiFQLSq6k1FxtVjqE5q+7UlELERERERFAyZWUUUSTAEDJlYiIiIhIASVXUiaRYQUVA1NMjkREREREpHpQciVlEpk/crXtYCpZOXZzgxERERERqQaUXEmZNK3vhb+nK1m5dnYknjQ7HBERERER0ym5kjKxWCyO613F6XpXIiIiIiJKrqTsIh3Xu0o2NxARERERkWpAyZWUWcG6q80auRIRERERUXIlZReRXzFw1+E00jJzTI5GRERERMRcSq6kzBr5ehDq74FhwO8HVJJdREREROo2JVdSLrqYsIiIiIhIHiVXUi4FFQO36GLCIiIiIlLHKbmSconMX3cVp5ErEREREanjlFxJuXRs7I/FAgeST3E0LdPscERERERETKPkSsrF18OV8IY+AGxRSXYRERERqcOUXEm5RTQpmBqodVciIiIiUncpuZJyi3IUtUg2NQ4RERERETOVKbmKj48nISHBcX/9+vWMHj2aefPmVVhgUnOcXY7dMAxzgxERERERMUmZkqt//OMffP/99wAkJiZy7bXXsn79ev71r3/x7LPPVmiAUv21DfHF1WbhREY2CSdOmR2OiIiIiIgpypRc/f7773Tt2hWApUuX0qFDB37++Wfef/993nnnnYqMT2oAdxcb7UL8AJVkFxEREZG6q0zJVXZ2Nu7u7gB8++23DBgwAIA2bdpw6NChiotOaoyCqYFadyUiIiIidVWZkqv27dszd+5cfvzxR1atWkXfvn0BOHjwIPXr16/QAKVmiMwvarFZFQNFREREpI4qU3I1bdo03nzzTa666ipuv/12IiMjAfj8888d0wWlbonML8e+9UAKObl2k6MREREREal6LmXZ6aqrruLo0aOkpqYSGBjo2H7ffffh5eVVYcFJzdGioQ8+7i6kZeaw+0gabYL9zA5JRERERKRKlWnk6tSpU2RmZjoSq3379jFz5kx27NhBo0aNKjRAqRlsVgsdGuclVJtV1EJERERE6qAyJVc33ngj7777LgDJycl069aNV155hYEDBzJnzpxS9zd79myaNWuGh4cH3bp1Y/369cW2nT9/PldeeSWBgYEEBgYSHR1dqL1hGEyYMIGQkBA8PT2Jjo5m165dpY5LSsex7ipB665EREREpO4pU3K1adMmrrzySgA++ugjgoKC2LdvH++++y6vvfZaqfpasmQJY8aMYeLEiWzatInIyEhiYmI4fPhwke1Xr17N7bffzvfff8/atWsJCwujT58+HDhwwNHmpZde4rXXXmPu3LmsW7cOb29vYmJiOH36dFlOV0oo6qyLCYuIiIiI1DUWwzCM0u7k5eXFn3/+yUUXXcSgQYNo3749EydOJD4+nosvvpiMjIwS99WtWze6dOnCrFmzALDb7YSFhfHQQw/x5JNPXnD/3NxcAgMDmTVrFkOHDsUwDEJDQxk7dizjxo0DICUlhaCgIN555x2GDBlywT5TU1Px9/cnJSUFPz+tHSqpA8mnuPzF77BZLfwxOQYPV5vZIYmIiIiIlEtpcoMyjVy1bNmS5cuXEx8fz8qVK+nTpw8Ahw8fLlUykpWVxcaNG4mOjj4TkNVKdHQ0a9euLVEfGRkZZGdnU69ePQD27NlDYmKiU5/+/v5069at2D4zMzNJTU11uknphfp70MDHnVy7wR8H9RyKiIiISN1SpuRqwoQJjBs3jmbNmtG1a1e6d+8OwDfffMMll1xS4n6OHj1Kbm4uQUFBTtuDgoJITEwsUR9PPPEEoaGhjmSqYL/S9Dl16lT8/f0dt7CwsBKfg5xhsVgcJdk1NVBERERE6poyJVe33nor+/fv59dff2XlypWO7b179+bf//53hQV3IS+++CIffvghn376KR4eHmXuZ/z48aSkpDhu8fHxFRhl3VJQ1GJLQrKpcYiIiIiIVLUyXecKIDg4mODgYBISEgBo0qRJqS8g3KBBA2w2G0lJSU7bk5KSCA4OPu++06dP58UXX+Tbb78lIiLCKa6CPkJCQpz6jIqKKrIvd3d33N3dSxW7FE0VA0VERESkrirTyJXdbufZZ5/F39+fpk2b0rRpUwICApgyZQp2u73E/bi5udGpUydiY2Od+o6NjXVMNSzKSy+9xJQpU1ixYgWdO3d2eqx58+YEBwc79Zmamsq6devO26dUjIjGedMC9xxNJyUj2+RoRERERESqTplGrv71r3/x9ttv8+KLL3L55ZcDsGbNGiZNmsTp06d5/vnnS9zXmDFjGDZsGJ07d6Zr167MnDmT9PR0RowYAcDQoUNp3LgxU6dOBWDatGlMmDCBDz74gGbNmjnWUfn4+ODj44PFYmH06NE899xztGrViubNm/PMM88QGhrKwIEDy3K6UgqB3m40re/FvmMZbDmQzJWtGpodkoiIiIhIlShTcrVo0SLeeustBgwY4NgWERFB48aNeeCBB0qVXA0ePJgjR44wYcIEEhMTiYqKYsWKFY6CFPv378dqPTPANmfOHLKysrj11lud+pk4cSKTJk0C4PHHHyc9PZ377ruP5ORkrrjiClasWFGudVlSchFNAth3LIPN8UquRERERKTuKNN1rjw8PNiyZQutW7d22r5jxw6ioqI4depUhQVoBl3nqnze+vFvnvtqO9e2C2L+0M4X3kFEREREpJqq9OtcRUZGOi76e7ZZs2Y5FZeQuslR1ELl2EVERESkDinTtMCXXnqJG264gW+//dZRJGLt2rXEx8fz9ddfV2iAUvO0D/XDZrVw+GQmiSmnCfbXdEwRERERqf3KNHLVq1cvdu7cyU033URycjLJycncfPPN/PHHHyxevLiiY5QaxsvNhdZBvgDEafRKREREROqIMq25Ks7mzZu59NJLyc3NraguTaE1V+X35Mdb+HBDPA9cFc7jfduYHY6IiIiISJlU+porkQs5czHhZFPjEBERERGpKkqupFJENMm7mPCW+BTs9gobHBURERERqbaUXEmlaB3ki4erlZOZOew5lm52OCIiIiIila5U1QJvvvnm8z6enJxcnlikFnG1WWkf6s/GfSfYHJ9MeEMfs0MSEREREalUpUqu/P39L/j40KFDyxWQ1B6RTQLYuO8EWxJSuPnSJmaHIyIiIiJSqUqVXC1cuLCy4pBaKDIsLxlXOXYRERERqQu05koqTWSTAAC2HUolK8dubjAiIiIiIpVMyZVUmqb1vfD3dCUrx86OxJNmhyMiIiIiUqmUXEmlsVgsjpLscbrelYiIiIjUckqupFJF5V9MeIvWXYmIiIhILafkSipVwbqrzRq5EhEREZFaTsmVVKqI/IqBuw6nkZaZY3I0IiIiIiKVR8mVVKpGvh6E+ntgGPD7gRSzwxERERERqTRKrqTSRRRMDdS6KxERERGpxZRcSaWLLChqkaCRKxERERGpvZRcSaWLLCjHrpErEREREanFlFxJpevQxB+LBQ4kn+JoWqbZ4YiIiIiIVAolV1Lp/DxcCW/oA8AWlWQXERERkVpKyZVUiYj8qYGb47XuSkRERERqJyVXUiWi8ota6GLCIiIiIlJbKbmSKnF2OXbDMMwNRkRERESkEii5kirRNsQXV5uFExnZJJw4ZXY4IiIiIiIVTsmVVAl3FxttQ/wAlWQXERERkdpJyZVUmcj8qYGqGCgiIiIitZGSK6kykQVFLVQxUERERERqISVXUmUi88uxbz2QQk6u3eRoREREREQqlpIrqTItGvrg4+7Cqexcdh9JMzscEREREZEKpeRKqozNaqFD47yiFptV1EJEREREahklV1KlHOuuErTuSkRERERqFyVXUqUiz7qYsIiIiIhIbaLkSqpUwcjVjsSTnM7ONTcYEREREZEKpORKqlSovwcNfNzJsRv8cTDV7HBERERERCqMkiupUhaLxVGSXRcTFhEREZHaRMmVVLkzFxNONjUOEREREZGKpORKqlxE/siVKgaKiIiISG2i5EqqXEHFwD1H00nJyDY3GBERERGRCqLkSqpcoLcbTet7AbDlQLK5wYiIiIiIVBDTk6vZs2fTrFkzPDw86NatG+vXry+27R9//MEtt9xCs2bNsFgszJw5s1CbSZMmYbFYnG5t2rSpxDOQsojIH73aoqmBIiIiIlJLmJpcLVmyhDFjxjBx4kQ2bdpEZGQkMTExHD58uMj2GRkZtGjRghdffJHg4OBi+23fvj2HDh1y3NasWVNZpyBlVFAxME5FLURERESkljA1uZoxYwb33nsvI0aMoF27dsydOxcvLy8WLFhQZPsuXbrw8ssvM2TIENzd3Yvt18XFheDgYMetQYMGlXUKUkaqGCgiIiIitY1pyVVWVhYbN24kOjr6TDBWK9HR0axdu7Zcfe/atYvQ0FBatGjBHXfcwf79+8/bPjMzk9TUVKebVK72oX7YrBYOn8wkMeW02eGIiIiIiJSbacnV0aNHyc3NJSgoyGl7UFAQiYmJZe63W7duvPPOO6xYsYI5c+awZ88errzySk6ePFnsPlOnTsXf399xCwsLK/PxpWS83Fxo1cgH0NRAEREREakdTC9oUdGuu+46brvtNiIiIoiJieHrr78mOTmZpUuXFrvP+PHjSUlJcdzi4+OrMOK6Kyp/auCWhGRT4xARERERqQimJVcNGjTAZrORlJTktD0pKem8xSpKKyAggNatW7N79+5i27i7u+Pn5+d0k8rnWHel5EpEREREagHTkis3Nzc6depEbGysY5vdbic2Npbu3btX2HHS0tL466+/CAkJqbA+pWJE5FcM3JKQgt1umByNiIiIiEj5mDotcMyYMcyfP59Fixaxfft2Ro4cSXp6OiNGjABg6NChjB8/3tE+KyuLuLg44uLiyMrK4sCBA8TFxTmNSo0bN44ffviBvXv38vPPP3PTTTdhs9m4/fbbq/z85PxaB/ni4Wrl5Okc9hxLNzscEREREZFycTHz4IMHD+bIkSNMmDCBxMREoqKiWLFihaPIxf79+7Faz+R/Bw8e5JJLLnHcnz59OtOnT6dXr16sXr0agISEBG6//XaOHTtGw4YNueKKK/jll19o2LBhlZ6bXJirzUr7UH827jvB5vhkwhv6mB2SiIiIiEiZWQzD0Hysc6SmpuLv709KSorWX1WyZ7/YxoKf9jC8RzMmDWhvdjgiIiIiIk5KkxvUumqBUrNEhuWtu1I5dhERERGp6ZRciakimwQAsO1QKlk5dnODEREREREpByVXYqqm9b3w93QlK8fOjsTiL/QsIiIiIlLdKbkSU1ksFkdJdl3vSkRERERqMiVXYrqogosJa92ViIiIiNRgSq7EdBH56640ciUiIiIiNZmSKzFdZP60wF2H00jLzDE5GhERERGRslFyJaZr5OdBqL8HhgG/H0gxOxwRERERkTJRciXVQsHUwC2aGigiIiIiNZSSK6kWIh1FLTRyJSIiIiI1k5IrqRYiVY5dRERERGo4JVdSLXRo4o/FAgknTnE0LdPscERERERESk3JlVQLfh6utGjgDWjdlYiIiIjUTEqupNrQuisRERERqcmUXEm1EVWQXGnkSkRERERqICVXUm2cKceegmEY5gYjIiIiIlJKSq6k2mgb4ourzcLx9CwSTpwyOxwRERERkVJRciXVhruLjbYhfgDExSebG4yIiIiISCkpuZJqJdIxNTDZ1DhEREREREpLyZVUKxEFFxNWxUARERERqWGUXEm1UlAxcOuBFHJy7eYGIyIiIiJSCkqupFpp0dAHH3cXTmXnsvtImtnhiIiIiIiUmJIrqVZsVgsdGucVtdiiqYEiIiIiUoMouZJqJzJ/amCcilqIiIiISA2i5EqqnYKKgZtVjl1EREREahAlV1LtFIxc7Ug8yensXHODEREREREpISVXUu2E+nvQwMeNHLvBHwdTzQ5HRERERKRElFxJtWOxWHQxYRERERGpcZRcSbVUMDVQ665EREREpKZQciXVUkQTfwC2JKgcu4iIiIjUDEqupFoqmBb499F0UjKyzQ1GRERERKQElFxJtRTo7cZF9bwA2HIg2dxgRERERERKQMmVVFsF6640NVBEREREagIlV1JtReavu4pTUQsRERERqQGUXEm1dWbkKtnUOERERERESkLJlVRb7UP9sFktJKVmkphy2uxwRERERETOS8lVdZd+FFISzI7CFF5uLrRq5APAZo1eiYiIiEg1p+Squvvv4zC7G6yfD3a72dFUuShdTFhEREREagglV9VZVkbeqFVWGnw9Dt65AY7uMjuqKhWRf70rjVyJiIiISHWn5Ko6c/OCESvgupfB1Rv2/wxzLocfX4HcunFh3ciwvIqBWxJSsNsNk6MRERERESmekqvqzmqFbvfBqF+gZTTkZkLsszD/ajgYZ3Z0la51kC8erlZOns5hz7F0s8MRERERESmWkquaIuAiuOMjuOlN8AyExK0w/xpYNRGyT5kdXaVxtVlpH1owepVsbjAiIiIiIudhenI1e/ZsmjVrhoeHB926dWP9+vXFtv3jjz+45ZZbaNasGRaLhZkzZ5a7zxrFYoHIITBqPbS/GYxc+Glm3lTBvT+ZHV2liSxYdxWfYm4gIiIiIiLnYWpytWTJEsaMGcPEiRPZtGkTkZGRxMTEcPjw4SLbZ2Rk0KJFC1588UWCg4MrpM8ayacR3LYQhnwAviFw/C9453r48lE4nWp2dBWuYN1VnCoGioiIiEg1ZmpyNWPGDO69915GjBhBu3btmDt3Ll5eXixYsKDI9l26dOHll19myJAhuLu7V0ifNVqbG+CBX+DSYXn3f10Ab1wGO1eaG1cFKxi52nYolayculeOXkRERERqBtOSq6ysLDZu3Eh0dPSZYKxWoqOjWbt2bZX2mZmZSWpqqtOtxvAMgAGvwbAvILA5pB6ADwbBR3fnXYC4Fmha3wt/T1eycuzsSDxpdjgiIiIiIkUyLbk6evQoubm5BAUFOW0PCgoiMTGxSvucOnUq/v7+jltYWFiZjm+q5j1h5M/Q42GwWOH3j2BWF9iyDIyaXcLcYrEQ0SRvaqCudyUiIiIi1ZXpBS2qg/Hjx5OSkuK4xcfHmx1S2bh5QZ8pcE8sBHWAU8fhk3vgg8F5FyOuwaLCAgDYrHVXIiIiIlJNmZZcNWjQAJvNRlJSktP2pKSkYotVVFaf7u7u+Pn5Od1qtMaXwn2r4ZqnweYGu1bC7Mtgw1tgr5lrliLy111tSVDFQBERERGpnkxLrtzc3OjUqROxsbGObXa7ndjYWLp3715t+qyxbK7Q8zH4vzUQ1g2yTsJXY+GdG+DoLrOjK7XI/GmBOw+fJC0zx+RoREREREQKM3Va4JgxY5g/fz6LFi1i+/btjBw5kvT0dEaMGAHA0KFDGT9+vKN9VlYWcXFxxMXFkZWVxYEDB4iLi2P37t0l7rPOaXgxjFgB170Mrt6w/+e862L9OANys82OrsQa+XkQ4u+BYcDvBzR6JSIiIiLVj4uZBx88eDBHjhxhwoQJJCYmEhUVxYoVKxwFKfbv34/Veib/O3jwIJdcconj/vTp05k+fTq9evVi9erVJeqzTrJaodt9cHFf+GI0/BULsZPhj0/gxtkQEml2hCUS2SSAQymJbElI5rIW9c0OR0RERETEicUwangpuUqQmpqKv78/KSkpNX/91bkMAzZ/CCvHw6kTYLHB5Q9DryfA1dPs6M5rzuq/mLbiT27oGMLsOy41OxwRERERqQNKkxuoWmBdY7FA1O0waj20vwmMXFjzb5h7Bez72ezozitS5dhFREREpBpTclVX+TSC296BIR+Abwgc2w0Lr4Mvx8Dp6nkR5Q5N/LFYIOHEKY6lZZodjoiIiIiIEyVXdV2bG+CBX+DSYXn3f30b3rgMdq40N64i+Hm40qKBN6CS7CIiIiJS/Si5EvAMgAGvwbAvILA5pB6ADwbBx/dA+lGzo3MSmX8x4ThdTFhEREREqhklV3JG854w8mfo8RBYrLB1GczuCluW5RXCqAYi8y8mrHVXIiIiIlLdKLkSZ25e0Oc5uOdbaNQeMo7BJ/fAB4MhJcHs6BwjV1sSUlChSxERERGpTpRcSdEad4L7VsPVT4PNDXathNmXwYa3wG43Lay2Ib642iwcT88i4cQp0+IQERERETmXkispnosb9HoM7v8RmnSFrJPw1Vh45wY4utuUkNxdbLQNybu+gKYGioiIiEh1ouRKLqxRG/jnCrjuJXD1hv0/w5we8OMMyM2u8nAc665U1EJEREREqhElV1IyVht0ux8eWAvh10BuJsROhvnXwKHNVRpKhONiwirHLiIiIiLVh5IrKZ3ApnDnJzBwLngEQOIWmHc1fDsJsqtmDVRUflGLrQkp5OSat/5LRERERORsSq6k9CwWiLodHtwA7QaCkQtr/g1zr4B9P1f64Vs09MHbzcap7Fx2H0mr9OOJiIiIiJSEkispO59GMGgRDH4ffILh2G5YeB18OQZOp1baYW1WCx3zpwZuidfUQBERERGpHpRcSfm17Qej1sGlw/Lu//o2vHEZ7FxZaYcsuN5VnCoGioiIiEg1oeRKKoZnAAx4DYZ+DoHNIPUAfDAIPr4H0o9W+OEKKgZuUXIlIiIiItWEkiupWC16wci10P1BsFhh6zKY3RW2fgSGUWGHKRi5+vPQSU5n51ZYvyIiIiIiZaXkSiqemxfEPA/3fAuN2kPGMfj4bvjPEEg5UCGHCPX3oIGPGzl2gz8OVt76LhERERGRklJyJZWncSe4bzVc/S+wusLOFTC7G2x4G+zlK6FusVg0NVBEREREqhUlV1K5XNyg1+Pwf2ugSVfIOglfjYFF/eDo7nJ1HZGfXG2OTy5/nCIiIiIi5aTkSqpGozbwzxXQdxq4esG+n2BOj7zrY+XmlKnLyLD8cuwJKscuIiIiIuZTciVVx2qDy/4PHvgFwq+B3Ez4dhLMvxoObS51dwXTAv8+mk7KqeyKjVVEREREpJSUXEnVC2wKd34CA+eARwAkboF5V8O3kyH7dMm78XbjonpeAGzV6JWIiIiImEzJlZjDYoGof8CDG6DdQDByYc0MmHs57Pu5xN0UlGTfrKIWIiIiImIyJVdiLp9GMGgRDH4ffILh2G5YeB18NRZOX7jEemSTvHVXcSpqISIiIiImU3Il1UPbfjBqHVw6NO/+hrfgje6w85vz7lYwcqVy7CIiIiJiNiVXUn14BsCA12HoZxDYDFIT4IPb4ON7If1Ykbu0D/XDZrWQlJpJYkrJ12uJiIiIiFQ0JVdS/bS4Ckauhe4PgsUKW5fC7C6w9SMwDKemXm4utGrkA2jdlYiIiIiYS8mVVE9uXhDzPNz9LTRqBxnH4OO74T9DIOWAU9OogqIWWnclIiIiIiZSciXVW5NOcN8PcPW/wOoKO1fA7G6w4W2w2wGIyL/elS4mLCIiIiJmUnIl1Z+LG/R6HP7vR2jSBbJOwldjYFE/OLqbyLC8ioGbE5Kx240LdCYiIiIiUjmUXEnN0agt/HMl9J0Grl6w7yeYezlt/lqAl4vBydM57DmWbnaUIiIiIlJHKbmSmsVqg8v+Dx74BVpcDTmnscVO4guPibSz7FVJdhERERExjZIrqZkCm8Jdn8LAOeARQHjObj53e5r6v0yDbJVkFxEREZGqp+RKai6LBaL+AaPWcyC0Dy4WOz2T3oW5V8C+tWZHJyIiIiJ1jJIrqfl8g8i++R3uz3qUw0YAHNsFC/vCV2Mh86TZ0YmIiIhIHaHkSmqFpvW9+MW9B9GZL3G89ZC8jRvegvnXwOHt5gYnIiIiInWCkiupFSwWCxFN/EnFh69bPAVDPwPfUDi6My/B2rLM7BBFREREpJZTciW1RmT+xYQ3xydDi6vg/v9B816QnQGf3JM3TTAn08wQRURERKQWU3IltUZkWAAAWxJS8jb4NMyrKNjzsbz7G96CBX0heb85AYqIiIhIrabkSmqNyCb+AOw6fJL0zJy8jVYbXPM03PEReAbCwU0w90rY+Y2JkYqIiIhIbaTkSmqNRn4ehPh7YDfg9wMpzg+2ujZvmmDopXA6GT64Db57Duy5psQqIiIiIrWPkiupVRzrrhKSCz8YcBH8cwV0uSfv/v9ehvduhvSjVRafiIiIiNRe1SK5mj17Ns2aNcPDw4Nu3bqxfv3687ZftmwZbdq0wcPDg44dO/L11187PT58+HAsFovTrW/fvpV5ClJNRITlTQ3cHJ9SdAMXd7jhFbj5LXD1gr9X500T3L+u6oIUERERkVrJ9ORqyZIljBkzhokTJ7Jp0yYiIyOJiYnh8OHDRbb/+eefuf3227n77rv57bffGDhwIAMHDuT33393ate3b18OHTrkuP3nP/+pitMRk0Wdb+TqbBG3wb3fQf1WcPIgvHM9rH0DDKPSYxQRERGR2sliGOb+NtmtWze6dOnCrFmzALDb7YSFhfHQQw/x5JNPFmo/ePBg0tPT+fLLLx3bLrvsMqKiopg7dy6QN3KVnJzM8uXLyxRTamoq/v7+pKSk4OfnV6Y+xBypp7OJnPwNhgEbn46mvo/7+XfIPAmfPwx/fJJ3v91AGPA6eOh1FxEREZHS5QamjlxlZWWxceNGoqOjHdusVivR0dGsXbu2yH3Wrl3r1B4gJiamUPvVq1fTqFEjLr74YkaOHMmxY8eKjSMzM5PU1FSnm9RMfh6utGjgDZxVkv183H3h1gVw3UtgdYVty2H+1ZC0rXIDFREREZFax9Tk6ujRo+Tm5hIUFOS0PSgoiMTExCL3SUxMvGD7vn378u677xIbG8u0adP44YcfuO6668jNLboy3NSpU/H393fcwsLCynlmYqaC613FxSeXbAeLBbrdDyP+C36N4dhumH8NbP6w0mIUERERkdrH9DVXlWHIkCEMGDCAjh07MnDgQL788ks2bNjA6tWri2w/fvx4UlJSHLf4+PiqDVgqVEHFwC0XWnd1rrAueeXaW1wNOafg0/vhi9GQfbqiQxQRERGRWsjU5KpBgwbYbDaSkpKcticlJREcHFzkPsHBwaVqD9CiRQsaNGjA7t27i3zc3d0dPz8/p5vUXAUjV5sTUij1kkLvBnDnx9DrScACGxfCghg4sbeiwxQRERGRWsbU5MrNzY1OnToRGxvr2Ga324mNjaV79+5F7tO9e3en9gCrVq0qtj1AQkICx44dIyQkpGICl2qtbYgvrjYLx9OzSDhxqvQdWG1w9Xi48yPwrAeH4uDNXrBzZYXHKiIiIiK1h+nTAseMGcP8+fNZtGgR27dvZ+TIkaSnpzNixAgAhg4dyvjx4x3tH3nkEVasWMErr7zCn3/+yaRJk/j111958MEHAUhLS+Oxxx7jl19+Ye/evcTGxnLjjTfSsmVLYmJiTDlHqVruLjbahuSNPl6wJPv5tIzOmybYuDOcToYPBkHss2Aveu2eiIiIiNRtpidXgwcPZvr06UyYMIGoqCji4uJYsWKFo2jF/v37OXTokKN9jx49+OCDD5g3bx6RkZF89NFHLF++nA4dOgBgs9nYsmULAwYMoHXr1tx999106tSJH3/8EXf3C5TlllqjYN3V819t5z/r95Oday9bRwFheYUuut6Xd//HV2DxQEgr+jpsIiIiIlJ3mX6dq+pI17mq+fYcTef2eb+QmJpXjOKiel480rsVAy9pjM1qKVunWz/KuyZWdjr4hsCtC6Fp8dNRRURERKTmK01uoOSqCEquaofT2bl8sG4/b6zezdG0LABaNPTm0ejW3NAxBGtZkqwjO2DJXXB0B1hscO2z0H1UXjl3EREREal1lFyVk5Kr2iUjK4d31+5j7g9/kZyRDUCbYF8evbY1fdoFYSltYpSZBl88Ar9/lHe/bX+4cTZ4+Fdw5CIiIiJiNiVX5aTkqnY6eTqbBWv28taPf3MyMweAiCb+PHpta65q3bB0SZZhwIa3YMV4sGdDvRYwaDEEd6ik6EVERETEDEquyknJVe2WnJHF/B//ZuFPe8nIyqv816lpIGP7tKZHeIPSdZawEZYNg5R4cPGEfjMg6h+VELWIiIiImEHJVTkpuaobjqVlMveHv3h37T4yc/KqCXZvUZ+xfVrTuVm9kneUcRw+uRd2f5t3/9KhcN3L4OpRCVGLiIiISFVSclVOSq7qlqTU07zx/W4+WL+f7Ny8j0Ov1g0Z26c1Efkl3S/Ibocfp8P3LwAGBEfAoHehXvNKi1tEREREKp+Sq3JSclU3HUg+xazvdrH01wRy7Xkfiz7tgnj02taOixJf0F/fwcf3QMaxvAIXN70JF19XiVGLiIiISGVSclVOSq7qtn3H0nk1dhfLfztAfo5Fv4gQRke3pmUjnwt3kJIAy4ZDwoa8+1c8Clc/DTaXSotZRERERCqHkqtyUnIlALsPpzHz2518ueUQAFYLDLykMY/0bkXT+t7n3zknC1ZNgHVz8u43uxJueRt8gyo5ahERERGpSEquyknJlZxt+6FUZqzayaptSQC4WC3c1rkJD17TisYBnuff+fdP4POHICsNfILhtoXQtEcVRC0iIiIiFUHJVTkpuZKibI5PZsaqnfyw8wgAbjYrt3cNY9TVLWnkd57KgEd2wtKhcGQ7WGwQPQl6PASlvXixiIiIiFQ5JVflpORKzufXvcd55ZudrP37GADuLlaG9WjG/T1bUN/HveidstLhy0dhy5K8+236wY2zwTOgaoIWERERkTJRclVOSq6kJH7efZRXVu1k474TAHi52fjn5c2598oW+Hu5Ft7BMODXBbDiScjNgsDmeeXaQyKqOHIRERERKSklV+Wk5EpKyjAMVu88woxvdrL1QAoAvh4u3HtlC0Zc3gxfjyKSrAObYOkwSNkPLh5w/XS49K4qjlxERERESkLJVTkpuZLSMgyDb7Yl8e9VO/kz8SQAAV6u/F+vcIZ2b4qX2zll2DOOw6f3w65v8u5fcmdekuV6gQIZIiIiIlKllFyVk5IrKSu73eCrrYf497c7+ftIOgANfNx44KqW/KPbRXi42s5uDGtege9fAMMOwR3zpgnWa2FS9CIiIiJyLiVX5aTkSsorJ9fOZ3EHmRm7k/jjpwAI9vPgwWtaMqhzGG4u1jON/14NH90NGUfB3R8GvgFt+5kTuIiIiIg4UXJVTkqupKJk59r5aGMCr8Xu4lDKaQCaBHrycO9W3HxJY1xs+UlW6kFYNhzi1+Xd7/Ew9J4INpeiOxYRERGRKqHkqpyUXElFO52dy4fr9zN79V8cOZkJQPMG3oyObkW/iFBsVgvkZsO3k2DtrLydml4Oty4A32DzAhcRERGp45RclZOSK6ksp7JyWfzLXub+8DfH07MAaB3kw5hrWxPTPhiLxQLbPoPloyDrJHg3ykuwml9pcuQiIiIidZOSq3JSciWVLS0zh3d+2sO8//1N6ukcANqH+jG2T2uuvrgRlmN/wdKhcPgPsFih9wTo8QhYrRfoWUREREQqkpKrclJyJVUl5VQ2b//4N2+v2UN6Vi4AUWEBjOtzMZc39cTy1VjY/J+8xhdfn1fswjPQxIhFRERE6hYlV+Wk5Eqq2vH0LN78318s+nkvp7PtAHRrXo+x17am64kv4OvHITcTAprC4MUQEmlyxCIiIiJ1g5KrclJyJWY5fPI0b3z/Fx+s209Wbl6SdWWrBjx9aRYX//AAJO8Hmztc/zJcOhQsFpMjFhEREandlFyVk5IrMdvB5FPM+n43SzfEk2PP+4gOaO3J88zCd39sXqOoO+D66eDmZWKkIiIiIrWbkqtyUnIl1cX+Yxm89t0uPtmUgN0AC3ZmNl7NgOMLsBh2COoAg96F+uFmhyoiIiJSKym5KiclV1Ld/HUkjVe/3cUXWw5iGNDd+gfzPN/AN/cEuPvBjbOh3QCzwxQRERGpdUqTG6ius0gNEN7Qh9duv4QVj/Skb/tg1trb0zv9Odbb20BmKiy9C1b+K+9CxCIiIiJiCiVXIjXIxcG+zL2rE188eAXtL27NP7Ke4s2cG/IeXDuLrLdvgNRD5gYpIiIiUkdpWmARNC1QaoqN+04wY9UOfP5ewcuuc/GznCLNJZCcm94moH1vs8MTERERqfE0LVCkjujUNJD377mM4Xc/xL8avs52+0X45JzAd+kt/PD2k5xIO212iCIiIiJ1hkauiqCRK6mJDMNgzfYEMj97lOjMVQCsNi5l22Uvc+fVkfh5uJocoYiIiEjNo2qB5aTkSmoywzDY9tVsWv06CTeyibc35DHrWK7sdS3DezTD293F7BBFREREagxNCxSpwywWC+37PYjLvd+S7h1GmPUIi4ynSfj2DXpO+463fvyb09m5ZocpIiIiUuto5KoIGrmSWuNUMsbykVh2fA3Ax7lX8K/su/Hz9ePBa1oyuEsY7i42k4MUERERqb40ciUieTwDsAz5AKInY1hs3GJbw1eeE/FO28uEz/7gmuk/sGTDfrJz7WZHKiIiIlLjaeSqCBq5klpp7xr46J+QlkSWzZsJjOTD9EsBaFrfi9HRrRgQ2Rib1WJyoCIiIiLVhwpalJOSK6m1TibmJVj7fgJga9gd3HOgP0kZeSNXLRv58Gh0a/p2CFaSJSIiIoKSq3JTciW1Wm4OfPcs/PRq3t3GXVkcNol/r0sn5VS2o5m3mw0fDxe83V3wdXfBx8MFH/dz77vm/2vL+7+7C75nt/Nwwd3FisWiRE1ERERqJiVX5aTkSuqEP7+CT0dCZgp4NSB9wJvMi7+IBWv2cDIzp8IO42K1OBIzx62Y+775ydyZJC0/eXNzwdvdhotNy0RFRESkaim5KiclV1JnHP8blg6FxK2ABa7+F9mXP0rK6VzSTueQlpl/O/v/Z90/eTqH9PxtJzNzSDudTXpmrqNdRfN0tRWZmPnmj5SdnaQVHmU786+nq02jaSIiIlIiNS65mj17Ni+//DKJiYlERkby+uuv07Vr12LbL1u2jGeeeYa9e/fSqlUrpk2bxvXXX+943DAMJk6cyPz580lOTubyyy9nzpw5tGrVqkTxKLmSOiX7FPz3cdj0bt79ltfC1U+BiwdYbWB1Oevf/JvF6nzf6gJW51Elu90gPSsvyUrPT8QKJWqnzyRm6fn3T+b/m5515n5WTsVWM7RayE/CXPF2t+UnXq55idhZiZrvuaNsZ/2/YJTNVaNpIiIitVqNSq6WLFnC0KFDmTt3Lt26dWPmzJksW7aMHTt20KhRo0Ltf/75Z3r27MnUqVPp168fH3zwAdOmTWPTpk106NABgGnTpjF16lQWLVpE8+bNeeaZZ9i6dSvbtm3Dw8PjgjEpuZI66bf34asxkHO6jB1YzknEzknIrDawFLGtBPvkWmzkGDaysZJtt5JlWMmyQ5bdSqbdSqbdQmauhdOOG5zKsZCRa+FUDmTkWEjPgfRsyDWs5GIjB+d/c7GSg41cI//fgvv5/y/8eN6+Li4ueLq74enujqurKxaLFasVLBZr/v8t2KwWLBYLVgvYrBasloIbef9azzxmyX/Mds5jTu0sZ7WzFtHurMcKtSs4rrUk7ZzbFrSznecxa/7jFqdzPatd/mNWa0E/eftZLGAh//+Qfz9v49mPWfO3Fww8Ws66X2h/jU6KiEgFqFHJVbdu3ejSpQuzZs0CwG63ExYWxkMPPcSTTz5ZqP3gwYNJT0/nyy+/dGy77LLLiIqKYu7cuRiGQWhoKGPHjmXcuHEApKSkEBQUxDvvvMOQIUMuGJOSK6mzErfCV2MheT/Yc/Jvuc7/GrlmR1nj2A0LBmBgyb+BgbXQNnv+NjjT3u543HLWY2dvP6uPIo5jz7+coXFOe3teClJoW0mOk3dOZ8d/dv9F98k57exn3cdxTBz9G8Vsy/u3wDnbDc7a90xbiyVvm6WgrQUw8v/F4uirYJOjreXMYwX3LWcdLy/DO9PG8d/841vOun/mMatjU8Fxzjx+1vEsFkfszjE6x3JWx07nefbz49S30zmeHddZ5+kUe17HZz8vBc7EcKaN8z75r4HTYaxnNzn3P86Rnx2E5eyztZy16ZxzcLRzfu3OfQ7OOfFzFP2Ycb59zpPIF/9L1vn2Ke6x8+xT7EMVfJxz3nOF9jjnPXWBzWfeJ8X1V0R7w+k9cG60RcduKS6uc455bt/F9njOZ7O4/ooJoBqqnvG5efnR6/oL/+5e2UqTG7hUUUxFysrKYuPGjYwfP96xzWq1Eh0dzdq1a4vcZ+3atYwZM8ZpW0xMDMuXLwdgz549JCYmEh0d7Xjc39+fbt26sXbt2iKTq8zMTDIzMx33U1NTy3NaIjVXcEe4+5vztzGMsxKu/Jthd77vSMZyi0jScs4kaeduK7TPOfsZuUX3ZT/3+LnntK+MfbLP/zydxWo5kyacUQlJavX82Vh7nPtbsumT6kVEarf91sZQDZKr0jA1uTp69Ci5ubkEBQU5bQ8KCuLPP/8scp/ExMQi2ycmJjoeL9hWXJtzTZ06lcmTJ5fpHETqHIsFbC55t7quINk6OyFzDJ/kjctgGHnJZ8H/L7itrPsapThG9dvXwKBgIoVhFGwDDHv+v2ceK7hvcHa7/P3O6ufsNo5+z/33zM7n9Gc4HZcijpu3p1FMG845bsGt4HD2Qvuc6S//fwWx5T8PjofOfh7PtMBS0JdTf4XvF4wJnpm3UtR94+yHzmw/t9+CqI1ztp47Keac4zs3L9z23LidYijiMaNQ23PjN878e26XRfV9FkvxO5xnn+Kal/YYpdtuqbBzK915nfteKklf5z50dquz4zrfs+/c4IItCx/n3PdQiToow3Gq7C8xVXUc5+euMp3yCq2S41Qk/XYEjB8/3mk0LDU1lbCwMBMjEpEawWoFq5vZUdQKZ0+wExERqalMLXPVoEEDbDYbSUlJTtuTkpIIDg4ucp/g4ODzti/4tzR9uru74+fn53QTEREREREpDVOTKzc3Nzp16kRsbKxjm91uJzY2lu7duxe5T/fu3Z3aA6xatcrRvnnz5gQHBzu1SU1NZd26dcX2KSIiIiIiUl6mTwscM2YMw4YNo3PnznTt2pWZM2eSnp7OiBEjABg6dCiNGzdm6tSpADzyyCP06tWLV155hRtuuIEPP/yQX3/9lXnz5gF5pXdHjx7Nc889R6tWrRyl2ENDQxk4cKBZpykiIiIiIrWc6cnV4MGDOXLkCBMmTCAxMZGoqChWrFjhKEixf/9+rGddnLRHjx588MEHPP300zz11FO0atWK5cuXO65xBfD444+Tnp7OfffdR3JyMldccQUrVqwo0TWuREREREREysL061xVR7rOlYiIiIiIQOlyA1PXXImIiIiIiNQWSq5EREREREQqgJIrERERERGRCqDkSkREREREpAIouRIREREREakASq5EREREREQqgJIrERERERGRCqDkSkREREREpAIouRIREREREakASq5EREREREQqgJIrERERERGRCqDkSkREREREpAIouRIREREREakALmYHUB0ZhgFAamqqyZGIiIiIiIiZCnKCghzhfJRcFeHkyZMAhIWFmRyJiIiIiIhUBydPnsTf3/+8bSxGSVKwOsZut3Pw4EF8fX2xWCxmhyNllJqaSlhYGPHx8fj5+ZkdjtRyer9JVdN7TqqS3m9S1arTe84wDE6ePEloaChW6/lXVWnkqghWq5UmTZqYHYZUED8/P9M/lFJ36P0mVU3vOalKer9JVasu77kLjVgVUEELERERERGRCqDkSkREREREpAIouZJay93dnYkTJ+Lu7m52KFIH6P0mVU3vOalKer9JVaup7zkVtBAREREREakAGrkSERERERGpAEquREREREREKoCSKxERERERkQqg5EpERERERKQCKLmSWmXq1Kl06dIFX19fGjVqxMCBA9mxY4fZYUkd8eKLL2KxWBg9erTZoUgtduDAAe68807q16+Pp6cnHTt25NdffzU7LKmlcnNzeeaZZ2jevDmenp6Eh4czZcoUVA9NKsr//vc/+vfvT2hoKBaLheXLlzs9bhgGEyZMICQkBE9PT6Kjo9m1a5c5wZaAkiupVX744QdGjRrFL7/8wqpVq8jOzqZPnz6kp6ebHZrUchs2bODNN98kIiLC7FCkFjtx4gSXX345rq6u/Pe//2Xbtm288sorBAYGmh2a1FLTpk1jzpw5zJo1i+3btzNt2jReeuklXn/9dbNDk1oiPT2dyMhIZs+eXeTjL730Eq+99hpz585l3bp1eHt7ExMTw+nTp6s40pJRKXap1Y4cOUKjRo344Ycf6Nmzp9nhSC2VlpbGpZdeyhtvvMFzzz1HVFQUM2fONDssqYWefPJJfvrpJ3788UezQ5E6ol+/fgQFBfH22287tt1yyy14enry3nvvmRiZ1EYWi4VPP/2UgQMHAnmjVqGhoYwdO5Zx48YBkJKSQlBQEO+88w5DhgwxMdqiaeRKarWUlBQA6tWrZ3IkUpuNGjWKG264gejoaLNDkVru888/p3Pnztx22200atSISy65hPnz55sdltRiPXr0IDY2lp07dwKwefNm1qxZw3XXXWdyZFIX7Nmzh8TERKefr/7+/nTr1o21a9eaGFnxXMwOQKSy2O12Ro8ezeWXX06HDh3MDkdqqQ8//JBNmzaxYcMGs0OROuDvv/9mzpw5jBkzhqeeeooNGzbw8MMP4+bmxrBhw8wOT2qhJ598ktTUVNq0aYPNZiM3N5fnn3+eO+64w+zQpA5ITEwEICgoyGl7UFCQ47HqRsmV1FqjRo3i999/Z82aNWaHIrVUfHw8jzzyCKtWrcLDw8PscKQOsNvtdO7cmRdeeAGASy65hN9//525c+cquZJKsXTpUt5//30++OAD2rdvT1xcHKNHjyY0NFTvOZEiaFqg1EoPPvggX375Jd9//z1NmjQxOxyppTZu3Mjhw4e59NJLcXFxwcXFhR9++IHXXnsNFxcXcnNzzQ5RapmQkBDatWvntK1t27bs37/fpIiktnvsscd48sknGTJkCB07duSuu+7i0UcfZerUqWaHJnVAcHAwAElJSU7bk5KSHI9VN0qupFYxDIMHH3yQTz/9lO+++47mzZubHZLUYr1792br1q3ExcU5bp07d+aOO+4gLi4Om81mdohSy1x++eWFLi+xc+dOmjZtalJEUttlZGRgtTr/umiz2bDb7SZFJHVJ8+bNCQ4OJjY21rEtNTWVdevW0b17dxMjK56mBUqtMmrUKD744AM+++wzfH19HfNx/f398fT0NDk6qW18fX0Lrefz9vamfv36WucnleLRRx+lR48evPDCCwwaNIj169czb9485s2bZ3ZoUkv179+f559/nosuuoj27dvz22+/MWPGDP75z3+aHZrUEmlpaezevdtxf8+ePfx/O/cTEtUagGH8OWFNM1OBJtkYREYmFhREQZKLrEUaBIURxRAzLRKppIggkiaNXNfOgaJsURQYGBL9gYI2QtRGc2HRMhCxiMCE2uhdBAODce/lcnS84/ODA3O+c2bm/ZYv53zf4OAgZWVlrF27lnPnztHV1UV1dTVVVVVkMhkqKytzOwrON27FrqISBMEfx3t6ekin03MbRgvS7t273Ypds+rJkydcunSJT58+UVVVxfnz5zl58mShY6lITUxMkMlk6OvrY3x8nMrKSo4dO8aVK1dYsmRJoeOpCLx+/ZqGhoYZ46lUirt37zI9PU1HRwc3b97k+/fv1NfX093dzcaNGwuQ9p9ZriRJkiQpBK65kiRJkqQQWK4kSZIkKQSWK0mSJEkKgeVKkiRJkkJguZIkSZKkEFiuJEmSJCkElitJkiRJCoHlSpIkSZJCYLmSJClkQRDw+PHjQseQJM0xy5Ukqaik02mCIJhxNDY2FjqaJKnIlRQ6gCRJYWtsbKSnpydvLBKJFCiNJGmh8MmVJKnoRCIRVq9enXeUlpYCv1/Zy2azNDU1EY1GWb9+PY8ePcr7/vDwMHv27CEajbJy5UpaWlr48eNH3j137txh8+bNRCIREokEZ86cybv+9etXDh06RCwWo7q6mv7+/tmdtCSp4CxXkqQFJ5PJ0NzczNDQEMlkkqNHjzIyMgLA5OQk+/bto7S0lHfv3tHb28vLly/zylM2m+X06dO0tLQwPDxMf38/GzZsyPuPq1evcuTIEd6/f8/+/ftJJpN8+/ZtTucpSZpbwfT09HShQ0iSFJZ0Os29e/dYunRp3nh7ezvt7e0EQUBrayvZbDZ3befOnWzbto3u7m5u3brFxYsX+fz5M/F4HICnT59y4MABRkdHqaioYM2aNZw4cYKurq4/ZgiCgMuXL3Pt2jXgd2FbtmwZz549c+2XJBUx11xJkopOQ0NDXnkCKCsry32uq6vLu1ZXV8fg4CAAIyMjbN26NVesAHbt2sXU1BQfP34kCAJGR0fZu3fv32bYsmVL7nM8HmfFihWMj4//1ylJkv4HLFeSpKITj8dnvKYXlmg0+q/uW7x4cd55EARMTU3NRiRJ0jzhmitJ0oLz5s2bGee1tbUA1NbWMjQ0xOTkZO76wMAAixYtoqamhuXLl7Nu3TpevXo1p5klSfOfT64kSUXn169fjI2N5Y2VlJRQXl4OQG9vL9u3b6e+vp779+/z9u1bbt++DUAymaSjo4NUKkVnZydfvnyhra2N48ePU1FRAUBnZyetra2sWrWKpqYmJiYmGBgYoK2tbW4nKkmaVyxXkqSi8/z5cxKJRN5YTU0NHz58AH7v5Pfw4UNOnTpFIpHgwYMHbNq0CYBYLMaLFy84e/YsO3bsIBaL0dzczPXr13O/lUql+PnzJzdu3ODChQuUl5dz+PDhuZugJGlecrdASdKCEgQBfX19HDx4sNBRJElFxjVXkiRJkhQCy5UkSZIkhcA1V5KkBcW34SVJs8UnV5IkSZIUAsuVJEmSJIXAciVJkiRJIbBcSZIkSVIILFeSJEmSFALLlSRJkiSFwHIlSZIkSSGwXEmSJElSCP4CiEeQlQ6w4H4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(trainer_history_train_df['epoch'], trainer_history_train_df['loss'], label=\"Training loss\")\n",
    "plt.plot(trainer_history_eval_df['epoch'], trainer_history_eval_df['eval_loss'], label=\"Eval loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Text classificacion fine-tuning DistilBert training and evaluation over time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057b253-8215-4cbb-995d-683c8cac3fe1",
   "metadata": {},
   "source": [
    "### Subiendo nuestro modelo al Hugging Face Hub\n",
    "\n",
    "¬øPor qu√© hacer esto?\n",
    "- Para poder compartir nuestro modelo.\n",
    "- Otras personas pueden probarlo.\n",
    "- Podemos mantener un historial de diferentes versiones del modelo.\n",
    "\n",
    "Para escribir en Hugging Face:\n",
    "- Si est√°s en Google Token: configura el \"token\" con acceso de \"lectura y escritura\".\n",
    "- Si est√°s en una m√°quina local: configura `huggingface-cli`.\n",
    "\n",
    "Para guardar en el Hugging Face Hub, podemos usar el m√©todo `Trainer.push_to_hub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b119752d-3f65-4e87-b874-3cbfd03c3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/acm/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0995627-9ce9-4e36-9b65-d5911fce018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model successfully uploaded to the Hugging Face Hub with URL: https://huggingface.co/tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/tree/main/\n"
     ]
    }
   ],
   "source": [
    "# Save our model to the Hugging Face Hub\n",
    "model_upload_url = trainer.push_to_hub(\n",
    "    commit_message=\"Subiendo el modelo de clasificador de texto de food/not_food\",\n",
    ")\n",
    "print(f\"[INFO] Model successfully uploaded to the Hugging Face Hub with URL: {model_upload_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938c863-cc7d-4995-81f2-85314725f356",
   "metadata": {},
   "source": [
    "## Haciendo y evaluando predicciones en los datos test\n",
    "\n",
    "**Nota**: Evaluar un modelo es tan importante como entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "635ba9ea-68a3-4128-9ac6-392e1b2baf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] M√©tricas de predicci√≥n en la data test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0004733024397864938,\n",
       " 'test_accuracy': 1.0,\n",
       " 'test_runtime': 0.0736,\n",
       " 'test_samples_per_second': 679.015,\n",
       " 'test_steps_per_second': 27.161}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones en el set de test\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "prediction_values = predictions_all.predictions\n",
    "prediction_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] M√©tricas de predicci√≥n en la data test:\")\n",
    "prediction_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bf46b89-d858-4530-8ec2-a39d1ba3bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.5655854,  4.050842 ],\n",
       "       [ 4.108436 , -3.5667434],\n",
       "       [-3.5987396,  4.051071 ],\n",
       "       [ 4.189356 , -3.5941718],\n",
       "       [ 4.174309 , -3.5734787],\n",
       "       [-3.5950534,  4.062822 ],\n",
       "       [ 4.179851 , -3.5814786],\n",
       "       [ 4.1800413, -3.5784364],\n",
       "       [-3.5961647,  4.0515275],\n",
       "       [-3.5851297,  4.040712 ],\n",
       "       [-3.5919209,  4.052533 ],\n",
       "       [-3.5278883,  3.977925 ],\n",
       "       [ 4.1621585, -3.5740569],\n",
       "       [-3.5964828,  4.047571 ],\n",
       "       [-3.575441 ,  4.0346985],\n",
       "       [ 4.193889 , -3.570478 ],\n",
       "       [-3.5895047,  4.049947 ],\n",
       "       [ 4.134468 , -3.565461 ],\n",
       "       [-3.6007972,  4.027627 ],\n",
       "       [-3.6008315,  4.056313 ],\n",
       "       [-3.5901027,  4.021924 ],\n",
       "       [-3.5940216,  4.0449224],\n",
       "       [ 4.157044 , -3.5858703],\n",
       "       [ 4.184146 , -3.5836735],\n",
       "       [-3.6022315,  4.0555916],\n",
       "       [-3.601858 ,  4.031769 ],\n",
       "       [-3.5864644,  4.0300655],\n",
       "       [ 4.173559 , -3.5732865],\n",
       "       [-3.5922463,  4.056378 ],\n",
       "       [ 4.1712446, -3.5756712],\n",
       "       [-3.5953584,  4.052969 ],\n",
       "       [-3.5861163,  4.0251436],\n",
       "       [-3.6032705,  4.0547924],\n",
       "       [ 4.183695 , -3.5825574],\n",
       "       [-3.5894945,  4.040144 ],\n",
       "       [-3.5976434,  4.031395 ],\n",
       "       [-3.5990906,  4.05225  ],\n",
       "       [-3.5894632,  4.0229206],\n",
       "       [ 4.1897984, -3.5634496],\n",
       "       [ 4.141019 , -3.548046 ],\n",
       "       [-3.3491764,  3.7925444],\n",
       "       [-3.5960152,  4.0398884],\n",
       "       [-3.5888462,  4.0464234],\n",
       "       [ 4.1806254, -3.5830078],\n",
       "       [-3.604766 ,  4.0404053],\n",
       "       [-3.5897412,  4.058768 ],\n",
       "       [-3.5865188,  4.0312247],\n",
       "       [-3.5943575,  4.057223 ],\n",
       "       [ 4.186881 , -3.5790954],\n",
       "       [-3.5953913,  4.0139875]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.0004733024397864938, 'test_accuracy': 1.0, 'test_runtime': 0.0736, 'test_samples_per_second': 679.015, 'test_steps_per_second': 27.161})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35c0eb-ead3-4f70-9393-e783b928f478",
   "metadata": {},
   "source": [
    "### Obtengamos las probabilidades predichas y evaluemos manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1882b35c-3213-4ed9-8184-22e7aaa0c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5655854,  4.050842 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo devuelve logits sin procesar\n",
    "predictions_all.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d39360bb-3c2f-4c45-95bd-f8ed451a0492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9206e-04, 9.9951e-01])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax convierte todos los valores para que est√©n entre 0 y 1 y la suma total de los valores sea 1\n",
    "# Esto es lo que se conoce como \"probabilidad de predicci√≥n\"\n",
    "torch.softmax(torch.tensor(predictions_all.predictions[0]), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4ce60-7655-4f00-bc0e-04caa4c482f6",
   "metadata": {},
   "source": [
    "**Nota**: Si deseas un buen m√©todo de evaluaci√≥n, haz predicciones sobre todo tu conjunto de datos de prueba, luego indexa las predicciones que son incorrectas pero tienen una alta probabilidad de predicci√≥n. Por ejemplo, obt√©n las 100-1000 principales y revisa todos los ejemplos donde la predicci√≥n del modelo ten√≠a una alta probabilidad pero fue incorrecta -> esto a menudo conduce a excelentes percepciones sobre tus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cbfd1-3de5-4780-b1a7-670e079fd3aa",
   "metadata": {},
   "source": [
    "**Nota**: Estos valores no sugieren cu√°n \"correcto\" est√° el modelo, porque un modelo puede tener una alta probabilidad de predicci√≥n pero a√∫n as√≠ estar equivocado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69d3c85f-142d-43c9-bbf9-c14fa9cfb0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Test accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Predicted logits (raw outputs of the model) -> prediction probabilities with torch.softmax -> predicted labels\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Obtener prediction probabilities con torch.softmax\n",
    "pred_probs = torch.softmax(torch.tensor(prediction_values), dim=1)\n",
    "pred_probs\n",
    "\n",
    "# 2. Obtener las predicted labels\n",
    "pred_labels = torch.argmax(pred_probs, dim=1)\n",
    "pred_labels\n",
    "\n",
    "# 3. Obtener las true labels\n",
    "true_labels = tokenized_dataset['test']['label']\n",
    "\n",
    "# 4. Calcular las etiquetas de predicci√≥n con las etiquetas reales y obtener la precisi√≥n en el test\n",
    "test_accuracy = accuracy_score(y_true = true_labels,\n",
    "                               y_pred = pred_labels)\n",
    "\n",
    "print(f\"[INFO] Test accuracy: {test_accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57aa62b-1bda-43f8-8850-aa5260c57e50",
   "metadata": {},
   "source": [
    "### Explorando las probabilidades de predicci√≥n de nuestro modelo\n",
    "\n",
    "Es una excelente manera de evaluar un modelo ordenando las predicciones y observando d√≥nde se equivoc√≥ el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b112fee6-6231-45c2-a3b1-a20fdf0bd35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red brick fireplace with a mantel serving as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bowl of sliced bell peppers with a sprinkle ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set of mugs hanging on a hook</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standing floor lamp providing light next to an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_label  pred_label  \\\n",
       "0  A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "1  Red brick fireplace with a mantel serving as a...           0           0   \n",
       "2  A bowl of sliced bell peppers with a sprinkle ...           1           1   \n",
       "3                      Set of mugs hanging on a hook           0           0   \n",
       "4  Standing floor lamp providing light next to an...           0           0   \n",
       "\n",
       "   pred_probs  \n",
       "0    0.999508  \n",
       "1    0.999536  \n",
       "2    0.999524  \n",
       "3    0.999584  \n",
       "4    0.999569  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataFrame of test predictions\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    \"text\": dataset['test']['text'],\n",
    "    \"true_label\": true_labels,\n",
    "    \"pred_label\": pred_labels,\n",
    "    \"pred_probs\": torch.max(pred_probs, dim=1).values\n",
    "})\n",
    "\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa057b23-b609-42ef-a519-3670acc9c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A bowl of cherries with a sprig of mint for ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A close-up shot of a cheesy pizza slice being ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Plate of sushi served with pickled ginger and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Two handfuls of bananas in a fruit bowl with g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Crunchy sushi roll with tempura flakes or pank...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pizza with a seafood theme, featuring toppings...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Close-up of a sushi roll with avocado, cucumbe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A slice of pepperoni pizza with a layer of mel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A fruit platter with a variety of exotic fruit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A bowl of sliced kiwi with a sprinkle of sugar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_label  pred_label  \\\n",
       "40  A bowl of cherries with a sprig of mint for ga...           1           1   \n",
       "11  A close-up shot of a cheesy pizza slice being ...           1           1   \n",
       "49  Plate of sushi served with pickled ginger and ...           1           1   \n",
       "14  Two handfuls of bananas in a fruit bowl with g...           1           1   \n",
       "31  Crunchy sushi roll with tempura flakes or pank...           1           1   \n",
       "20  Pizza with a seafood theme, featuring toppings...           1           1   \n",
       "37  Close-up of a sushi roll with avocado, cucumbe...           1           1   \n",
       "0   A slice of pepperoni pizza with a layer of mel...           1           1   \n",
       "26  A fruit platter with a variety of exotic fruit...           1           1   \n",
       "46  A bowl of sliced kiwi with a sprinkle of sugar...           1           1   \n",
       "\n",
       "    pred_probs  \n",
       "40    0.999209  \n",
       "11    0.999450  \n",
       "49    0.999504  \n",
       "14    0.999505  \n",
       "31    0.999505  \n",
       "20    0.999506  \n",
       "37    0.999506  \n",
       "0     0.999508  \n",
       "26    0.999508  \n",
       "46    0.999509  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra 10 ejemplos con baja prediction probability\n",
    "test_predictions_df.sort_values(\"pred_probs\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600f1ab-d683-4a51-b2bc-a5ba6a8b4c26",
   "metadata": {},
   "source": [
    "## Haciendo y evaluando predicciones en datos personalizados\n",
    "\n",
    "Vamos a probar el modelo para que haga predicciones sobre frases que no est√°n ni en el training set ni en el test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1f1cb31-3405-4244-aab6-da560d82bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "hugging_face_model_path = \"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef9d41-7664-40a9-8b8c-99ac41e2d84e",
   "metadata": {},
   "source": [
    "### Discutiendo formas de hacer predicciones (inferencia)\n",
    "* Nota: Siempre que escuches la palabra \"inferencia\", significa usar un modelo para hacer predicciones sobre datos.\n",
    "\n",
    "Dos formas principales de realizar inferencia:\n",
    "1. **Modo Pipeline** - Usando `transformers.pipeline` para cargar nuestro modelo y realizar clasificaci√≥n de texto.\n",
    "2. **Modo PyTorch** - Usando una combinaci√≥n de `transformers.AutoTokenizer` y `transformers.AutoModelForSequenceClassification` y pasando el nombre de nuestro modelo objetivo.\n",
    "\n",
    "Cada modo soporta:\n",
    "1. Predicciones una a la vez (r√°pido, pero puede ser m√°s lento con muchos, muchos ejemplos).\n",
    "    * √ötil para, por ejemplo, un sistema de comentarios donde los comentarios ocurren de forma espor√°dica, para predecir si el comentario es \"spam\" o \"no spam\".\n",
    "2. Lotes de predicciones a la vez (m√°s r√°pido, pero hasta cierto punto, por ejemplo, si predices 32 ejemplos a la vez, esto puede ser mucho m√°s r√°pido que uno a la vez, pero si predices 128 a la vez, puede que no veas muchas m√°s mejoras en la velocidad).\n",
    "    * √ötil cuando tienes una base de datos est√°tica grande o muchos ejemplos entrando al mismo tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3e9de0a-db18-4666-a432-4639469d5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Definiendo el device para hacer las predicciones\n",
    "# Note: Normalmente si el hardware es m√°s r√°pido, m√°s r√°pidas son las predicciones, \n",
    "# por ejemplo, si tienes una GPU, te conviene usarla en lugar de la CPU \n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "DEVICE = set_device()\n",
    "print(f\"[INFO] Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca05b7-c393-4667-8251-333f5e0c693c",
   "metadata": {},
   "source": [
    "### Haciendo prediciones con el pipeline mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "636afad1-19ba-4493-9747-a5b1fa138f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 13 23:24:19 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8               4W /  80W |   1598MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6469      G   /usr/bin/gnome-shell                          2MiB |\n",
      "|    0   N/A  N/A     15129      C   ...rses/ztm-huggingface/env/bin/python     1592MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66f91271-8c0e-403c-a014-3e3ad2e1b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x752199cc7d50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE = 32 # reminder: prediction speed often increases with higher batch size (e.g. 1->32 but can saturate at even point)\n",
    "\n",
    "# Create an instance of transformers.pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=local_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k=1,\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "food_not_food_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62e0f679-3535-4fe7-85dd-e04dccccb3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9984574317932129}]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_custom_sentence = \"A plate of pizza\" \n",
    "food_not_food_classifier(test_custom_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8aa59e5d-6074-45ad-9cec-d01cdfc3d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipeline\n",
    "del food_not_food_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f651567-2cdd-4258-9b3d-3c9b8dfb4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pipeline with a model from Hugging Face\n",
    "from transformers import pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=hugging_face_model_path,\n",
    "                                    device=DEVICE,\n",
    "                                    top_k=1,\n",
    "                                    batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8ee8d4a-f0db-4dd7-87c2-05444f454d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9984574317932129}]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(test_custom_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da0e22-7eb6-4f58-acd1-afb0be4cca64",
   "metadata": {},
   "source": [
    "#### Hacer m√∫ltiples predicciones al mismo tiempo con predicci√≥n por lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8528f41-d37e-4138-95e5-372a6088cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.9983304142951965}],\n",
       " [{'label': 'not_food', 'score': 0.9984914064407349}],\n",
       " [{'label': 'not_food', 'score': 0.9984080195426941}],\n",
       " [{'label': 'not_food', 'score': 0.9960306286811829}],\n",
       " [{'label': 'not_food', 'score': 0.9941054582595825}],\n",
       " [{'label': 'not_food', 'score': 0.9981845021247864}],\n",
       " [{'label': 'not_food', 'score': 0.9975733160972595}],\n",
       " [{'label': 'food', 'score': 0.9968075752258301}],\n",
       " [{'label': 'not_food', 'score': 0.9991003274917603}],\n",
       " [{'label': 'not_food', 'score': 0.9979191422462463}]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una lista de oraciones para hacer predicciones\n",
    "sentences = [\n",
    "    \"I whipped up a fresh batch of code, but it seems to have a syntax error.\",\n",
    "    \"We need to marinate these ideas overnight before presenting them to the client.\",\n",
    "    \"The new software is definitely a spicy upgrade, taking some time to get used to.\",\n",
    "    \"Her social media post was the perfect recipe for a viral sensation.\",\n",
    "    \"He served up a rebuttal full of facts, leaving his opponent speechless.\",\n",
    "    \"The team needs to simmer down a bit before tackling the next challenge.\",\n",
    "    \"The presentation was a delicious blend of humor and information, keeping the audience engaged.\",\n",
    "    \"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant.\",\n",
    "    \"Daniel Bourke is really cool :D\",\n",
    "    \"My favoruite food is biltong!\"\n",
    "]\n",
    "\n",
    "food_not_food_classifier(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6c177-1ab7-46f2-b94a-3236f930200e",
   "metadata": {},
   "source": [
    "#### Medir el tiempo de nuestro modelo con tama√±os de muestra m√°s grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc1f4e72-a7db-4cef-a420-d92a4891f348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cantidad de frases: 1000\n",
      "[INFO] Tiempo total para realizar predicciones en 1000 frases (una por una): 3.910560131072998s\n",
      "[INFO] Tiempo promedio para realizar una predicci√≥n (m√©todo una a una): 0.003910560131072998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create 1000 sentences\n",
    "sentences_1000 = sentences * 100\n",
    "\n",
    "# Time how long it takes to make predictions on all sentences (one at a time)\n",
    "print(f\"[INFO] Cantidad de frases: {len(sentences_1000)}\")\n",
    "start_time_one_at_a_time = time.time()\n",
    "for sentence in sentences_1000:\n",
    "    # Realizar una predicci√≥n\n",
    "    food_not_food_classifier(sentence)\n",
    "end_time_one_at_a_time = time.time()\n",
    "\n",
    "total_time_one_at_a_time = end_time_one_at_a_time - start_time_one_at_a_time\n",
    "avg_time_per_pred = total_time_one_at_a_time/len(sentences_1000)\n",
    "print(f\"[INFO] Tiempo total para realizar predicciones en {len(sentences_1000)} frases (una por una): {total_time_one_at_a_time}s\")\n",
    "print(f\"[INFO] Tiempo promedio para realizar una predicci√≥n (m√©todo una a una): {avg_time_per_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b885bfec-cb10-4091-80b9-4032caba80b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of sentences: 100\n",
      "[INFO] Tiempo total para realizar predicciones en 100 frases (batch mode): 0.104925\n",
      "[INFO] Tiempo promedio para realizar una predicci√≥n (batch mode): 0.00104925\n",
      "\n",
      "[INFO] Number of sentences: 1000\n",
      "[INFO] Tiempo total para realizar predicciones en 1000 frases (batch mode): 0.67505\n",
      "[INFO] Tiempo promedio para realizar una predicci√≥n (batch mode): 0.00067505\n",
      "\n",
      "[INFO] Number of sentences: 10000\n",
      "[INFO] Tiempo total para realizar predicciones en 10000 frases (batch mode): 6.44067\n",
      "[INFO] Tiempo promedio para realizar una predicci√≥n (batch mode): 0.00064407\n",
      "\n",
      "[INFO] Number of sentences: 100000\n",
      "[INFO] Tiempo total para realizar predicciones en 100000 frases (batch mode): 66.494505\n",
      "[INFO] Tiempo promedio para realizar una predicci√≥n (batch mode): 0.00066495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's now use pipeline in batches\n",
    "for i in [10, 100, 1000, 10_000]:\n",
    "    sentences_big = sentences*i\n",
    "    print(f\"[INFO] Number of sentences: {len(sentences_big)}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Predict on all sentences in batch ode\n",
    "    food_not_food_classifier(sentences_big)\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time_per_all_sentences_batch_mode = end_time - start_time\n",
    "    avg_time_per_sentence_batch_mode = total_time_per_all_sentences_batch_mode/len(sentences_big)\n",
    "\n",
    "    print(f\"[INFO] Tiempo total para realizar predicciones en {len(sentences_big)} frases (batch mode): {round(total_time_per_all_sentences_batch_mode, 6)}\")\n",
    "    print(f\"[INFO] Tiempo promedio para realizar una predicci√≥n (batch mode): {round(avg_time_per_sentence_batch_mode, 8)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0238a0-8f8b-4a45-a909-9b5a3643bfe9",
   "metadata": {},
   "source": [
    "### Haciendo predicciones con PyTorch\n",
    "\n",
    "Pasos para hacer predicciones con PyTorch:\n",
    "1. Crear el tokenizer con `AutoTokenizer`\n",
    "2. Crear el modelo con `AutoModel` (`AutoModelForSequenceClassification`)\n",
    "3. Tokenizar el texto con el paso 1\n",
    "4. Hacer la predicci√≥n con el paso 2\n",
    "5. Formatear la predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "165b457d-527b-4b8e-b2ae-8cb7617288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Setup the model path\n",
    "model_path = \"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# Create an example to predict on\n",
    "sample_food_text = \"A delicious photo of a plate of scrambled eggs, toast an bacon\"\n",
    "\n",
    "# Prepare the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "inputs = tokenizer(sample_food_text,\n",
    "                   return_tensors=\"pt\") # \"pt\" stands for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef4e353d-4b6e-4e9b-8f17-031dd22fbd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load our text classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1bf38126-3ec4-4cd5-8f4c-a249120ae62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.4358,  3.8867]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "# with torch.no_grad()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a4e54c7-87b5-4de2-8e38-d18fd3bf28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: A delicious photo of a plate of scrambled eggs, toast an bacon\n",
      "Etiqueta predecida: food\n",
      "Probabilidad de predicci√≥n: 0.9993398785591125\n"
     ]
    }
   ],
   "source": [
    "# Convierte logits en prediction probability + label\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "prediction_probability = torch.softmax(outputs.logits, dim=1).max().item()\n",
    "\n",
    "print(f\"Texto: {sample_food_text}\")\n",
    "print(f\"Etiqueta predecida: {model.config.id2label[predicted_class_id]}\")\n",
    "print(f\"Probabilidad de predicci√≥n: {prediction_probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e4330bb-e4d0-4f73-b2f1-7321f73e7ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9993398785591125}]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(sample_food_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7860b-2341-4102-a6b0-59157e6571e6",
   "metadata": {},
   "source": [
    "## Proceso completo\n",
    "\n",
    "Vamos a repasar el proceso principio a fin.\n",
    "\n",
    "Desde la importaci√≥n de los datos, pasando por la construcci√≥n del modelo, la evaluaci√≥n del modelo hasta el guardado del modelo para nuestro proyecto de clasificaci√≥n de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e489ffe-32f4-4bc2-a549-cf7bb85058ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62b310e2-c2ce-44bf-a7bc-643bee19c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creando carpeta para guardar los modelos: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n",
      "[INFO] Descargando dataset de Hugging Face Hub, nombre: mrdbourke/learn_hf_food_not_food_image_captions\n",
      "[INFO] Tokenizing text for model training with tokenizer: distilbert/distilbert-base-uncased\n",
      "[INFO] Cargando modelo: distilbert/distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ¬°Modelo cargado correctamente!!\n",
      "[INFO] Empezando entrenamiento de modelo...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Entrenamiento completado, guardando modelo en siguiente carpeta local: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\n",
      "[INFO] Subiendo modelo a Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_args.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.30k/5.30k [00:00<00:00, 7.41kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Modelo subido con √©xito, disponible en https://huggingface.co/tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/tree/main/\n",
      "[INFO] Realizando evaluaci√≥n en test dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] M√©tricas de predicci√≥n en test data:\n",
      "{'test_accuracy': 1.0,\n",
      " 'test_loss': 0.0005472198827192187,\n",
      " 'test_runtime': 0.0564,\n",
      " 'test_samples_per_second': 886.989,\n",
      " 'test_steps_per_second': 35.48}\n"
     ]
    }
   ],
   "source": [
    "# 1. Importamos las librer√≠as necesarias\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 2. Configuramos variables para model training y saving pipeline\n",
    "DATASET_NAME = \"mrdbourke/learn_hf_food_not_food_image_captions\"\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "MODEL_SAVE_DIR_NAME = \"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\"\n",
    "\n",
    "# 3. Creamos directorio para salvar los modelos\n",
    "print(f\"[INFO] Creando carpeta para guardar los modelos: {MODEL_SAVE_DIR_NAME}\")\n",
    "model_save_dir = Path(MODEL_SAVE_DIR_NAME)\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4. Cargamos y preprocesamos el dataset desde Hugging Face Hub\n",
    "print(f\"[INFO] Descargando dataset de Hugging Face Hub, nombre: {DATASET_NAME}\")\n",
    "dataset = datasets.load_dataset(DATASET_NAME)\n",
    "\n",
    "id2label = {0: \"not_food\", 1: \"food\"}\n",
    "label2id  = {\"not_food\": 0, \"food\": 1}\n",
    "\n",
    "# Creando funci√≥n para mapear id a etiquetas en el dataset \n",
    "def map_labels_to_number(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "# Mapear la funci√≥n en todo el dataset\n",
    "dataset = dataset['train'].map(map_labels_to_number)\n",
    "\n",
    "# Dividimos el dataset en train/test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Importamos tokenizer y lo mapeamos en todo el dataset\n",
    "print(f\"[INFO] Tokenizing text for model training with tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=MODEL_NAME,\n",
    "                                          use_fast=True)\n",
    "\n",
    "# Creamos funci√≥n para tokenizar ejemplos\n",
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'],\n",
    "                     padding=True,\n",
    "                     truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(function=tokenize_text,\n",
    "                                batched=True,\n",
    "                                batch_size=1000)\n",
    "                     \n",
    "# 6. Definimos una m√©trica de evaluaci√≥n\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_accuracy(predictions_and_labels):\n",
    "    predictions, labels = predictions_and_labels\n",
    "\n",
    "    # El modelo tendr√° outputs logits de la siguiente forma ([[item_n, item_n], [item_m, item_m]]) \n",
    "    # dependiendo del n√∫mero de clases que tenga el problema\n",
    "    # Queramos comparar etiquetas que est√°n en la forma ([0,0,0,1])\n",
    "    if len(predictions.shape) >= 2:\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "# 7. Seteamos un modelo\n",
    "print(f\"[INFO] Cargando modelo: {MODEL_NAME}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "print(f\"[INFO] ¬°Modelo cargado correctamente!!\")\n",
    "\n",
    "# Configurar TrainingArguments (estos son los hiperpar√°metros para nuestro modelo)\n",
    "# Hiperpar√°metros = configuraciones que podemos establecer como desarrolladores\n",
    "# Par√°metros = configuraciones/pesos que nuestro modelo aprende por s√≠ mismo\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = model_save_dir,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    "    hub_private_repo=False #Note: this will make our model public by default\n",
    ")\n",
    "\n",
    "# Creamos instancia de Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "# 8. Entrenamos el modelo\n",
    "print(f\"[INFO] Empezando entrenamiento de modelo...\")\n",
    "results = trainer.train()\n",
    "\n",
    "# 9. Guardamos el modelo en un directorio local\n",
    "print(f\"[INFO] Entrenamiento completado, guardando modelo en siguiente carpeta local: {model_save_dir}\")\n",
    "trainer.save_model(output_dir=model_save_dir)\n",
    "\n",
    "# 10. Subimos el modelo a Hugging Face Hub\n",
    "print(f\"[INFO] Subiendo modelo a Hugging Face Hub...\")\n",
    "model_upload_url = trainer.push_to_hub(\n",
    "    commit_message=\"Subiendo clasificador de texto (food, not food)\",\n",
    "    token=os.getenv(\"HF_TOKEN\")\n",
    ")\n",
    "print(f\"[INFO] Modelo subido con √©xito, disponible en {model_upload_url}\")\n",
    "\n",
    "# 11. Evaluaci√≥n delo modelo en lla test data\n",
    "print(f\"[INFO] Realizando evaluaci√≥n en test dataset...\")\n",
    "predictions_all = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_values = predictions_all.predictions\n",
    "predictions_metrics = predictions_all.metrics\n",
    "\n",
    "print(f\"[INFO] M√©tricas de predicci√≥n en test data:\")\n",
    "pprint.pprint(predictions_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bfa3041a-adaf-4564-a36d-22c16b14ef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'not_food', 'score': 0.9995301961898804}]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Nos aseguramos que el modelo funciona con frases que no est√°n ni en el training ni en el test set\n",
    "from transformers import pipeline\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=model_save_dir,\n",
    "                                    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "                                    top_k=1,\n",
    "                                    batch_size=32)\n",
    "\n",
    "food_not_food_classifier(\"Yo!!! We just trained a model not food text classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3695d6cf-d29f-479c-aea0-8352a06e681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9993554949760437}]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"A bowl of sliced bell peppers with a sprinkle of paprika and a side of hummus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0233fca7-d612-4ed5-a78c-8516988cbaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9972631931304932}]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"a pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc129874-eb4b-49ae-be69-05ff3c152b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9918377995491028}]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"My favoruite food is biltong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89ae18bb-576d-49be-a013-0ec590e9f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'food', 'score': 0.9989994168281555}]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_not_food_classifier(\"Eggs and bakon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d137b-289a-424f-8fcf-dfefb74563c7",
   "metadata": {},
   "source": [
    "## Convirtiendo nuestro modelo a una demo\n",
    "\n",
    "onvertir un modelo en una demostraci√≥n te ayuda a compartirlo con otros para que puedan probarlo.\n",
    "\n",
    "Y potencialmente puede ofrecer algunas ideas sobre c√≥mo mejorar tu modelo.\n",
    "\n",
    "Vamos a crear una demostraci√≥n de un modelo de aprendizaje autom√°tico con Gradio.\n",
    "\n",
    "Gradio ayuda a crear el flujo de trabajo: entradas -> Modelo de Aprendizaje Autom√°tico -> salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3616f71-c1c9-4e81-8335-94aaae121da3",
   "metadata": {},
   "source": [
    "### Creamos una funci√≥n para realizar inferencias\n",
    "\n",
    "1. Tomamos un input tipo string\n",
    "2. Configuramos un pipeline de clasificaci√≥n de texto\n",
    "3. Tomamos el output del pipeline\n",
    "4. Devolvemos la salida del pipeline en el paso 3 como un diccionario formateado con el siguiente formato:\n",
    "   `{\"label_1\": probability_1, \"label_2\": probability_2,...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8eb5cd57-c96e-4e0e-88e0-800d023b2247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_food': 0.9996128678321838, 'food': 0.0003871637745760381}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# 1. Creamos una funci√≥n para tomar el string input\n",
    "def food_not_food_classifier(text: str) -> Dict[str, float]:\n",
    "    # 2. Seteamos el food not food classifier\n",
    "    food_not_food_classifier_pipeline = pipeline(task=\"text-classification\",\n",
    "                                        model=\"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\",\n",
    "                                        batch_size=32,\n",
    "                                        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                        top_k=None) # top_k=None => return all possible labels\n",
    "\n",
    "    # 3. Tomamos el output del pipeline\n",
    "    outputs = food_not_food_classifier_pipeline(text)[0]\n",
    "\n",
    "    # 4. Formateamos el output para Gradio\n",
    "    output_dict = {}\n",
    "    for item in outputs:\n",
    "        output_dict[item['label']]=item['score']\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "food_not_food_classifier(text=\"We're building a local demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cecc3-ef07-4e65-98d2-eb397d7b5ed1",
   "metadata": {},
   "source": [
    "### Construyendo una peque√±a demo Grado que corra en forma local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90e8a608-edf1-418d-b454-013c11f5237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import gradio\n",
    "import gradio as gr\n",
    "\n",
    "# 2. Create a gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=food_not_food_classifier,\n",
    "    inputs=\"text\",\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"Food not food classifier\",\n",
    "    description=\"A text classifier to determine if a sentence is about food or not\",\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error\"],\n",
    "              [\"A plate of pancakes and strawberry icing\"]])\n",
    "\n",
    "# 3. Launch the interface\n",
    "demo.launch()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d54fd-640d-4647-8a5f-b9bbc3ff2737",
   "metadata": {},
   "source": [
    "### Haciendo nuestra demo accesible p√∫blicamente\n",
    "\n",
    "Existen 2 formas principales de hacer nuestra demo accesible p√∫blicamente con Hugging Face Space:\n",
    "1. Manualmente - Podemos ir a hugginface.co/spaces -> \"Crear nuevo espacio\" -> agregar nuestros archivos y ¬°publicar!\n",
    "2. Program√°ticamente - Podemos usar la API de Python de Hugging Face Hub y agregar nuestros archivos a un Space con c√≥digo.\n",
    "\n",
    "Para crear un espacio program√°ticamente necesitaremos 3 archivos:\n",
    "1. `app.py` - Esta es la aplicaci√≥n principal con la funcionalidad de nuestra demo.\n",
    "2. `requirements.txt` - Estas son las dependencias que nuestra aplicaci√≥n necesitar√°.\n",
    "3. `README.md` - Esto explicar√° de qu√© trata nuestro proyecto/demo. Tambi√©n a√±adir√° algunos metadatos en formato YAML.\n",
    "\n",
    "Para crear estos usaremos la siguiente estructura:\n",
    "\n",
    "```\n",
    "demos/\n",
    "‚îî‚îÄ‚îÄ food_not_food_text_classifier/\n",
    "    ‚îú‚îÄ‚îÄ app.py\n",
    "    ‚îú‚îÄ‚îÄ README.md\n",
    "    ‚îî‚îÄ‚îÄ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e6a8b-a12e-432f-8623-2a38bc174e39",
   "metadata": {},
   "source": [
    "#### Creando una carpeta para guardar la demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dc6395a-7c1b-4edd-80de-bb5ddd72e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Make directory for demos\n",
    "demos_dir = Path(\"./demos\")\n",
    "demos_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a folder for the food_not_food_text_classifier demo\n",
    "food_not_food_text_classifier_demo_dir = Path(demos_dir, \"food_not_food_text_classifier\")\n",
    "food_not_food_text_classifier_demo_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e33d26-be3e-462c-aa5b-293896a8b2cc",
   "metadata": {},
   "source": [
    "#### Creando un archivo app.py\n",
    "\n",
    "Nuestro `app.py` contendr√° la l√≥gica principal de nuestra aplicaci√≥n para ejecutarse.\n",
    "\n",
    "Cuando subimos a Hugging Face Spaces, Spaces intentar√° ejecutar `app.py` autom√°ticamente.\n",
    "\n",
    "En nuestro archivo `app.py` queremos:\n",
    "1. Importar los paquetes\n",
    "2. Definir nuestra funci√≥n para usar nuestro modelo (esto funcionar√° con Gradio)\n",
    "3. Crear una demo con Gradio\n",
    "4. Ejecutar la demo con `demo.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "820e7559-fb55-444d-b255-944a301df27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/app.py\n",
    "# 1. Importamos las librer√≠as necesarias\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "from typing import Dict\n",
    "from transformers import pipeline\n",
    "\n",
    "# 2. Deifnimos nuestra funci√≥n para usar el modelo\n",
    "food_not_food_classifier = pipeline(task=\"text-classification\",\n",
    "                                    model=\"tonicanada/learn_hf_food_not_food_text_classifier-distilbert-base-uncased\",\n",
    "                                    top_k=1,\n",
    "                                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                                    batch_size=32)\n",
    "\n",
    "def classify_text(text):\n",
    "    # Usa el clasificador\n",
    "    result = food_not_food_classifier(text)\n",
    "    # Ahora accedemos al primer diccionario en la primera lista\n",
    "    return result[0][0]['label'], result[0][0]['score']\n",
    "    \n",
    "\n",
    "# 3. Create a Gradio interface\n",
    "description = \"\"\"\n",
    "A text classifier to determine if a sentence is about food or not food. \n",
    "\n",
    "Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [small dataset of food and not food text](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "See [source code](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb).\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn = classify_text,\n",
    "    inputs = \"text\",\n",
    "    outputs=[gr.Label(num_top_classes=2), gr.Textbox()],\n",
    "    title=\"üçóüö´ü•ë Food or Not Food Text Classifier\",\n",
    "    description=description,\n",
    "    examples=[[\"I whipped up a fresh batch of code, but it seems to have a syntax error.\"],\n",
    "                       [\"A delicious photo of a plate of scrambled eggs, bacon and toast.\"]])\n",
    "\n",
    "\n",
    "# 4. Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f87f0-65ab-49b3-990f-e3e7a3c93be2",
   "metadata": {},
   "source": [
    "#### Creando a README file\n",
    "\n",
    "Este archivo est√° en formato Markdown.  \n",
    "Con un bloque YAML en la parte superior.  \n",
    "El bloque YAML en la parte superior se utiliza para los metadatos y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a6e53391-e9ee-4df1-9529-f0c2951db306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/README.md\n",
    "---\n",
    "title: Food Not Food Text Classifier\n",
    "emoji: üçóüö´ü•ë\n",
    "colorFrom: blue\n",
    "colorTo: yellow\n",
    "sdk: gradio\n",
    "app_file: app.py\n",
    "pinned: false\n",
    "license: apache-2.0\n",
    "---\n",
    "\n",
    "# üçóüö´ü•ë Food Not Food Text Classifier\n",
    "\n",
    "Small demo to showcase a text classifier to determine if a sentence is about food or not food.\n",
    "\n",
    "DistillBERT model fine-tuned on a small synthetic dataset of 250 generated [Food or Not Food image captions](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).\n",
    "\n",
    "[Source code notebook](https://github.com/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf1523-be75-48c9-ae87-48a12511d26c",
   "metadata": {},
   "source": [
    "#### Creando un requirements file\n",
    "\n",
    "Este archivo le indicar√° a nuestro Hugging Face Space qu√© versiones/paquetes utilizar.\n",
    "\n",
    "Si no creamos este archivo, podr√≠amos obtener un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11327b72-bb2c-4429-b65a-b7535c925d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./demos/food_not_food_text_classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./demos/food_not_food_text_classifier/requirements.txt\n",
    "gradio\n",
    "torch\n",
    "transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a4af7-8216-4880-94e7-73bce53c77cb",
   "metadata": {},
   "source": [
    "#### Subiendo nuestra demo a Hugging Face Spaces\n",
    "\n",
    "Para hacerlo, utilizaremos la API de Python de Hugging Face Hub.\n",
    "\n",
    "Para subir nuestra demo a HF Spaces, podemos hacer lo siguiente:\n",
    "1. Importar las funciones necesarias\n",
    "2. Definir lo que queremos subir + los nombres de los archivos\n",
    "3. Crear el repositorio\n",
    "4. Obtener el nombre de nuestro repositorio de nuestra carga\n",
    "5. Subir el contenido de nuestro `./demos/food_not_food_classifier/` a nuestro Hugging Face\n",
    "6. Esperar que todo funcione e inspeccionar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d8d943db-efe8-4905-9805-3c9ff3fffef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "880bcef3-114a-4c09-ab7f-06b71bd1529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creando repo en Hugging Face Hub con nombre: learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Nombre completo del repositorio en HF: tonicanada/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Subiendo ./demos/food_not_food_text_classifier/ al repo tonicanada/learn_hf_food_not_food_text_classifier_demo\n",
      "[INFO] Demo folder se ha subido con √©xito, esta es la commit url: https://huggingface.co/spaces/tonicanada/learn_hf_food_not_food_text_classifier_demo/tree/main/.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import (\n",
    "    create_repo,\n",
    "    get_full_repo_name,\n",
    "    upload_file,\n",
    "    upload_folder\n",
    ")\n",
    "\n",
    "# Define los par√°metros que nos gustar√≠a usar para subir nuestro Space\n",
    "LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD = \"./demos/food_not_food_text_classifier/\"\n",
    "HF_TARGET_SPACE_NAME = \"learn_hf_food_not_food_text_classifier_demo\"\n",
    "HF_REPO_TYPE = \"space\"\n",
    "HF_SPACE_SDK = \"gradio\"\n",
    "\n",
    "# Crea a Space repo on Hugging Face Hub\n",
    "print(f\"[INFO] Creando repo en Hugging Face Hub con nombre: {HF_TARGET_SPACE_NAME}\")\n",
    "create_repo(\n",
    "    repo_id=HF_TARGET_SPACE_NAME,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    repo_type = HF_REPO_TYPE,\n",
    "    private=False,\n",
    "    space_sdk=HF_SPACE_SDK,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# Obtener el nombre completo del repo (e.g. {username}/{repo_name})\n",
    "hf_full_repo_name = get_full_repo_name(model_id=HF_TARGET_SPACE_NAME)\n",
    "print(f\"[INFO] Nombre completo del repositorio en HF: {hf_full_repo_name}\")\n",
    "\n",
    "# Subiendo el demo folder\n",
    "print(f\"[INFO] Subiendo {LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD} al repo {hf_full_repo_name}\")\n",
    "folder_upload_url = upload_folder(\n",
    "    repo_id=hf_full_repo_name,\n",
    "    folder_path=LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,\n",
    "    path_in_repo=\".\",\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    repo_type=HF_REPO_TYPE,\n",
    "    commit_message=\"Uploading our food not food classifier demo from a notebook!\"\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Demo folder se ha subido con √©xito, esta es la commit url: {folder_upload_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf35b7-100b-43cf-9d51-2969e97b030a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
